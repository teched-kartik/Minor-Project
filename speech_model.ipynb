{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SOUND_CLASSIFICATION_DATASET/training1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME  LABEL\n",
       "0     1      1\n",
       "1     2      1\n",
       "2     3      1\n",
       "3     4      0\n",
       "4     5      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1584 entries, 0 to 1583\n",
      "Data columns (total 2 columns):\n",
      "NAME     1584 non-null int64\n",
      "LABEL    1584 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 24.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa import display\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                        | 133/1584 [01:25<16:08,  1.50it/s]C:\\Users\\lenovo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\pitch.py:146: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1584/1584 [15:51<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING \n",
    "x_train=[]\n",
    "y_train=[]\n",
    "path=\"SOUND_CLASSIFICATION_DATASET/TRAIN_SET/\"\n",
    "for i in tqdm(range(len(data))):\n",
    "    file=str(data.iloc[i][\"NAME\"])+\".wav\"\n",
    "    label=data.iloc[i][\"LABEL\"]\n",
    "    filename=path+file\n",
    "    y,sr=librosa.load(filename)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000).T,axis=0)\n",
    "    chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens)),(40,5))\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"SOUND_CLASSIFICATION_DATASET/testing1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 2 columns):\n",
      "NAME     56 non-null int64\n",
      "LABEL    56 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 976.0 bytes\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:35<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING TEST SET\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "path=\"SOUND_CLASSIFICATION_DATASET/TEST_SET/\"\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    file=str(dataset.iloc[i][\"NAME\"])+\".wav\"\n",
    "    label=dataset.iloc[i][\"LABEL\"]\n",
    "    filename=path+file\n",
    "    y,sr=librosa.load(filename)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000).T,axis=0)\n",
    "    chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens)),(40,5))\n",
    "    x_test.append(features)\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING TO ARRAY\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1584, 40, 5), (1584,), (56, 40, 5), (56,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , y_train.shape , x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((1584,1))\n",
    "y_test = y_test.reshape((56,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape((56,40,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 40, 5, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1584, 2), (56, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to one hot\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1583]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((1584,40,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584, 40, 5, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lenovo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#adding layers and forming the model\n",
    "model.add(Conv2D(64,kernel_size=5,strides=1,padding=\"Same\",activation=\"relu\",input_shape=(40,5,1)))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lenovo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1584 samples, validate on 56 samples\n",
      "Epoch 1/50\n",
      "1584/1584 [==============================] - ETA: 3:58 - loss: 2.1688 - acc: 0.406 - ETA: 2:01 - loss: 4.6602 - acc: 0.375 - ETA: 1:21 - loss: 4.2112 - acc: 0.364 - ETA: 1:02 - loss: 3.8800 - acc: 0.390 - ETA: 49s - loss: 3.4624 - acc: 0.443 - ETA: 42s - loss: 3.1500 - acc: 0.46 - ETA: 36s - loss: 2.8436 - acc: 0.47 - ETA: 31s - loss: 2.6604 - acc: 0.50 - ETA: 28s - loss: 2.6087 - acc: 0.50 - ETA: 25s - loss: 2.4431 - acc: 0.51 - ETA: 23s - loss: 2.3311 - acc: 0.50 - ETA: 21s - loss: 2.2462 - acc: 0.49 - ETA: 19s - loss: 2.1663 - acc: 0.50 - ETA: 18s - loss: 2.0784 - acc: 0.49 - ETA: 16s - loss: 1.9936 - acc: 0.50 - ETA: 15s - loss: 1.9358 - acc: 0.49 - ETA: 14s - loss: 1.8615 - acc: 0.49 - ETA: 13s - loss: 1.8028 - acc: 0.50 - ETA: 12s - loss: 1.7374 - acc: 0.51 - ETA: 11s - loss: 1.7021 - acc: 0.51 - ETA: 11s - loss: 1.6685 - acc: 0.50 - ETA: 10s - loss: 1.6373 - acc: 0.51 - ETA: 9s - loss: 1.5967 - acc: 0.5204 - ETA: 9s - loss: 1.5636 - acc: 0.526 - ETA: 8s - loss: 1.5330 - acc: 0.526 - ETA: 8s - loss: 1.5097 - acc: 0.527 - ETA: 7s - loss: 1.4843 - acc: 0.531 - ETA: 7s - loss: 1.4758 - acc: 0.530 - ETA: 6s - loss: 1.4517 - acc: 0.531 - ETA: 6s - loss: 1.4252 - acc: 0.534 - ETA: 5s - loss: 1.3960 - acc: 0.539 - ETA: 5s - loss: 1.3782 - acc: 0.540 - ETA: 5s - loss: 1.3564 - acc: 0.542 - ETA: 4s - loss: 1.3418 - acc: 0.544 - ETA: 4s - loss: 1.3244 - acc: 0.541 - ETA: 4s - loss: 1.3103 - acc: 0.540 - ETA: 3s - loss: 1.2940 - acc: 0.544 - ETA: 3s - loss: 1.2812 - acc: 0.546 - ETA: 3s - loss: 1.2726 - acc: 0.544 - ETA: 2s - loss: 1.2597 - acc: 0.546 - ETA: 2s - loss: 1.2492 - acc: 0.547 - ETA: 2s - loss: 1.2317 - acc: 0.552 - ETA: 1s - loss: 1.2286 - acc: 0.554 - ETA: 1s - loss: 1.2147 - acc: 0.557 - ETA: 1s - loss: 1.2007 - acc: 0.559 - ETA: 0s - loss: 1.1862 - acc: 0.563 - ETA: 0s - loss: 1.1734 - acc: 0.566 - ETA: 0s - loss: 1.1643 - acc: 0.567 - ETA: 0s - loss: 1.1515 - acc: 0.570 - 14s 9ms/step - loss: 1.1444 - acc: 0.5732 - val_loss: 0.6981 - val_acc: 0.6250\n",
      "Epoch 2/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.6852 - acc: 0.656 - ETA: 7s - loss: 0.6215 - acc: 0.703 - ETA: 7s - loss: 0.6320 - acc: 0.687 - ETA: 7s - loss: 0.6388 - acc: 0.656 - ETA: 7s - loss: 0.6004 - acc: 0.675 - ETA: 7s - loss: 0.6035 - acc: 0.677 - ETA: 7s - loss: 0.6317 - acc: 0.665 - ETA: 7s - loss: 0.6356 - acc: 0.664 - ETA: 6s - loss: 0.6261 - acc: 0.680 - ETA: 6s - loss: 0.6240 - acc: 0.684 - ETA: 6s - loss: 0.6092 - acc: 0.693 - ETA: 6s - loss: 0.6018 - acc: 0.703 - ETA: 6s - loss: 0.5883 - acc: 0.711 - ETA: 6s - loss: 0.5953 - acc: 0.709 - ETA: 6s - loss: 0.5850 - acc: 0.716 - ETA: 6s - loss: 0.5756 - acc: 0.718 - ETA: 6s - loss: 0.5757 - acc: 0.722 - ETA: 6s - loss: 0.5707 - acc: 0.729 - ETA: 5s - loss: 0.5755 - acc: 0.730 - ETA: 5s - loss: 0.5721 - acc: 0.734 - ETA: 5s - loss: 0.5700 - acc: 0.735 - ETA: 5s - loss: 0.5647 - acc: 0.735 - ETA: 5s - loss: 0.5566 - acc: 0.740 - ETA: 4s - loss: 0.5532 - acc: 0.739 - ETA: 4s - loss: 0.5509 - acc: 0.743 - ETA: 4s - loss: 0.5419 - acc: 0.750 - ETA: 4s - loss: 0.5367 - acc: 0.752 - ETA: 4s - loss: 0.5337 - acc: 0.755 - ETA: 3s - loss: 0.5333 - acc: 0.755 - ETA: 3s - loss: 0.5291 - acc: 0.761 - ETA: 3s - loss: 0.5239 - acc: 0.766 - ETA: 3s - loss: 0.5211 - acc: 0.765 - ETA: 3s - loss: 0.5201 - acc: 0.765 - ETA: 2s - loss: 0.5129 - acc: 0.769 - ETA: 2s - loss: 0.5041 - acc: 0.775 - ETA: 2s - loss: 0.5051 - acc: 0.774 - ETA: 2s - loss: 0.5045 - acc: 0.774 - ETA: 2s - loss: 0.5018 - acc: 0.777 - ETA: 1s - loss: 0.5020 - acc: 0.776 - ETA: 1s - loss: 0.4983 - acc: 0.778 - ETA: 1s - loss: 0.4943 - acc: 0.780 - ETA: 1s - loss: 0.4963 - acc: 0.781 - ETA: 1s - loss: 0.4987 - acc: 0.779 - ETA: 1s - loss: 0.5064 - acc: 0.776 - ETA: 0s - loss: 0.5063 - acc: 0.777 - ETA: 0s - loss: 0.5065 - acc: 0.775 - ETA: 0s - loss: 0.5036 - acc: 0.777 - ETA: 0s - loss: 0.5018 - acc: 0.778 - ETA: 0s - loss: 0.4984 - acc: 0.780 - 9s 6ms/step - loss: 0.4972 - acc: 0.7822 - val_loss: 0.5767 - val_acc: 0.7857\n",
      "Epoch 3/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.3912 - acc: 0.843 - ETA: 8s - loss: 0.3968 - acc: 0.812 - ETA: 8s - loss: 0.3986 - acc: 0.822 - ETA: 8s - loss: 0.4032 - acc: 0.804 - ETA: 8s - loss: 0.3559 - acc: 0.843 - ETA: 7s - loss: 0.4982 - acc: 0.776 - ETA: 7s - loss: 0.4794 - acc: 0.785 - ETA: 7s - loss: 0.4628 - acc: 0.800 - ETA: 7s - loss: 0.4784 - acc: 0.798 - ETA: 6s - loss: 0.5064 - acc: 0.796 - ETA: 6s - loss: 0.4905 - acc: 0.806 - ETA: 6s - loss: 0.4704 - acc: 0.815 - ETA: 6s - loss: 0.4670 - acc: 0.814 - ETA: 6s - loss: 0.4521 - acc: 0.821 - ETA: 5s - loss: 0.4445 - acc: 0.822 - ETA: 5s - loss: 0.4497 - acc: 0.818 - ETA: 5s - loss: 0.4445 - acc: 0.819 - ETA: 5s - loss: 0.4582 - acc: 0.824 - ETA: 5s - loss: 0.4497 - acc: 0.825 - ETA: 5s - loss: 0.4520 - acc: 0.823 - ETA: 4s - loss: 0.4516 - acc: 0.824 - ETA: 4s - loss: 0.4450 - acc: 0.826 - ETA: 4s - loss: 0.4412 - acc: 0.826 - ETA: 4s - loss: 0.4499 - acc: 0.825 - ETA: 4s - loss: 0.4457 - acc: 0.828 - ETA: 4s - loss: 0.4408 - acc: 0.829 - ETA: 3s - loss: 0.4378 - acc: 0.828 - ETA: 3s - loss: 0.4417 - acc: 0.827 - ETA: 3s - loss: 0.4384 - acc: 0.828 - ETA: 3s - loss: 0.4371 - acc: 0.830 - ETA: 3s - loss: 0.4349 - acc: 0.831 - ETA: 3s - loss: 0.4283 - acc: 0.833 - ETA: 2s - loss: 0.4223 - acc: 0.836 - ETA: 2s - loss: 0.4202 - acc: 0.836 - ETA: 2s - loss: 0.4181 - acc: 0.838 - ETA: 2s - loss: 0.4112 - acc: 0.842 - ETA: 2s - loss: 0.4099 - acc: 0.842 - ETA: 1s - loss: 0.4057 - acc: 0.845 - ETA: 1s - loss: 0.4098 - acc: 0.847 - ETA: 1s - loss: 0.4052 - acc: 0.848 - ETA: 1s - loss: 0.4057 - acc: 0.848 - ETA: 1s - loss: 0.4032 - acc: 0.849 - ETA: 1s - loss: 0.4049 - acc: 0.848 - ETA: 0s - loss: 0.4014 - acc: 0.849 - ETA: 0s - loss: 0.3975 - acc: 0.851 - ETA: 0s - loss: 0.3980 - acc: 0.851 - ETA: 0s - loss: 0.3945 - acc: 0.851 - ETA: 0s - loss: 0.3976 - acc: 0.852 - ETA: 0s - loss: 0.3963 - acc: 0.852 - 9s 5ms/step - loss: 0.3946 - acc: 0.8529 - val_loss: 0.5731 - val_acc: 0.7500\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 7s - loss: 0.7296 - acc: 0.875 - ETA: 7s - loss: 0.5648 - acc: 0.828 - ETA: 7s - loss: 0.4342 - acc: 0.875 - ETA: 7s - loss: 0.4019 - acc: 0.882 - ETA: 7s - loss: 0.3587 - acc: 0.893 - ETA: 7s - loss: 0.3870 - acc: 0.880 - ETA: 7s - loss: 0.3859 - acc: 0.875 - ETA: 6s - loss: 0.3680 - acc: 0.882 - ETA: 6s - loss: 0.3464 - acc: 0.888 - ETA: 6s - loss: 0.3235 - acc: 0.896 - ETA: 6s - loss: 0.3173 - acc: 0.894 - ETA: 6s - loss: 0.3122 - acc: 0.895 - ETA: 6s - loss: 0.3098 - acc: 0.896 - ETA: 5s - loss: 0.3402 - acc: 0.886 - ETA: 5s - loss: 0.3397 - acc: 0.883 - ETA: 5s - loss: 0.3448 - acc: 0.882 - ETA: 5s - loss: 0.3391 - acc: 0.884 - ETA: 5s - loss: 0.3385 - acc: 0.885 - ETA: 4s - loss: 0.3323 - acc: 0.888 - ETA: 4s - loss: 0.3298 - acc: 0.887 - ETA: 4s - loss: 0.3265 - acc: 0.885 - ETA: 4s - loss: 0.3275 - acc: 0.887 - ETA: 4s - loss: 0.3296 - acc: 0.887 - ETA: 4s - loss: 0.3240 - acc: 0.889 - ETA: 4s - loss: 0.3261 - acc: 0.888 - ETA: 3s - loss: 0.3232 - acc: 0.889 - ETA: 3s - loss: 0.3189 - acc: 0.891 - ETA: 3s - loss: 0.3332 - acc: 0.886 - ETA: 3s - loss: 0.3292 - acc: 0.886 - ETA: 3s - loss: 0.3287 - acc: 0.886 - ETA: 3s - loss: 0.3242 - acc: 0.888 - ETA: 2s - loss: 0.3227 - acc: 0.888 - ETA: 2s - loss: 0.3248 - acc: 0.888 - ETA: 2s - loss: 0.3218 - acc: 0.887 - ETA: 2s - loss: 0.3167 - acc: 0.889 - ETA: 2s - loss: 0.3140 - acc: 0.891 - ETA: 2s - loss: 0.3125 - acc: 0.891 - ETA: 1s - loss: 0.3075 - acc: 0.893 - ETA: 1s - loss: 0.3053 - acc: 0.894 - ETA: 1s - loss: 0.3029 - acc: 0.894 - ETA: 1s - loss: 0.3013 - acc: 0.894 - ETA: 1s - loss: 0.3032 - acc: 0.894 - ETA: 1s - loss: 0.3047 - acc: 0.894 - ETA: 0s - loss: 0.3007 - acc: 0.895 - ETA: 0s - loss: 0.2993 - acc: 0.896 - ETA: 0s - loss: 0.3039 - acc: 0.892 - ETA: 0s - loss: 0.3024 - acc: 0.893 - ETA: 0s - loss: 0.2997 - acc: 0.893 - ETA: 0s - loss: 0.3005 - acc: 0.892 - 8s 5ms/step - loss: 0.3017 - acc: 0.8933 - val_loss: 0.3272 - val_acc: 0.8750\n",
      "Epoch 5/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.3048 - acc: 0.875 - ETA: 7s - loss: 0.3205 - acc: 0.906 - ETA: 8s - loss: 0.2694 - acc: 0.916 - ETA: 8s - loss: 0.3268 - acc: 0.882 - ETA: 7s - loss: 0.3039 - acc: 0.881 - ETA: 7s - loss: 0.3074 - acc: 0.885 - ETA: 7s - loss: 0.2965 - acc: 0.875 - ETA: 7s - loss: 0.2858 - acc: 0.886 - ETA: 6s - loss: 0.3507 - acc: 0.875 - ETA: 6s - loss: 0.3313 - acc: 0.884 - ETA: 6s - loss: 0.3233 - acc: 0.886 - ETA: 6s - loss: 0.3362 - acc: 0.875 - ETA: 6s - loss: 0.3219 - acc: 0.877 - ETA: 5s - loss: 0.3170 - acc: 0.877 - ETA: 5s - loss: 0.3120 - acc: 0.881 - ETA: 5s - loss: 0.2990 - acc: 0.886 - ETA: 5s - loss: 0.2937 - acc: 0.887 - ETA: 5s - loss: 0.2896 - acc: 0.888 - ETA: 5s - loss: 0.2846 - acc: 0.888 - ETA: 4s - loss: 0.2752 - acc: 0.892 - ETA: 4s - loss: 0.2719 - acc: 0.894 - ETA: 4s - loss: 0.2683 - acc: 0.894 - ETA: 4s - loss: 0.2609 - acc: 0.898 - ETA: 4s - loss: 0.2583 - acc: 0.901 - ETA: 4s - loss: 0.2633 - acc: 0.898 - ETA: 3s - loss: 0.2644 - acc: 0.897 - ETA: 3s - loss: 0.2642 - acc: 0.899 - ETA: 3s - loss: 0.2588 - acc: 0.901 - ETA: 3s - loss: 0.2649 - acc: 0.898 - ETA: 3s - loss: 0.2631 - acc: 0.901 - ETA: 3s - loss: 0.2609 - acc: 0.902 - ETA: 3s - loss: 0.2613 - acc: 0.901 - ETA: 2s - loss: 0.2579 - acc: 0.902 - ETA: 2s - loss: 0.2543 - acc: 0.904 - ETA: 2s - loss: 0.2509 - acc: 0.906 - ETA: 2s - loss: 0.2484 - acc: 0.907 - ETA: 2s - loss: 0.2486 - acc: 0.905 - ETA: 2s - loss: 0.2537 - acc: 0.903 - ETA: 1s - loss: 0.2518 - acc: 0.903 - ETA: 1s - loss: 0.2492 - acc: 0.904 - ETA: 1s - loss: 0.2475 - acc: 0.906 - ETA: 1s - loss: 0.2488 - acc: 0.905 - ETA: 1s - loss: 0.2460 - acc: 0.906 - ETA: 0s - loss: 0.2471 - acc: 0.906 - ETA: 0s - loss: 0.2449 - acc: 0.906 - ETA: 0s - loss: 0.2445 - acc: 0.906 - ETA: 0s - loss: 0.2465 - acc: 0.904 - ETA: 0s - loss: 0.2433 - acc: 0.906 - ETA: 0s - loss: 0.2435 - acc: 0.907 - 9s 6ms/step - loss: 0.2453 - acc: 0.9059 - val_loss: 0.2076 - val_acc: 0.9464\n",
      "Epoch 6/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.2458 - acc: 0.843 - ETA: 9s - loss: 0.1666 - acc: 0.906 - ETA: 8s - loss: 0.2265 - acc: 0.906 - ETA: 8s - loss: 0.1980 - acc: 0.921 - ETA: 8s - loss: 0.2280 - acc: 0.925 - ETA: 7s - loss: 0.2332 - acc: 0.916 - ETA: 7s - loss: 0.2492 - acc: 0.906 - ETA: 7s - loss: 0.2400 - acc: 0.910 - ETA: 7s - loss: 0.2536 - acc: 0.909 - ETA: 6s - loss: 0.3050 - acc: 0.896 - ETA: 6s - loss: 0.3137 - acc: 0.894 - ETA: 6s - loss: 0.2982 - acc: 0.901 - ETA: 6s - loss: 0.3064 - acc: 0.901 - ETA: 6s - loss: 0.3111 - acc: 0.895 - ETA: 6s - loss: 0.3177 - acc: 0.887 - ETA: 5s - loss: 0.3074 - acc: 0.886 - ETA: 5s - loss: 0.3049 - acc: 0.889 - ETA: 5s - loss: 0.3036 - acc: 0.890 - ETA: 5s - loss: 0.3009 - acc: 0.891 - ETA: 5s - loss: 0.3280 - acc: 0.885 - ETA: 4s - loss: 0.3186 - acc: 0.886 - ETA: 4s - loss: 0.3146 - acc: 0.886 - ETA: 4s - loss: 0.3223 - acc: 0.884 - ETA: 4s - loss: 0.3182 - acc: 0.885 - ETA: 4s - loss: 0.3094 - acc: 0.888 - ETA: 4s - loss: 0.3063 - acc: 0.889 - ETA: 3s - loss: 0.3066 - acc: 0.888 - ETA: 3s - loss: 0.3047 - acc: 0.888 - ETA: 3s - loss: 0.3051 - acc: 0.887 - ETA: 3s - loss: 0.3021 - acc: 0.888 - ETA: 3s - loss: 0.2978 - acc: 0.890 - ETA: 2s - loss: 0.2979 - acc: 0.888 - ETA: 2s - loss: 0.2978 - acc: 0.888 - ETA: 2s - loss: 0.2935 - acc: 0.890 - ETA: 2s - loss: 0.2932 - acc: 0.891 - ETA: 2s - loss: 0.2937 - acc: 0.890 - ETA: 2s - loss: 0.2902 - acc: 0.891 - ETA: 1s - loss: 0.2899 - acc: 0.892 - ETA: 1s - loss: 0.2882 - acc: 0.892 - ETA: 1s - loss: 0.2873 - acc: 0.893 - ETA: 1s - loss: 0.2862 - acc: 0.892 - ETA: 1s - loss: 0.2870 - acc: 0.892 - ETA: 1s - loss: 0.2855 - acc: 0.891 - ETA: 0s - loss: 0.2816 - acc: 0.892 - ETA: 0s - loss: 0.2804 - acc: 0.893 - ETA: 0s - loss: 0.2830 - acc: 0.892 - ETA: 0s - loss: 0.2796 - acc: 0.894 - ETA: 0s - loss: 0.2803 - acc: 0.893 - ETA: 0s - loss: 0.2786 - acc: 0.892 - 8s 5ms/step - loss: 0.2790 - acc: 0.8927 - val_loss: 0.3748 - val_acc: 0.8750\n",
      "Epoch 7/50\n",
      "1584/1584 [==============================] - ETA: 10s - loss: 0.1516 - acc: 0.93 - ETA: 9s - loss: 0.1631 - acc: 0.9375 - ETA: 8s - loss: 0.1733 - acc: 0.947 - ETA: 8s - loss: 0.1698 - acc: 0.945 - ETA: 7s - loss: 0.1743 - acc: 0.943 - ETA: 7s - loss: 0.1889 - acc: 0.927 - ETA: 7s - loss: 0.2213 - acc: 0.906 - ETA: 7s - loss: 0.2031 - acc: 0.918 - ETA: 6s - loss: 0.2047 - acc: 0.920 - ETA: 6s - loss: 0.2007 - acc: 0.921 - ETA: 6s - loss: 0.2050 - acc: 0.917 - ETA: 6s - loss: 0.2161 - acc: 0.908 - ETA: 6s - loss: 0.2122 - acc: 0.908 - ETA: 5s - loss: 0.2052 - acc: 0.910 - ETA: 5s - loss: 0.2033 - acc: 0.910 - ETA: 5s - loss: 0.2045 - acc: 0.908 - ETA: 5s - loss: 0.2109 - acc: 0.906 - ETA: 5s - loss: 0.2015 - acc: 0.911 - ETA: 4s - loss: 0.1926 - acc: 0.916 - ETA: 4s - loss: 0.1982 - acc: 0.914 - ETA: 4s - loss: 0.1957 - acc: 0.915 - ETA: 4s - loss: 0.2027 - acc: 0.911 - ETA: 4s - loss: 0.2090 - acc: 0.909 - ETA: 4s - loss: 0.2131 - acc: 0.907 - ETA: 3s - loss: 0.2072 - acc: 0.911 - ETA: 3s - loss: 0.2020 - acc: 0.913 - ETA: 3s - loss: 0.2001 - acc: 0.914 - ETA: 3s - loss: 0.2007 - acc: 0.914 - ETA: 3s - loss: 0.2059 - acc: 0.913 - ETA: 3s - loss: 0.2074 - acc: 0.914 - ETA: 2s - loss: 0.2217 - acc: 0.914 - ETA: 2s - loss: 0.2269 - acc: 0.911 - ETA: 2s - loss: 0.2319 - acc: 0.909 - ETA: 2s - loss: 0.2312 - acc: 0.909 - ETA: 2s - loss: 0.2271 - acc: 0.911 - ETA: 2s - loss: 0.2328 - acc: 0.908 - ETA: 2s - loss: 0.2320 - acc: 0.907 - ETA: 1s - loss: 0.2321 - acc: 0.907 - ETA: 1s - loss: 0.2287 - acc: 0.909 - ETA: 1s - loss: 0.2289 - acc: 0.910 - ETA: 1s - loss: 0.2285 - acc: 0.910 - ETA: 1s - loss: 0.2259 - acc: 0.912 - ETA: 1s - loss: 0.2245 - acc: 0.912 - ETA: 0s - loss: 0.2282 - acc: 0.910 - ETA: 0s - loss: 0.2255 - acc: 0.911 - ETA: 0s - loss: 0.2232 - acc: 0.913 - ETA: 0s - loss: 0.2236 - acc: 0.912 - ETA: 0s - loss: 0.2240 - acc: 0.911 - ETA: 0s - loss: 0.2271 - acc: 0.910 - 8s 5ms/step - loss: 0.2266 - acc: 0.9110 - val_loss: 0.1931 - val_acc: 0.9464\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 9s - loss: 0.1042 - acc: 0.968 - ETA: 8s - loss: 0.1023 - acc: 0.968 - ETA: 7s - loss: 0.1169 - acc: 0.958 - ETA: 7s - loss: 0.1213 - acc: 0.960 - ETA: 7s - loss: 0.1406 - acc: 0.950 - ETA: 7s - loss: 0.1423 - acc: 0.942 - ETA: 7s - loss: 0.1251 - acc: 0.950 - ETA: 6s - loss: 0.1385 - acc: 0.941 - ETA: 6s - loss: 0.1359 - acc: 0.937 - ETA: 6s - loss: 0.1470 - acc: 0.934 - ETA: 6s - loss: 0.1613 - acc: 0.934 - ETA: 6s - loss: 0.1659 - acc: 0.929 - ETA: 5s - loss: 0.1649 - acc: 0.932 - ETA: 5s - loss: 0.1658 - acc: 0.935 - ETA: 5s - loss: 0.1587 - acc: 0.939 - ETA: 5s - loss: 0.1604 - acc: 0.941 - ETA: 5s - loss: 0.1598 - acc: 0.941 - ETA: 5s - loss: 0.1613 - acc: 0.939 - ETA: 4s - loss: 0.1634 - acc: 0.935 - ETA: 4s - loss: 0.1595 - acc: 0.937 - ETA: 4s - loss: 0.1549 - acc: 0.940 - ETA: 4s - loss: 0.1550 - acc: 0.938 - ETA: 4s - loss: 0.1648 - acc: 0.932 - ETA: 4s - loss: 0.1699 - acc: 0.929 - ETA: 3s - loss: 0.1694 - acc: 0.931 - ETA: 3s - loss: 0.1698 - acc: 0.932 - ETA: 3s - loss: 0.1674 - acc: 0.934 - ETA: 3s - loss: 0.1721 - acc: 0.931 - ETA: 3s - loss: 0.1690 - acc: 0.933 - ETA: 3s - loss: 0.1678 - acc: 0.934 - ETA: 2s - loss: 0.1680 - acc: 0.933 - ETA: 2s - loss: 0.1674 - acc: 0.932 - ETA: 2s - loss: 0.1680 - acc: 0.932 - ETA: 2s - loss: 0.1697 - acc: 0.932 - ETA: 2s - loss: 0.1742 - acc: 0.931 - ETA: 2s - loss: 0.1737 - acc: 0.931 - ETA: 1s - loss: 0.1765 - acc: 0.929 - ETA: 1s - loss: 0.1788 - acc: 0.928 - ETA: 1s - loss: 0.1767 - acc: 0.930 - ETA: 1s - loss: 0.1758 - acc: 0.931 - ETA: 1s - loss: 0.1766 - acc: 0.929 - ETA: 1s - loss: 0.1761 - acc: 0.930 - ETA: 1s - loss: 0.1750 - acc: 0.931 - ETA: 0s - loss: 0.1785 - acc: 0.930 - ETA: 0s - loss: 0.1798 - acc: 0.929 - ETA: 0s - loss: 0.1774 - acc: 0.930 - ETA: 0s - loss: 0.1808 - acc: 0.929 - ETA: 0s - loss: 0.1837 - acc: 0.929 - ETA: 0s - loss: 0.1871 - acc: 0.927 - 8s 5ms/step - loss: 0.1860 - acc: 0.9287 - val_loss: 0.2202 - val_acc: 0.9464\n",
      "Epoch 9/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.2029 - acc: 0.937 - ETA: 7s - loss: 0.2376 - acc: 0.921 - ETA: 7s - loss: 0.2103 - acc: 0.927 - ETA: 7s - loss: 0.1758 - acc: 0.945 - ETA: 7s - loss: 0.1761 - acc: 0.950 - ETA: 7s - loss: 0.1753 - acc: 0.942 - ETA: 6s - loss: 0.1797 - acc: 0.933 - ETA: 6s - loss: 0.1656 - acc: 0.937 - ETA: 6s - loss: 0.1767 - acc: 0.930 - ETA: 6s - loss: 0.1765 - acc: 0.931 - ETA: 6s - loss: 0.1762 - acc: 0.929 - ETA: 5s - loss: 0.1747 - acc: 0.929 - ETA: 5s - loss: 0.1756 - acc: 0.930 - ETA: 5s - loss: 0.1740 - acc: 0.930 - ETA: 5s - loss: 0.1705 - acc: 0.929 - ETA: 5s - loss: 0.1707 - acc: 0.925 - ETA: 5s - loss: 0.1705 - acc: 0.926 - ETA: 5s - loss: 0.1638 - acc: 0.930 - ETA: 5s - loss: 0.1634 - acc: 0.930 - ETA: 4s - loss: 0.1594 - acc: 0.934 - ETA: 4s - loss: 0.1598 - acc: 0.934 - ETA: 4s - loss: 0.1630 - acc: 0.934 - ETA: 4s - loss: 0.1699 - acc: 0.933 - ETA: 4s - loss: 0.1647 - acc: 0.936 - ETA: 4s - loss: 0.1686 - acc: 0.933 - ETA: 3s - loss: 0.1711 - acc: 0.932 - ETA: 3s - loss: 0.1686 - acc: 0.934 - ETA: 3s - loss: 0.1707 - acc: 0.933 - ETA: 3s - loss: 0.1767 - acc: 0.932 - ETA: 3s - loss: 0.1820 - acc: 0.930 - ETA: 3s - loss: 0.1860 - acc: 0.928 - ETA: 2s - loss: 0.1846 - acc: 0.928 - ETA: 2s - loss: 0.1849 - acc: 0.928 - ETA: 2s - loss: 0.1929 - acc: 0.927 - ETA: 2s - loss: 0.1923 - acc: 0.927 - ETA: 2s - loss: 0.1913 - acc: 0.928 - ETA: 2s - loss: 0.1899 - acc: 0.928 - ETA: 1s - loss: 0.1901 - acc: 0.926 - ETA: 1s - loss: 0.1894 - acc: 0.925 - ETA: 1s - loss: 0.1869 - acc: 0.926 - ETA: 1s - loss: 0.1893 - acc: 0.925 - ETA: 1s - loss: 0.1915 - acc: 0.924 - ETA: 1s - loss: 0.1953 - acc: 0.922 - ETA: 0s - loss: 0.1975 - acc: 0.921 - ETA: 0s - loss: 0.1959 - acc: 0.921 - ETA: 0s - loss: 0.2007 - acc: 0.919 - ETA: 0s - loss: 0.1978 - acc: 0.920 - ETA: 0s - loss: 0.2005 - acc: 0.920 - ETA: 0s - loss: 0.1990 - acc: 0.921 - 8s 5ms/step - loss: 0.1977 - acc: 0.9217 - val_loss: 0.2320 - val_acc: 0.9286\n",
      "Epoch 10/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.1176 - acc: 0.968 - ETA: 7s - loss: 0.1222 - acc: 0.968 - ETA: 7s - loss: 0.1481 - acc: 0.947 - ETA: 6s - loss: 0.1499 - acc: 0.945 - ETA: 6s - loss: 0.1485 - acc: 0.937 - ETA: 6s - loss: 0.1530 - acc: 0.937 - ETA: 6s - loss: 0.1488 - acc: 0.937 - ETA: 6s - loss: 0.1487 - acc: 0.937 - ETA: 6s - loss: 0.1479 - acc: 0.937 - ETA: 6s - loss: 0.1552 - acc: 0.931 - ETA: 6s - loss: 0.1615 - acc: 0.926 - ETA: 6s - loss: 0.1599 - acc: 0.924 - ETA: 5s - loss: 0.1513 - acc: 0.930 - ETA: 5s - loss: 0.1550 - acc: 0.926 - ETA: 5s - loss: 0.1597 - acc: 0.925 - ETA: 5s - loss: 0.1602 - acc: 0.925 - ETA: 5s - loss: 0.1671 - acc: 0.921 - ETA: 5s - loss: 0.1639 - acc: 0.921 - ETA: 4s - loss: 0.1694 - acc: 0.919 - ETA: 4s - loss: 0.1713 - acc: 0.917 - ETA: 4s - loss: 0.1705 - acc: 0.916 - ETA: 4s - loss: 0.1658 - acc: 0.919 - ETA: 4s - loss: 0.1641 - acc: 0.921 - ETA: 4s - loss: 0.1648 - acc: 0.920 - ETA: 3s - loss: 0.1670 - acc: 0.920 - ETA: 3s - loss: 0.1664 - acc: 0.920 - ETA: 3s - loss: 0.1625 - acc: 0.923 - ETA: 3s - loss: 0.1610 - acc: 0.924 - ETA: 3s - loss: 0.1637 - acc: 0.924 - ETA: 3s - loss: 0.1620 - acc: 0.925 - ETA: 3s - loss: 0.1585 - acc: 0.926 - ETA: 2s - loss: 0.1586 - acc: 0.926 - ETA: 2s - loss: 0.1636 - acc: 0.924 - ETA: 2s - loss: 0.1669 - acc: 0.923 - ETA: 2s - loss: 0.1665 - acc: 0.924 - ETA: 2s - loss: 0.1626 - acc: 0.926 - ETA: 2s - loss: 0.1596 - acc: 0.928 - ETA: 1s - loss: 0.1575 - acc: 0.929 - ETA: 1s - loss: 0.1548 - acc: 0.931 - ETA: 1s - loss: 0.1554 - acc: 0.931 - ETA: 1s - loss: 0.1557 - acc: 0.932 - ETA: 1s - loss: 0.1530 - acc: 0.933 - ETA: 1s - loss: 0.1518 - acc: 0.934 - ETA: 0s - loss: 0.1545 - acc: 0.933 - ETA: 0s - loss: 0.1540 - acc: 0.934 - ETA: 0s - loss: 0.1531 - acc: 0.935 - ETA: 0s - loss: 0.1536 - acc: 0.934 - ETA: 0s - loss: 0.1517 - acc: 0.936 - ETA: 0s - loss: 0.1512 - acc: 0.936 - 8s 5ms/step - loss: 0.1507 - acc: 0.9362 - val_loss: 0.1321 - val_acc: 0.9464\n",
      "Epoch 11/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.1964 - acc: 0.937 - ETA: 7s - loss: 0.1792 - acc: 0.937 - ETA: 7s - loss: 0.1707 - acc: 0.937 - ETA: 7s - loss: 0.1435 - acc: 0.953 - ETA: 7s - loss: 0.1838 - acc: 0.937 - ETA: 6s - loss: 0.1805 - acc: 0.937 - ETA: 6s - loss: 0.2142 - acc: 0.928 - ETA: 6s - loss: 0.2013 - acc: 0.929 - ETA: 6s - loss: 0.1902 - acc: 0.934 - ETA: 6s - loss: 0.2138 - acc: 0.921 - ETA: 6s - loss: 0.2029 - acc: 0.926 - ETA: 5s - loss: 0.2030 - acc: 0.924 - ETA: 5s - loss: 0.2030 - acc: 0.925 - ETA: 5s - loss: 0.1965 - acc: 0.928 - ETA: 5s - loss: 0.2017 - acc: 0.927 - ETA: 5s - loss: 0.2006 - acc: 0.925 - ETA: 5s - loss: 0.1950 - acc: 0.928 - ETA: 4s - loss: 0.2001 - acc: 0.923 - ETA: 4s - loss: 0.2073 - acc: 0.921 - ETA: 4s - loss: 0.2114 - acc: 0.918 - ETA: 4s - loss: 0.2078 - acc: 0.919 - ETA: 4s - loss: 0.2149 - acc: 0.914 - ETA: 4s - loss: 0.2099 - acc: 0.915 - ETA: 4s - loss: 0.2059 - acc: 0.916 - ETA: 3s - loss: 0.2051 - acc: 0.916 - ETA: 3s - loss: 0.2074 - acc: 0.915 - ETA: 3s - loss: 0.2054 - acc: 0.917 - ETA: 3s - loss: 0.2007 - acc: 0.919 - ETA: 3s - loss: 0.2008 - acc: 0.921 - ETA: 3s - loss: 0.1993 - acc: 0.921 - ETA: 2s - loss: 0.1980 - acc: 0.923 - ETA: 2s - loss: 0.2045 - acc: 0.922 - ETA: 2s - loss: 0.2037 - acc: 0.923 - ETA: 2s - loss: 0.2046 - acc: 0.922 - ETA: 2s - loss: 0.1997 - acc: 0.925 - ETA: 2s - loss: 0.1973 - acc: 0.926 - ETA: 1s - loss: 0.1974 - acc: 0.926 - ETA: 1s - loss: 0.1963 - acc: 0.926 - ETA: 1s - loss: 0.1932 - acc: 0.927 - ETA: 1s - loss: 0.1906 - acc: 0.928 - ETA: 1s - loss: 0.1897 - acc: 0.928 - ETA: 1s - loss: 0.1906 - acc: 0.927 - ETA: 1s - loss: 0.1914 - acc: 0.926 - ETA: 0s - loss: 0.1921 - acc: 0.926 - ETA: 0s - loss: 0.1929 - acc: 0.925 - ETA: 0s - loss: 0.1920 - acc: 0.926 - ETA: 0s - loss: 0.1956 - acc: 0.923 - ETA: 0s - loss: 0.1965 - acc: 0.923 - ETA: 0s - loss: 0.1970 - acc: 0.924 - 8s 5ms/step - loss: 0.1960 - acc: 0.9249 - val_loss: 0.2188 - val_acc: 0.9464\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 6s - loss: 0.1640 - acc: 0.906 - ETA: 7s - loss: 0.1478 - acc: 0.921 - ETA: 7s - loss: 0.1294 - acc: 0.937 - ETA: 7s - loss: 0.1214 - acc: 0.953 - ETA: 6s - loss: 0.1168 - acc: 0.956 - ETA: 6s - loss: 0.1434 - acc: 0.942 - ETA: 6s - loss: 0.1366 - acc: 0.946 - ETA: 6s - loss: 0.1526 - acc: 0.937 - ETA: 6s - loss: 0.1685 - acc: 0.937 - ETA: 6s - loss: 0.2218 - acc: 0.931 - ETA: 6s - loss: 0.2148 - acc: 0.931 - ETA: 5s - loss: 0.2083 - acc: 0.932 - ETA: 5s - loss: 0.2008 - acc: 0.935 - ETA: 5s - loss: 0.2108 - acc: 0.930 - ETA: 5s - loss: 0.2063 - acc: 0.933 - ETA: 5s - loss: 0.2064 - acc: 0.933 - ETA: 5s - loss: 0.2084 - acc: 0.935 - ETA: 4s - loss: 0.2106 - acc: 0.932 - ETA: 4s - loss: 0.2071 - acc: 0.932 - ETA: 4s - loss: 0.2048 - acc: 0.932 - ETA: 4s - loss: 0.2014 - acc: 0.933 - ETA: 4s - loss: 0.1982 - acc: 0.933 - ETA: 4s - loss: 0.1923 - acc: 0.934 - ETA: 3s - loss: 0.1910 - acc: 0.932 - ETA: 3s - loss: 0.1908 - acc: 0.931 - ETA: 3s - loss: 0.1937 - acc: 0.926 - ETA: 3s - loss: 0.1912 - acc: 0.927 - ETA: 3s - loss: 0.1896 - acc: 0.927 - ETA: 3s - loss: 0.1847 - acc: 0.930 - ETA: 3s - loss: 0.1942 - acc: 0.924 - ETA: 2s - loss: 0.1939 - acc: 0.924 - ETA: 2s - loss: 0.1917 - acc: 0.924 - ETA: 2s - loss: 0.1895 - acc: 0.925 - ETA: 2s - loss: 0.1923 - acc: 0.924 - ETA: 2s - loss: 0.1914 - acc: 0.925 - ETA: 2s - loss: 0.1917 - acc: 0.925 - ETA: 1s - loss: 0.1895 - acc: 0.925 - ETA: 1s - loss: 0.1884 - acc: 0.926 - ETA: 1s - loss: 0.1869 - acc: 0.927 - ETA: 1s - loss: 0.1899 - acc: 0.925 - ETA: 1s - loss: 0.1914 - acc: 0.924 - ETA: 1s - loss: 0.1892 - acc: 0.925 - ETA: 1s - loss: 0.1867 - acc: 0.927 - ETA: 0s - loss: 0.1847 - acc: 0.928 - ETA: 0s - loss: 0.1853 - acc: 0.927 - ETA: 0s - loss: 0.1868 - acc: 0.926 - ETA: 0s - loss: 0.1863 - acc: 0.926 - ETA: 0s - loss: 0.1852 - acc: 0.927 - ETA: 0s - loss: 0.1885 - acc: 0.926 - 8s 5ms/step - loss: 0.1868 - acc: 0.9268 - val_loss: 0.1956 - val_acc: 0.9286\n",
      "Epoch 13/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0630 - acc: 0.968 - ETA: 7s - loss: 0.1662 - acc: 0.890 - ETA: 7s - loss: 0.1540 - acc: 0.906 - ETA: 7s - loss: 0.1671 - acc: 0.914 - ETA: 7s - loss: 0.1681 - acc: 0.912 - ETA: 6s - loss: 0.1729 - acc: 0.911 - ETA: 6s - loss: 0.1908 - acc: 0.906 - ETA: 6s - loss: 0.1740 - acc: 0.918 - ETA: 6s - loss: 0.1688 - acc: 0.920 - ETA: 6s - loss: 0.1806 - acc: 0.918 - ETA: 6s - loss: 0.1765 - acc: 0.920 - ETA: 6s - loss: 0.1734 - acc: 0.921 - ETA: 5s - loss: 0.1794 - acc: 0.915 - ETA: 5s - loss: 0.1810 - acc: 0.915 - ETA: 5s - loss: 0.1762 - acc: 0.916 - ETA: 5s - loss: 0.1680 - acc: 0.921 - ETA: 5s - loss: 0.1651 - acc: 0.922 - ETA: 5s - loss: 0.1713 - acc: 0.920 - ETA: 4s - loss: 0.1752 - acc: 0.919 - ETA: 4s - loss: 0.1695 - acc: 0.923 - ETA: 4s - loss: 0.1649 - acc: 0.925 - ETA: 4s - loss: 0.1652 - acc: 0.927 - ETA: 4s - loss: 0.1768 - acc: 0.925 - ETA: 4s - loss: 0.1720 - acc: 0.927 - ETA: 3s - loss: 0.1699 - acc: 0.927 - ETA: 3s - loss: 0.1652 - acc: 0.930 - ETA: 3s - loss: 0.1704 - acc: 0.927 - ETA: 3s - loss: 0.1703 - acc: 0.928 - ETA: 3s - loss: 0.1742 - acc: 0.926 - ETA: 3s - loss: 0.1779 - acc: 0.927 - ETA: 2s - loss: 0.1750 - acc: 0.927 - ETA: 2s - loss: 0.1724 - acc: 0.927 - ETA: 2s - loss: 0.1744 - acc: 0.926 - ETA: 2s - loss: 0.1703 - acc: 0.928 - ETA: 2s - loss: 0.1681 - acc: 0.929 - ETA: 2s - loss: 0.1696 - acc: 0.928 - ETA: 2s - loss: 0.1677 - acc: 0.929 - ETA: 1s - loss: 0.1655 - acc: 0.929 - ETA: 1s - loss: 0.1650 - acc: 0.929 - ETA: 1s - loss: 0.1616 - acc: 0.931 - ETA: 1s - loss: 0.1639 - acc: 0.930 - ETA: 1s - loss: 0.1606 - acc: 0.932 - ETA: 1s - loss: 0.1702 - acc: 0.932 - ETA: 0s - loss: 0.1697 - acc: 0.932 - ETA: 0s - loss: 0.1671 - acc: 0.934 - ETA: 0s - loss: 0.1676 - acc: 0.934 - ETA: 0s - loss: 0.1647 - acc: 0.935 - ETA: 0s - loss: 0.1644 - acc: 0.936 - ETA: 0s - loss: 0.1654 - acc: 0.935 - 8s 5ms/step - loss: 0.1644 - acc: 0.9362 - val_loss: 0.2729 - val_acc: 0.9107\n",
      "Epoch 14/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.2021 - acc: 0.937 - ETA: 7s - loss: 0.1401 - acc: 0.937 - ETA: 7s - loss: 0.2979 - acc: 0.937 - ETA: 7s - loss: 0.2627 - acc: 0.937 - ETA: 7s - loss: 0.2419 - acc: 0.931 - ETA: 7s - loss: 0.2504 - acc: 0.927 - ETA: 7s - loss: 0.2261 - acc: 0.933 - ETA: 6s - loss: 0.2060 - acc: 0.937 - ETA: 6s - loss: 0.1896 - acc: 0.944 - ETA: 6s - loss: 0.1730 - acc: 0.950 - ETA: 6s - loss: 0.1771 - acc: 0.943 - ETA: 6s - loss: 0.1736 - acc: 0.942 - ETA: 6s - loss: 0.1805 - acc: 0.942 - ETA: 5s - loss: 0.1690 - acc: 0.946 - ETA: 5s - loss: 0.1694 - acc: 0.945 - ETA: 5s - loss: 0.1629 - acc: 0.947 - ETA: 5s - loss: 0.1615 - acc: 0.948 - ETA: 5s - loss: 0.1575 - acc: 0.949 - ETA: 5s - loss: 0.1511 - acc: 0.952 - ETA: 4s - loss: 0.1564 - acc: 0.951 - ETA: 4s - loss: 0.1562 - acc: 0.952 - ETA: 4s - loss: 0.1553 - acc: 0.951 - ETA: 4s - loss: 0.1560 - acc: 0.951 - ETA: 4s - loss: 0.1553 - acc: 0.950 - ETA: 4s - loss: 0.1574 - acc: 0.948 - ETA: 3s - loss: 0.1541 - acc: 0.949 - ETA: 3s - loss: 0.1599 - acc: 0.947 - ETA: 3s - loss: 0.1595 - acc: 0.948 - ETA: 3s - loss: 0.1559 - acc: 0.949 - ETA: 3s - loss: 0.1522 - acc: 0.950 - ETA: 3s - loss: 0.1504 - acc: 0.950 - ETA: 2s - loss: 0.1572 - acc: 0.948 - ETA: 2s - loss: 0.1575 - acc: 0.947 - ETA: 2s - loss: 0.1552 - acc: 0.947 - ETA: 2s - loss: 0.1566 - acc: 0.946 - ETA: 2s - loss: 0.1562 - acc: 0.947 - ETA: 2s - loss: 0.1571 - acc: 0.946 - ETA: 1s - loss: 0.1591 - acc: 0.945 - ETA: 1s - loss: 0.1577 - acc: 0.946 - ETA: 1s - loss: 0.1567 - acc: 0.946 - ETA: 1s - loss: 0.1569 - acc: 0.946 - ETA: 1s - loss: 0.1591 - acc: 0.945 - ETA: 1s - loss: 0.1598 - acc: 0.944 - ETA: 0s - loss: 0.1598 - acc: 0.945 - ETA: 0s - loss: 0.1591 - acc: 0.945 - ETA: 0s - loss: 0.1634 - acc: 0.943 - ETA: 0s - loss: 0.1640 - acc: 0.942 - ETA: 0s - loss: 0.1644 - acc: 0.941 - ETA: 0s - loss: 0.1636 - acc: 0.942 - 9s 5ms/step - loss: 0.1644 - acc: 0.9407 - val_loss: 0.1651 - val_acc: 0.9107\n",
      "Epoch 15/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.1936 - acc: 0.906 - ETA: 7s - loss: 0.1895 - acc: 0.906 - ETA: 7s - loss: 0.1658 - acc: 0.927 - ETA: 7s - loss: 0.1487 - acc: 0.945 - ETA: 7s - loss: 0.1490 - acc: 0.950 - ETA: 7s - loss: 0.1483 - acc: 0.953 - ETA: 7s - loss: 0.1376 - acc: 0.955 - ETA: 6s - loss: 0.1400 - acc: 0.953 - ETA: 6s - loss: 0.1424 - acc: 0.951 - ETA: 6s - loss: 0.1945 - acc: 0.950 - ETA: 6s - loss: 0.1846 - acc: 0.948 - ETA: 6s - loss: 0.1912 - acc: 0.947 - ETA: 6s - loss: 0.1870 - acc: 0.949 - ETA: 6s - loss: 0.1813 - acc: 0.950 - ETA: 6s - loss: 0.1826 - acc: 0.950 - ETA: 5s - loss: 0.1748 - acc: 0.951 - ETA: 5s - loss: 0.1781 - acc: 0.950 - ETA: 5s - loss: 0.1738 - acc: 0.951 - ETA: 5s - loss: 0.1675 - acc: 0.952 - ETA: 5s - loss: 0.1690 - acc: 0.950 - ETA: 5s - loss: 0.1669 - acc: 0.949 - ETA: 5s - loss: 0.1711 - acc: 0.946 - ETA: 4s - loss: 0.1724 - acc: 0.945 - ETA: 4s - loss: 0.1711 - acc: 0.944 - ETA: 4s - loss: 0.1677 - acc: 0.945 - ETA: 4s - loss: 0.1699 - acc: 0.944 - ETA: 4s - loss: 0.1814 - acc: 0.939 - ETA: 3s - loss: 0.1835 - acc: 0.938 - ETA: 3s - loss: 0.1791 - acc: 0.940 - ETA: 3s - loss: 0.1763 - acc: 0.941 - ETA: 3s - loss: 0.1813 - acc: 0.942 - ETA: 3s - loss: 0.1774 - acc: 0.944 - ETA: 3s - loss: 0.1780 - acc: 0.942 - ETA: 2s - loss: 0.1772 - acc: 0.943 - ETA: 2s - loss: 0.1794 - acc: 0.941 - ETA: 2s - loss: 0.1784 - acc: 0.941 - ETA: 2s - loss: 0.1779 - acc: 0.940 - ETA: 2s - loss: 0.1753 - acc: 0.940 - ETA: 1s - loss: 0.1735 - acc: 0.941 - ETA: 1s - loss: 0.1724 - acc: 0.941 - ETA: 1s - loss: 0.1714 - acc: 0.941 - ETA: 1s - loss: 0.1703 - acc: 0.941 - ETA: 1s - loss: 0.1677 - acc: 0.942 - ETA: 1s - loss: 0.1664 - acc: 0.942 - ETA: 0s - loss: 0.1650 - acc: 0.943 - ETA: 0s - loss: 0.1633 - acc: 0.943 - ETA: 0s - loss: 0.1631 - acc: 0.943 - ETA: 0s - loss: 0.1622 - acc: 0.944 - ETA: 0s - loss: 0.1649 - acc: 0.943 - 9s 6ms/step - loss: 0.1641 - acc: 0.9432 - val_loss: 0.0908 - val_acc: 0.9643\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 9s - loss: 0.1827 - acc: 0.906 - ETA: 9s - loss: 0.1676 - acc: 0.921 - ETA: 8s - loss: 0.1212 - acc: 0.947 - ETA: 8s - loss: 0.1318 - acc: 0.937 - ETA: 8s - loss: 0.1220 - acc: 0.937 - ETA: 7s - loss: 0.1052 - acc: 0.947 - ETA: 7s - loss: 0.0930 - acc: 0.955 - ETA: 7s - loss: 0.0932 - acc: 0.953 - ETA: 7s - loss: 0.1011 - acc: 0.954 - ETA: 7s - loss: 0.1119 - acc: 0.953 - ETA: 7s - loss: 0.1104 - acc: 0.951 - ETA: 8s - loss: 0.1207 - acc: 0.945 - ETA: 7s - loss: 0.1172 - acc: 0.947 - ETA: 7s - loss: 0.1207 - acc: 0.942 - ETA: 7s - loss: 0.1207 - acc: 0.941 - ETA: 7s - loss: 0.1225 - acc: 0.941 - ETA: 6s - loss: 0.1298 - acc: 0.939 - ETA: 6s - loss: 0.1389 - acc: 0.935 - ETA: 6s - loss: 0.1383 - acc: 0.934 - ETA: 5s - loss: 0.1374 - acc: 0.934 - ETA: 5s - loss: 0.1368 - acc: 0.933 - ETA: 5s - loss: 0.1356 - acc: 0.933 - ETA: 5s - loss: 0.1327 - acc: 0.934 - ETA: 5s - loss: 0.1422 - acc: 0.931 - ETA: 4s - loss: 0.1382 - acc: 0.933 - ETA: 4s - loss: 0.1389 - acc: 0.933 - ETA: 4s - loss: 0.1408 - acc: 0.932 - ETA: 4s - loss: 0.1381 - acc: 0.934 - ETA: 3s - loss: 0.1374 - acc: 0.935 - ETA: 3s - loss: 0.1458 - acc: 0.931 - ETA: 3s - loss: 0.1459 - acc: 0.931 - ETA: 3s - loss: 0.1455 - acc: 0.932 - ETA: 3s - loss: 0.1446 - acc: 0.932 - ETA: 2s - loss: 0.1438 - acc: 0.932 - ETA: 2s - loss: 0.1420 - acc: 0.933 - ETA: 2s - loss: 0.1421 - acc: 0.933 - ETA: 2s - loss: 0.1478 - acc: 0.931 - ETA: 2s - loss: 0.1457 - acc: 0.933 - ETA: 1s - loss: 0.1503 - acc: 0.931 - ETA: 1s - loss: 0.1476 - acc: 0.933 - ETA: 1s - loss: 0.1530 - acc: 0.932 - ETA: 1s - loss: 0.1514 - acc: 0.933 - ETA: 1s - loss: 0.1494 - acc: 0.935 - ETA: 0s - loss: 0.1534 - acc: 0.935 - ETA: 0s - loss: 0.1670 - acc: 0.933 - ETA: 0s - loss: 0.1661 - acc: 0.933 - ETA: 0s - loss: 0.1645 - acc: 0.934 - ETA: 0s - loss: 0.1634 - acc: 0.935 - ETA: 0s - loss: 0.1614 - acc: 0.936 - 9s 6ms/step - loss: 0.1599 - acc: 0.9375 - val_loss: 0.1607 - val_acc: 0.9643\n",
      "Epoch 17/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.1287 - acc: 0.937 - ETA: 7s - loss: 0.1298 - acc: 0.921 - ETA: 7s - loss: 0.0990 - acc: 0.937 - ETA: 7s - loss: 0.0766 - acc: 0.953 - ETA: 7s - loss: 0.1015 - acc: 0.950 - ETA: 7s - loss: 0.1018 - acc: 0.947 - ETA: 7s - loss: 0.1191 - acc: 0.946 - ETA: 6s - loss: 0.1156 - acc: 0.949 - ETA: 6s - loss: 0.1116 - acc: 0.954 - ETA: 6s - loss: 0.1124 - acc: 0.953 - ETA: 6s - loss: 0.1212 - acc: 0.951 - ETA: 6s - loss: 0.1130 - acc: 0.955 - ETA: 5s - loss: 0.1085 - acc: 0.959 - ETA: 5s - loss: 0.1044 - acc: 0.962 - ETA: 5s - loss: 0.1003 - acc: 0.964 - ETA: 5s - loss: 0.1068 - acc: 0.960 - ETA: 5s - loss: 0.1104 - acc: 0.959 - ETA: 5s - loss: 0.1129 - acc: 0.960 - ETA: 4s - loss: 0.1113 - acc: 0.962 - ETA: 4s - loss: 0.1129 - acc: 0.962 - ETA: 4s - loss: 0.1092 - acc: 0.964 - ETA: 4s - loss: 0.1099 - acc: 0.963 - ETA: 4s - loss: 0.1064 - acc: 0.964 - ETA: 4s - loss: 0.1034 - acc: 0.966 - ETA: 3s - loss: 0.1025 - acc: 0.966 - ETA: 3s - loss: 0.1040 - acc: 0.966 - ETA: 3s - loss: 0.1077 - acc: 0.965 - ETA: 3s - loss: 0.1049 - acc: 0.966 - ETA: 3s - loss: 0.1049 - acc: 0.965 - ETA: 3s - loss: 0.1049 - acc: 0.965 - ETA: 3s - loss: 0.1144 - acc: 0.962 - ETA: 2s - loss: 0.1183 - acc: 0.960 - ETA: 2s - loss: 0.1216 - acc: 0.957 - ETA: 2s - loss: 0.1271 - acc: 0.956 - ETA: 2s - loss: 0.1271 - acc: 0.956 - ETA: 2s - loss: 0.1260 - acc: 0.957 - ETA: 2s - loss: 0.1253 - acc: 0.958 - ETA: 1s - loss: 0.1248 - acc: 0.958 - ETA: 1s - loss: 0.1279 - acc: 0.955 - ETA: 1s - loss: 0.1318 - acc: 0.954 - ETA: 1s - loss: 0.1340 - acc: 0.952 - ETA: 1s - loss: 0.1330 - acc: 0.953 - ETA: 1s - loss: 0.1348 - acc: 0.952 - ETA: 0s - loss: 0.1335 - acc: 0.953 - ETA: 0s - loss: 0.1331 - acc: 0.953 - ETA: 0s - loss: 0.1333 - acc: 0.953 - ETA: 0s - loss: 0.1348 - acc: 0.952 - ETA: 0s - loss: 0.1331 - acc: 0.953 - ETA: 0s - loss: 0.1341 - acc: 0.954 - 8s 5ms/step - loss: 0.1348 - acc: 0.9533 - val_loss: 0.1604 - val_acc: 0.9643\n",
      "Epoch 18/50\n",
      "1584/1584 [==============================] - ETA: 6s - loss: 0.1173 - acc: 0.937 - ETA: 6s - loss: 0.1130 - acc: 0.937 - ETA: 7s - loss: 0.1276 - acc: 0.927 - ETA: 7s - loss: 0.1189 - acc: 0.945 - ETA: 6s - loss: 0.1187 - acc: 0.950 - ETA: 6s - loss: 0.1072 - acc: 0.958 - ETA: 6s - loss: 0.0994 - acc: 0.964 - ETA: 6s - loss: 0.0878 - acc: 0.968 - ETA: 6s - loss: 0.0835 - acc: 0.968 - ETA: 6s - loss: 0.0770 - acc: 0.971 - ETA: 6s - loss: 0.0983 - acc: 0.963 - ETA: 5s - loss: 0.1027 - acc: 0.958 - ETA: 5s - loss: 0.1030 - acc: 0.959 - ETA: 5s - loss: 0.1003 - acc: 0.959 - ETA: 5s - loss: 0.0967 - acc: 0.962 - ETA: 5s - loss: 0.0915 - acc: 0.964 - ETA: 5s - loss: 0.0914 - acc: 0.963 - ETA: 5s - loss: 0.0874 - acc: 0.965 - ETA: 4s - loss: 0.0892 - acc: 0.963 - ETA: 4s - loss: 0.0874 - acc: 0.964 - ETA: 4s - loss: 0.0886 - acc: 0.962 - ETA: 4s - loss: 0.0906 - acc: 0.961 - ETA: 4s - loss: 0.0926 - acc: 0.960 - ETA: 4s - loss: 0.0942 - acc: 0.960 - ETA: 3s - loss: 0.0913 - acc: 0.962 - ETA: 3s - loss: 0.0997 - acc: 0.961 - ETA: 3s - loss: 0.1022 - acc: 0.959 - ETA: 3s - loss: 0.0995 - acc: 0.960 - ETA: 3s - loss: 0.0971 - acc: 0.961 - ETA: 3s - loss: 0.1000 - acc: 0.959 - ETA: 2s - loss: 0.0974 - acc: 0.960 - ETA: 2s - loss: 0.0995 - acc: 0.959 - ETA: 2s - loss: 0.1003 - acc: 0.959 - ETA: 2s - loss: 0.1018 - acc: 0.957 - ETA: 2s - loss: 0.1013 - acc: 0.958 - ETA: 2s - loss: 0.1053 - acc: 0.955 - ETA: 2s - loss: 0.1062 - acc: 0.955 - ETA: 1s - loss: 0.1083 - acc: 0.955 - ETA: 1s - loss: 0.1089 - acc: 0.955 - ETA: 1s - loss: 0.1083 - acc: 0.955 - ETA: 1s - loss: 0.1083 - acc: 0.955 - ETA: 1s - loss: 0.1085 - acc: 0.956 - ETA: 1s - loss: 0.1194 - acc: 0.954 - ETA: 0s - loss: 0.1180 - acc: 0.955 - ETA: 0s - loss: 0.1202 - acc: 0.954 - ETA: 0s - loss: 0.1183 - acc: 0.955 - ETA: 0s - loss: 0.1202 - acc: 0.956 - ETA: 0s - loss: 0.1217 - acc: 0.956 - ETA: 0s - loss: 0.1222 - acc: 0.956 - 8s 5ms/step - loss: 0.1217 - acc: 0.9564 - val_loss: 0.1602 - val_acc: 0.9643\n",
      "Epoch 19/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.1343 - acc: 0.937 - ETA: 8s - loss: 0.0959 - acc: 0.968 - ETA: 8s - loss: 0.1184 - acc: 0.937 - ETA: 8s - loss: 0.1150 - acc: 0.945 - ETA: 7s - loss: 0.1051 - acc: 0.956 - ETA: 7s - loss: 0.0968 - acc: 0.963 - ETA: 7s - loss: 0.0936 - acc: 0.964 - ETA: 7s - loss: 0.1047 - acc: 0.964 - ETA: 6s - loss: 0.0956 - acc: 0.968 - ETA: 6s - loss: 0.0998 - acc: 0.962 - ETA: 6s - loss: 0.0950 - acc: 0.965 - ETA: 6s - loss: 0.0959 - acc: 0.963 - ETA: 6s - loss: 0.0967 - acc: 0.963 - ETA: 6s - loss: 0.0957 - acc: 0.964 - ETA: 6s - loss: 0.0936 - acc: 0.962 - ETA: 5s - loss: 0.0957 - acc: 0.960 - ETA: 5s - loss: 0.0929 - acc: 0.963 - ETA: 5s - loss: 0.0917 - acc: 0.961 - ETA: 5s - loss: 0.0965 - acc: 0.958 - ETA: 5s - loss: 0.1106 - acc: 0.953 - ETA: 4s - loss: 0.1136 - acc: 0.950 - ETA: 4s - loss: 0.1130 - acc: 0.950 - ETA: 4s - loss: 0.1131 - acc: 0.951 - ETA: 4s - loss: 0.1113 - acc: 0.951 - ETA: 4s - loss: 0.1113 - acc: 0.951 - ETA: 4s - loss: 0.1231 - acc: 0.949 - ETA: 3s - loss: 0.1221 - acc: 0.950 - ETA: 3s - loss: 0.1186 - acc: 0.952 - ETA: 3s - loss: 0.1162 - acc: 0.953 - ETA: 3s - loss: 0.1146 - acc: 0.954 - ETA: 3s - loss: 0.1120 - acc: 0.955 - ETA: 3s - loss: 0.1116 - acc: 0.955 - ETA: 2s - loss: 0.1152 - acc: 0.952 - ETA: 2s - loss: 0.1122 - acc: 0.954 - ETA: 2s - loss: 0.1114 - acc: 0.954 - ETA: 2s - loss: 0.1088 - acc: 0.955 - ETA: 2s - loss: 0.1080 - acc: 0.956 - ETA: 1s - loss: 0.1084 - acc: 0.956 - ETA: 1s - loss: 0.1062 - acc: 0.957 - ETA: 1s - loss: 0.1059 - acc: 0.957 - ETA: 1s - loss: 0.1059 - acc: 0.958 - ETA: 1s - loss: 0.1082 - acc: 0.957 - ETA: 1s - loss: 0.1086 - acc: 0.957 - ETA: 0s - loss: 0.1065 - acc: 0.958 - ETA: 0s - loss: 0.1049 - acc: 0.959 - ETA: 0s - loss: 0.1027 - acc: 0.959 - ETA: 0s - loss: 0.1035 - acc: 0.960 - ETA: 0s - loss: 0.1106 - acc: 0.958 - ETA: 0s - loss: 0.1089 - acc: 0.959 - 8s 5ms/step - loss: 0.1080 - acc: 0.9596 - val_loss: 0.3160 - val_acc: 0.9464\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0750 - acc: 0.968 - ETA: 7s - loss: 0.1382 - acc: 0.937 - ETA: 7s - loss: 0.1026 - acc: 0.958 - ETA: 7s - loss: 0.0896 - acc: 0.968 - ETA: 7s - loss: 0.1319 - acc: 0.950 - ETA: 7s - loss: 0.1183 - acc: 0.953 - ETA: 7s - loss: 0.1051 - acc: 0.959 - ETA: 6s - loss: 0.1106 - acc: 0.957 - ETA: 6s - loss: 0.1045 - acc: 0.958 - ETA: 6s - loss: 0.1031 - acc: 0.956 - ETA: 6s - loss: 0.1028 - acc: 0.954 - ETA: 6s - loss: 0.1008 - acc: 0.955 - ETA: 5s - loss: 0.1025 - acc: 0.951 - ETA: 5s - loss: 0.0977 - acc: 0.955 - ETA: 5s - loss: 0.1003 - acc: 0.954 - ETA: 5s - loss: 0.0976 - acc: 0.955 - ETA: 5s - loss: 0.0938 - acc: 0.957 - ETA: 5s - loss: 0.0944 - acc: 0.958 - ETA: 4s - loss: 0.0946 - acc: 0.958 - ETA: 4s - loss: 0.0943 - acc: 0.957 - ETA: 4s - loss: 0.0911 - acc: 0.959 - ETA: 4s - loss: 0.0895 - acc: 0.960 - ETA: 4s - loss: 0.0938 - acc: 0.959 - ETA: 4s - loss: 0.0962 - acc: 0.957 - ETA: 3s - loss: 0.0961 - acc: 0.957 - ETA: 3s - loss: 0.0964 - acc: 0.957 - ETA: 3s - loss: 0.0935 - acc: 0.959 - ETA: 3s - loss: 0.0911 - acc: 0.960 - ETA: 3s - loss: 0.0892 - acc: 0.962 - ETA: 3s - loss: 0.0914 - acc: 0.959 - ETA: 3s - loss: 0.0887 - acc: 0.960 - ETA: 2s - loss: 0.0906 - acc: 0.960 - ETA: 2s - loss: 0.0898 - acc: 0.960 - ETA: 2s - loss: 0.0880 - acc: 0.961 - ETA: 2s - loss: 0.0939 - acc: 0.959 - ETA: 2s - loss: 0.0939 - acc: 0.960 - ETA: 2s - loss: 0.0984 - acc: 0.957 - ETA: 1s - loss: 0.0976 - acc: 0.958 - ETA: 1s - loss: 0.0995 - acc: 0.956 - ETA: 1s - loss: 0.1018 - acc: 0.956 - ETA: 1s - loss: 0.0997 - acc: 0.957 - ETA: 1s - loss: 0.1014 - acc: 0.956 - ETA: 1s - loss: 0.1000 - acc: 0.956 - ETA: 0s - loss: 0.1012 - acc: 0.956 - ETA: 0s - loss: 0.0993 - acc: 0.956 - ETA: 0s - loss: 0.1002 - acc: 0.955 - ETA: 0s - loss: 0.0985 - acc: 0.956 - ETA: 0s - loss: 0.0988 - acc: 0.957 - ETA: 0s - loss: 0.0976 - acc: 0.957 - 8s 5ms/step - loss: 0.0972 - acc: 0.9577 - val_loss: 0.2329 - val_acc: 0.9464\n",
      "Epoch 21/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0518 - acc: 0.968 - ETA: 7s - loss: 0.0502 - acc: 0.968 - ETA: 7s - loss: 0.0527 - acc: 0.968 - ETA: 8s - loss: 0.0666 - acc: 0.968 - ETA: 8s - loss: 0.0622 - acc: 0.975 - ETA: 7s - loss: 0.0541 - acc: 0.979 - ETA: 7s - loss: 0.0517 - acc: 0.982 - ETA: 7s - loss: 0.0523 - acc: 0.980 - ETA: 7s - loss: 0.0503 - acc: 0.982 - ETA: 7s - loss: 0.0509 - acc: 0.981 - ETA: 7s - loss: 0.0501 - acc: 0.983 - ETA: 7s - loss: 0.0535 - acc: 0.981 - ETA: 6s - loss: 0.0539 - acc: 0.980 - ETA: 6s - loss: 0.0521 - acc: 0.982 - ETA: 6s - loss: 0.0499 - acc: 0.983 - ETA: 6s - loss: 0.0549 - acc: 0.982 - ETA: 5s - loss: 0.0584 - acc: 0.981 - ETA: 5s - loss: 0.0575 - acc: 0.980 - ETA: 5s - loss: 0.0602 - acc: 0.978 - ETA: 5s - loss: 0.0626 - acc: 0.978 - ETA: 5s - loss: 0.0609 - acc: 0.979 - ETA: 4s - loss: 0.0707 - acc: 0.977 - ETA: 4s - loss: 0.0800 - acc: 0.974 - ETA: 4s - loss: 0.0836 - acc: 0.971 - ETA: 4s - loss: 0.0888 - acc: 0.970 - ETA: 4s - loss: 0.0862 - acc: 0.971 - ETA: 3s - loss: 0.0895 - acc: 0.968 - ETA: 3s - loss: 0.0918 - acc: 0.967 - ETA: 3s - loss: 0.0923 - acc: 0.967 - ETA: 3s - loss: 0.0951 - acc: 0.966 - ETA: 3s - loss: 0.0950 - acc: 0.966 - ETA: 3s - loss: 0.0977 - acc: 0.965 - ETA: 2s - loss: 0.0957 - acc: 0.966 - ETA: 2s - loss: 0.0992 - acc: 0.966 - ETA: 2s - loss: 0.1029 - acc: 0.964 - ETA: 2s - loss: 0.1041 - acc: 0.964 - ETA: 2s - loss: 0.1035 - acc: 0.964 - ETA: 1s - loss: 0.1028 - acc: 0.963 - ETA: 1s - loss: 0.1020 - acc: 0.963 - ETA: 1s - loss: 0.1008 - acc: 0.964 - ETA: 1s - loss: 0.1010 - acc: 0.963 - ETA: 1s - loss: 0.0999 - acc: 0.963 - ETA: 1s - loss: 0.0981 - acc: 0.964 - ETA: 0s - loss: 0.0972 - acc: 0.965 - ETA: 0s - loss: 0.0968 - acc: 0.966 - ETA: 0s - loss: 0.0962 - acc: 0.966 - ETA: 0s - loss: 0.0967 - acc: 0.966 - ETA: 0s - loss: 0.0972 - acc: 0.965 - ETA: 0s - loss: 0.0988 - acc: 0.964 - 9s 5ms/step - loss: 0.0996 - acc: 0.9646 - val_loss: 0.1756 - val_acc: 0.9464\n",
      "Epoch 22/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0139 - acc: 1.000 - ETA: 7s - loss: 0.0224 - acc: 1.000 - ETA: 7s - loss: 0.0553 - acc: 0.968 - ETA: 7s - loss: 0.0876 - acc: 0.953 - ETA: 7s - loss: 0.0768 - acc: 0.962 - ETA: 7s - loss: 0.0678 - acc: 0.968 - ETA: 7s - loss: 0.0758 - acc: 0.968 - ETA: 6s - loss: 0.0846 - acc: 0.964 - ETA: 6s - loss: 0.0882 - acc: 0.961 - ETA: 6s - loss: 0.0823 - acc: 0.965 - ETA: 6s - loss: 0.0802 - acc: 0.965 - ETA: 6s - loss: 0.0754 - acc: 0.968 - ETA: 6s - loss: 0.0814 - acc: 0.968 - ETA: 6s - loss: 0.0839 - acc: 0.966 - ETA: 6s - loss: 0.0860 - acc: 0.966 - ETA: 6s - loss: 0.0863 - acc: 0.964 - ETA: 6s - loss: 0.0993 - acc: 0.965 - ETA: 6s - loss: 0.0946 - acc: 0.967 - ETA: 5s - loss: 0.0942 - acc: 0.967 - ETA: 5s - loss: 0.0908 - acc: 0.968 - ETA: 5s - loss: 0.0895 - acc: 0.968 - ETA: 5s - loss: 0.0925 - acc: 0.964 - ETA: 5s - loss: 0.0917 - acc: 0.963 - ETA: 4s - loss: 0.1002 - acc: 0.962 - ETA: 4s - loss: 0.0991 - acc: 0.962 - ETA: 4s - loss: 0.1017 - acc: 0.961 - ETA: 4s - loss: 0.0997 - acc: 0.961 - ETA: 4s - loss: 0.1010 - acc: 0.962 - ETA: 3s - loss: 0.0994 - acc: 0.962 - ETA: 3s - loss: 0.0980 - acc: 0.962 - ETA: 3s - loss: 0.0979 - acc: 0.961 - ETA: 3s - loss: 0.0975 - acc: 0.961 - ETA: 3s - loss: 0.0987 - acc: 0.961 - ETA: 2s - loss: 0.0992 - acc: 0.960 - ETA: 2s - loss: 0.0988 - acc: 0.960 - ETA: 2s - loss: 0.0985 - acc: 0.960 - ETA: 2s - loss: 0.0971 - acc: 0.962 - ETA: 2s - loss: 0.0967 - acc: 0.962 - ETA: 1s - loss: 0.0955 - acc: 0.963 - ETA: 1s - loss: 0.0998 - acc: 0.960 - ETA: 1s - loss: 0.0993 - acc: 0.960 - ETA: 1s - loss: 0.0977 - acc: 0.960 - ETA: 1s - loss: 0.0989 - acc: 0.960 - ETA: 0s - loss: 0.0984 - acc: 0.959 - ETA: 0s - loss: 0.0987 - acc: 0.959 - ETA: 0s - loss: 0.0981 - acc: 0.959 - ETA: 0s - loss: 0.1000 - acc: 0.959 - ETA: 0s - loss: 0.1049 - acc: 0.957 - ETA: 0s - loss: 0.1043 - acc: 0.957 - 9s 6ms/step - loss: 0.1043 - acc: 0.9577 - val_loss: 0.1094 - val_acc: 0.9643\n",
      "Epoch 23/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0857 - acc: 0.968 - ETA: 7s - loss: 0.1085 - acc: 0.953 - ETA: 7s - loss: 0.1217 - acc: 0.958 - ETA: 7s - loss: 0.1278 - acc: 0.937 - ETA: 7s - loss: 0.1141 - acc: 0.950 - ETA: 7s - loss: 0.1051 - acc: 0.958 - ETA: 7s - loss: 0.1077 - acc: 0.955 - ETA: 7s - loss: 0.0982 - acc: 0.960 - ETA: 7s - loss: 0.1116 - acc: 0.951 - ETA: 6s - loss: 0.1119 - acc: 0.950 - ETA: 6s - loss: 0.1044 - acc: 0.954 - ETA: 6s - loss: 0.1004 - acc: 0.955 - ETA: 6s - loss: 0.0934 - acc: 0.959 - ETA: 6s - loss: 0.0949 - acc: 0.959 - ETA: 6s - loss: 0.0948 - acc: 0.960 - ETA: 6s - loss: 0.0935 - acc: 0.960 - ETA: 5s - loss: 0.0907 - acc: 0.963 - ETA: 5s - loss: 0.0917 - acc: 0.961 - ETA: 5s - loss: 0.0931 - acc: 0.958 - ETA: 5s - loss: 0.0959 - acc: 0.956 - ETA: 5s - loss: 0.0989 - acc: 0.956 - ETA: 4s - loss: 0.0983 - acc: 0.957 - ETA: 4s - loss: 0.0969 - acc: 0.957 - ETA: 4s - loss: 0.1050 - acc: 0.951 - ETA: 4s - loss: 0.1054 - acc: 0.951 - ETA: 4s - loss: 0.1030 - acc: 0.951 - ETA: 3s - loss: 0.1013 - acc: 0.952 - ETA: 3s - loss: 0.1024 - acc: 0.952 - ETA: 3s - loss: 0.0991 - acc: 0.953 - ETA: 3s - loss: 0.0997 - acc: 0.954 - ETA: 3s - loss: 0.0987 - acc: 0.953 - ETA: 3s - loss: 0.0986 - acc: 0.953 - ETA: 2s - loss: 0.0964 - acc: 0.954 - ETA: 2s - loss: 0.0968 - acc: 0.955 - ETA: 2s - loss: 0.0953 - acc: 0.956 - ETA: 2s - loss: 0.0948 - acc: 0.956 - ETA: 2s - loss: 0.0934 - acc: 0.957 - ETA: 2s - loss: 0.0921 - acc: 0.958 - ETA: 1s - loss: 0.0911 - acc: 0.959 - ETA: 1s - loss: 0.0930 - acc: 0.958 - ETA: 1s - loss: 0.0957 - acc: 0.958 - ETA: 1s - loss: 0.1008 - acc: 0.956 - ETA: 1s - loss: 0.0996 - acc: 0.956 - ETA: 1s - loss: 0.0983 - acc: 0.957 - ETA: 0s - loss: 0.0989 - acc: 0.956 - ETA: 0s - loss: 0.0991 - acc: 0.957 - ETA: 0s - loss: 0.1036 - acc: 0.956 - ETA: 0s - loss: 0.1035 - acc: 0.956 - ETA: 0s - loss: 0.1038 - acc: 0.956 - 9s 6ms/step - loss: 0.1029 - acc: 0.9571 - val_loss: 0.1346 - val_acc: 0.9286\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 8s - loss: 0.1490 - acc: 0.937 - ETA: 7s - loss: 0.1282 - acc: 0.937 - ETA: 7s - loss: 0.1421 - acc: 0.947 - ETA: 7s - loss: 0.1156 - acc: 0.953 - ETA: 7s - loss: 0.0986 - acc: 0.962 - ETA: 7s - loss: 0.0894 - acc: 0.968 - ETA: 7s - loss: 0.0826 - acc: 0.968 - ETA: 7s - loss: 0.0804 - acc: 0.972 - ETA: 6s - loss: 0.0860 - acc: 0.968 - ETA: 6s - loss: 0.0810 - acc: 0.971 - ETA: 6s - loss: 0.0830 - acc: 0.971 - ETA: 6s - loss: 0.0874 - acc: 0.968 - ETA: 6s - loss: 0.0928 - acc: 0.968 - ETA: 5s - loss: 0.0959 - acc: 0.964 - ETA: 5s - loss: 0.0948 - acc: 0.964 - ETA: 5s - loss: 0.0936 - acc: 0.964 - ETA: 5s - loss: 0.0924 - acc: 0.966 - ETA: 5s - loss: 0.1020 - acc: 0.967 - ETA: 5s - loss: 0.0989 - acc: 0.968 - ETA: 4s - loss: 0.0977 - acc: 0.970 - ETA: 4s - loss: 0.0981 - acc: 0.970 - ETA: 4s - loss: 0.0967 - acc: 0.970 - ETA: 4s - loss: 0.0947 - acc: 0.970 - ETA: 4s - loss: 0.0930 - acc: 0.970 - ETA: 4s - loss: 0.0898 - acc: 0.971 - ETA: 3s - loss: 0.0886 - acc: 0.971 - ETA: 3s - loss: 0.0869 - acc: 0.972 - ETA: 3s - loss: 0.0859 - acc: 0.972 - ETA: 3s - loss: 0.0842 - acc: 0.973 - ETA: 3s - loss: 0.1050 - acc: 0.970 - ETA: 3s - loss: 0.1059 - acc: 0.968 - ETA: 2s - loss: 0.1029 - acc: 0.969 - ETA: 2s - loss: 0.1021 - acc: 0.969 - ETA: 2s - loss: 0.1015 - acc: 0.968 - ETA: 2s - loss: 0.1037 - acc: 0.967 - ETA: 2s - loss: 0.1033 - acc: 0.967 - ETA: 2s - loss: 0.1031 - acc: 0.966 - ETA: 1s - loss: 0.1054 - acc: 0.965 - ETA: 1s - loss: 0.1040 - acc: 0.966 - ETA: 1s - loss: 0.1037 - acc: 0.966 - ETA: 1s - loss: 0.1033 - acc: 0.966 - ETA: 1s - loss: 0.1016 - acc: 0.967 - ETA: 1s - loss: 0.1010 - acc: 0.967 - ETA: 0s - loss: 0.1011 - acc: 0.967 - ETA: 0s - loss: 0.0993 - acc: 0.968 - ETA: 0s - loss: 0.0997 - acc: 0.968 - ETA: 0s - loss: 0.0985 - acc: 0.968 - ETA: 0s - loss: 0.0980 - acc: 0.968 - ETA: 0s - loss: 0.0998 - acc: 0.968 - 9s 5ms/step - loss: 0.1020 - acc: 0.9678 - val_loss: 0.1775 - val_acc: 0.9643\n",
      "Epoch 25/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0626 - acc: 0.968 - ETA: 7s - loss: 0.1306 - acc: 0.953 - ETA: 7s - loss: 0.1808 - acc: 0.927 - ETA: 7s - loss: 0.1476 - acc: 0.937 - ETA: 7s - loss: 0.1557 - acc: 0.937 - ETA: 7s - loss: 0.1370 - acc: 0.947 - ETA: 7s - loss: 0.1423 - acc: 0.937 - ETA: 6s - loss: 0.1293 - acc: 0.945 - ETA: 6s - loss: 0.1198 - acc: 0.947 - ETA: 6s - loss: 0.1162 - acc: 0.953 - ETA: 6s - loss: 0.1099 - acc: 0.954 - ETA: 6s - loss: 0.1072 - acc: 0.955 - ETA: 6s - loss: 0.1102 - acc: 0.954 - ETA: 5s - loss: 0.1126 - acc: 0.950 - ETA: 5s - loss: 0.1082 - acc: 0.952 - ETA: 5s - loss: 0.1051 - acc: 0.953 - ETA: 5s - loss: 0.1035 - acc: 0.954 - ETA: 5s - loss: 0.1001 - acc: 0.956 - ETA: 5s - loss: 0.0965 - acc: 0.958 - ETA: 4s - loss: 0.1045 - acc: 0.956 - ETA: 4s - loss: 0.1012 - acc: 0.958 - ETA: 4s - loss: 0.0979 - acc: 0.960 - ETA: 4s - loss: 0.1006 - acc: 0.957 - ETA: 4s - loss: 0.0971 - acc: 0.959 - ETA: 4s - loss: 0.1002 - acc: 0.960 - ETA: 3s - loss: 0.0982 - acc: 0.960 - ETA: 3s - loss: 0.1036 - acc: 0.958 - ETA: 3s - loss: 0.1001 - acc: 0.959 - ETA: 3s - loss: 0.1019 - acc: 0.959 - ETA: 3s - loss: 0.0995 - acc: 0.960 - ETA: 3s - loss: 0.0977 - acc: 0.961 - ETA: 2s - loss: 0.0966 - acc: 0.961 - ETA: 2s - loss: 0.0960 - acc: 0.963 - ETA: 2s - loss: 0.0974 - acc: 0.962 - ETA: 2s - loss: 0.0963 - acc: 0.962 - ETA: 2s - loss: 0.0945 - acc: 0.962 - ETA: 2s - loss: 0.0927 - acc: 0.963 - ETA: 1s - loss: 0.0929 - acc: 0.963 - ETA: 1s - loss: 0.0969 - acc: 0.962 - ETA: 1s - loss: 0.0992 - acc: 0.961 - ETA: 1s - loss: 0.1014 - acc: 0.961 - ETA: 1s - loss: 0.0997 - acc: 0.961 - ETA: 1s - loss: 0.0997 - acc: 0.961 - ETA: 0s - loss: 0.1043 - acc: 0.958 - ETA: 0s - loss: 0.1024 - acc: 0.959 - ETA: 0s - loss: 0.1006 - acc: 0.960 - ETA: 0s - loss: 0.1005 - acc: 0.960 - ETA: 0s - loss: 0.1012 - acc: 0.960 - ETA: 0s - loss: 0.1095 - acc: 0.956 - 8s 5ms/step - loss: 0.1088 - acc: 0.9571 - val_loss: 0.1084 - val_acc: 0.9643\n",
      "Epoch 26/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0624 - acc: 0.968 - ETA: 8s - loss: 0.0470 - acc: 0.984 - ETA: 7s - loss: 0.0616 - acc: 0.979 - ETA: 7s - loss: 0.0656 - acc: 0.976 - ETA: 7s - loss: 0.0698 - acc: 0.981 - ETA: 7s - loss: 0.0743 - acc: 0.974 - ETA: 7s - loss: 0.0915 - acc: 0.968 - ETA: 7s - loss: 0.0911 - acc: 0.968 - ETA: 6s - loss: 0.0881 - acc: 0.968 - ETA: 6s - loss: 0.0896 - acc: 0.965 - ETA: 6s - loss: 0.0981 - acc: 0.960 - ETA: 6s - loss: 0.0951 - acc: 0.960 - ETA: 6s - loss: 0.0880 - acc: 0.963 - ETA: 6s - loss: 0.0930 - acc: 0.959 - ETA: 5s - loss: 0.1046 - acc: 0.958 - ETA: 5s - loss: 0.1019 - acc: 0.959 - ETA: 5s - loss: 0.1019 - acc: 0.955 - ETA: 5s - loss: 0.1004 - acc: 0.956 - ETA: 5s - loss: 0.1021 - acc: 0.955 - ETA: 5s - loss: 0.0992 - acc: 0.957 - ETA: 4s - loss: 0.1225 - acc: 0.956 - ETA: 4s - loss: 0.1176 - acc: 0.958 - ETA: 4s - loss: 0.1220 - acc: 0.957 - ETA: 4s - loss: 0.1194 - acc: 0.958 - ETA: 4s - loss: 0.1225 - acc: 0.956 - ETA: 4s - loss: 0.1275 - acc: 0.953 - ETA: 3s - loss: 0.1239 - acc: 0.953 - ETA: 3s - loss: 0.1245 - acc: 0.953 - ETA: 3s - loss: 0.1218 - acc: 0.954 - ETA: 3s - loss: 0.1194 - acc: 0.955 - ETA: 3s - loss: 0.1196 - acc: 0.954 - ETA: 3s - loss: 0.1239 - acc: 0.952 - ETA: 2s - loss: 0.1221 - acc: 0.953 - ETA: 2s - loss: 0.1225 - acc: 0.954 - ETA: 2s - loss: 0.1235 - acc: 0.952 - ETA: 2s - loss: 0.1213 - acc: 0.954 - ETA: 2s - loss: 0.1195 - acc: 0.954 - ETA: 1s - loss: 0.1174 - acc: 0.954 - ETA: 1s - loss: 0.1168 - acc: 0.955 - ETA: 1s - loss: 0.1143 - acc: 0.956 - ETA: 1s - loss: 0.1156 - acc: 0.955 - ETA: 1s - loss: 0.1161 - acc: 0.954 - ETA: 1s - loss: 0.1142 - acc: 0.955 - ETA: 0s - loss: 0.1134 - acc: 0.955 - ETA: 0s - loss: 0.1132 - acc: 0.955 - ETA: 0s - loss: 0.1124 - acc: 0.955 - ETA: 0s - loss: 0.1157 - acc: 0.954 - ETA: 0s - loss: 0.1152 - acc: 0.955 - ETA: 0s - loss: 0.1167 - acc: 0.952 - 9s 5ms/step - loss: 0.1160 - acc: 0.9533 - val_loss: 0.2645 - val_acc: 0.9286\n",
      "Epoch 27/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0638 - acc: 0.968 - ETA: 8s - loss: 0.0652 - acc: 0.968 - ETA: 8s - loss: 0.0688 - acc: 0.968 - ETA: 8s - loss: 0.0696 - acc: 0.968 - ETA: 8s - loss: 0.0786 - acc: 0.968 - ETA: 7s - loss: 0.0954 - acc: 0.968 - ETA: 7s - loss: 0.1296 - acc: 0.959 - ETA: 7s - loss: 0.1174 - acc: 0.964 - ETA: 7s - loss: 0.1086 - acc: 0.968 - ETA: 6s - loss: 0.0989 - acc: 0.971 - ETA: 6s - loss: 0.1063 - acc: 0.968 - ETA: 6s - loss: 0.1045 - acc: 0.971 - ETA: 6s - loss: 0.1017 - acc: 0.971 - ETA: 6s - loss: 0.0979 - acc: 0.973 - ETA: 6s - loss: 0.0943 - acc: 0.975 - ETA: 5s - loss: 0.0932 - acc: 0.976 - ETA: 5s - loss: 0.0922 - acc: 0.976 - ETA: 5s - loss: 0.0911 - acc: 0.975 - ETA: 5s - loss: 0.0938 - acc: 0.975 - ETA: 5s - loss: 0.0936 - acc: 0.975 - ETA: 5s - loss: 0.0909 - acc: 0.976 - ETA: 4s - loss: 0.0956 - acc: 0.974 - ETA: 4s - loss: 0.0924 - acc: 0.975 - ETA: 4s - loss: 0.0897 - acc: 0.976 - ETA: 4s - loss: 0.0871 - acc: 0.977 - ETA: 4s - loss: 0.0858 - acc: 0.977 - ETA: 3s - loss: 0.0839 - acc: 0.978 - ETA: 3s - loss: 0.0824 - acc: 0.978 - ETA: 3s - loss: 0.0802 - acc: 0.979 - ETA: 3s - loss: 0.0778 - acc: 0.980 - ETA: 3s - loss: 0.0755 - acc: 0.980 - ETA: 3s - loss: 0.0735 - acc: 0.981 - ETA: 2s - loss: 0.0769 - acc: 0.980 - ETA: 2s - loss: 0.0752 - acc: 0.980 - ETA: 2s - loss: 0.0762 - acc: 0.979 - ETA: 2s - loss: 0.0742 - acc: 0.980 - ETA: 2s - loss: 0.0817 - acc: 0.978 - ETA: 2s - loss: 0.0805 - acc: 0.979 - ETA: 1s - loss: 0.0830 - acc: 0.976 - ETA: 1s - loss: 0.0820 - acc: 0.977 - ETA: 1s - loss: 0.0816 - acc: 0.976 - ETA: 1s - loss: 0.0809 - acc: 0.976 - ETA: 1s - loss: 0.0810 - acc: 0.976 - ETA: 0s - loss: 0.0810 - acc: 0.975 - ETA: 0s - loss: 0.0794 - acc: 0.976 - ETA: 0s - loss: 0.0780 - acc: 0.976 - ETA: 0s - loss: 0.0784 - acc: 0.976 - ETA: 0s - loss: 0.0806 - acc: 0.975 - ETA: 0s - loss: 0.0800 - acc: 0.975 - 9s 6ms/step - loss: 0.0794 - acc: 0.9760 - val_loss: 0.0886 - val_acc: 0.9464\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 11s - loss: 0.0215 - acc: 1.00 - ETA: 10s - loss: 0.0782 - acc: 0.96 - ETA: 9s - loss: 0.0948 - acc: 0.9479 - ETA: 9s - loss: 0.1032 - acc: 0.945 - ETA: 8s - loss: 0.1124 - acc: 0.943 - ETA: 8s - loss: 0.1285 - acc: 0.942 - ETA: 7s - loss: 0.1200 - acc: 0.946 - ETA: 7s - loss: 0.1119 - acc: 0.949 - ETA: 7s - loss: 0.1228 - acc: 0.944 - ETA: 7s - loss: 0.1404 - acc: 0.943 - ETA: 6s - loss: 0.1339 - acc: 0.946 - ETA: 6s - loss: 0.1288 - acc: 0.947 - ETA: 6s - loss: 0.1350 - acc: 0.947 - ETA: 6s - loss: 0.1322 - acc: 0.948 - ETA: 6s - loss: 0.1299 - acc: 0.950 - ETA: 5s - loss: 0.1242 - acc: 0.953 - ETA: 5s - loss: 0.1173 - acc: 0.955 - ETA: 5s - loss: 0.1143 - acc: 0.956 - ETA: 5s - loss: 0.1104 - acc: 0.958 - ETA: 5s - loss: 0.1213 - acc: 0.954 - ETA: 4s - loss: 0.1176 - acc: 0.956 - ETA: 4s - loss: 0.1144 - acc: 0.958 - ETA: 4s - loss: 0.1112 - acc: 0.959 - ETA: 4s - loss: 0.1137 - acc: 0.957 - ETA: 4s - loss: 0.1111 - acc: 0.958 - ETA: 4s - loss: 0.1105 - acc: 0.959 - ETA: 3s - loss: 0.1100 - acc: 0.958 - ETA: 3s - loss: 0.1065 - acc: 0.959 - ETA: 3s - loss: 0.1049 - acc: 0.960 - ETA: 3s - loss: 0.1019 - acc: 0.961 - ETA: 3s - loss: 0.1006 - acc: 0.962 - ETA: 2s - loss: 0.0994 - acc: 0.963 - ETA: 2s - loss: 0.0971 - acc: 0.965 - ETA: 2s - loss: 0.0954 - acc: 0.966 - ETA: 2s - loss: 0.0933 - acc: 0.967 - ETA: 2s - loss: 0.0976 - acc: 0.966 - ETA: 2s - loss: 0.0951 - acc: 0.967 - ETA: 1s - loss: 0.0971 - acc: 0.967 - ETA: 1s - loss: 0.0948 - acc: 0.967 - ETA: 1s - loss: 0.0928 - acc: 0.968 - ETA: 1s - loss: 0.0935 - acc: 0.967 - ETA: 1s - loss: 0.0937 - acc: 0.966 - ETA: 1s - loss: 0.0933 - acc: 0.966 - ETA: 0s - loss: 0.0913 - acc: 0.967 - ETA: 0s - loss: 0.0900 - acc: 0.968 - ETA: 0s - loss: 0.0887 - acc: 0.968 - ETA: 0s - loss: 0.0869 - acc: 0.969 - ETA: 0s - loss: 0.0854 - acc: 0.970 - ETA: 0s - loss: 0.0880 - acc: 0.968 - 8s 5ms/step - loss: 0.0872 - acc: 0.9684 - val_loss: 0.4769 - val_acc: 0.9286\n",
      "Epoch 29/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.1054 - acc: 0.937 - ETA: 8s - loss: 0.0776 - acc: 0.968 - ETA: 7s - loss: 0.0608 - acc: 0.979 - ETA: 7s - loss: 0.0500 - acc: 0.984 - ETA: 7s - loss: 0.0467 - acc: 0.981 - ETA: 7s - loss: 0.0391 - acc: 0.984 - ETA: 7s - loss: 0.0525 - acc: 0.977 - ETA: 7s - loss: 0.0471 - acc: 0.980 - ETA: 6s - loss: 0.0502 - acc: 0.979 - ETA: 6s - loss: 0.0624 - acc: 0.978 - ETA: 6s - loss: 0.0744 - acc: 0.977 - ETA: 6s - loss: 0.0738 - acc: 0.976 - ETA: 6s - loss: 0.0698 - acc: 0.978 - ETA: 6s - loss: 0.0701 - acc: 0.977 - ETA: 6s - loss: 0.0668 - acc: 0.979 - ETA: 5s - loss: 0.0745 - acc: 0.976 - ETA: 5s - loss: 0.0725 - acc: 0.976 - ETA: 5s - loss: 0.0753 - acc: 0.975 - ETA: 5s - loss: 0.0722 - acc: 0.977 - ETA: 5s - loss: 0.0711 - acc: 0.976 - ETA: 4s - loss: 0.0712 - acc: 0.976 - ETA: 4s - loss: 0.0707 - acc: 0.977 - ETA: 4s - loss: 0.0693 - acc: 0.976 - ETA: 4s - loss: 0.0818 - acc: 0.974 - ETA: 4s - loss: 0.0839 - acc: 0.972 - ETA: 4s - loss: 0.0821 - acc: 0.973 - ETA: 3s - loss: 0.0801 - acc: 0.974 - ETA: 3s - loss: 0.0796 - acc: 0.974 - ETA: 3s - loss: 0.0822 - acc: 0.973 - ETA: 3s - loss: 0.0808 - acc: 0.972 - ETA: 3s - loss: 0.0803 - acc: 0.972 - ETA: 3s - loss: 0.0809 - acc: 0.972 - ETA: 2s - loss: 0.0803 - acc: 0.971 - ETA: 2s - loss: 0.0782 - acc: 0.972 - ETA: 2s - loss: 0.0787 - acc: 0.971 - ETA: 2s - loss: 0.0782 - acc: 0.971 - ETA: 2s - loss: 0.0781 - acc: 0.970 - ETA: 1s - loss: 0.0765 - acc: 0.971 - ETA: 1s - loss: 0.0748 - acc: 0.972 - ETA: 1s - loss: 0.0735 - acc: 0.972 - ETA: 1s - loss: 0.0724 - acc: 0.973 - ETA: 1s - loss: 0.0726 - acc: 0.972 - ETA: 1s - loss: 0.0765 - acc: 0.971 - ETA: 0s - loss: 0.0750 - acc: 0.972 - ETA: 0s - loss: 0.0746 - acc: 0.972 - ETA: 0s - loss: 0.0742 - acc: 0.972 - ETA: 0s - loss: 0.0775 - acc: 0.971 - ETA: 0s - loss: 0.0771 - acc: 0.971 - ETA: 0s - loss: 0.0785 - acc: 0.970 - 9s 5ms/step - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0850 - val_acc: 0.9821\n",
      "Epoch 30/50\n",
      "1584/1584 [==============================] - ETA: 10s - loss: 0.0041 - acc: 1.00 - ETA: 9s - loss: 0.0215 - acc: 0.9844 - ETA: 8s - loss: 0.0389 - acc: 0.979 - ETA: 8s - loss: 0.0424 - acc: 0.984 - ETA: 8s - loss: 0.0538 - acc: 0.975 - ETA: 8s - loss: 0.0634 - acc: 0.968 - ETA: 7s - loss: 0.0627 - acc: 0.968 - ETA: 7s - loss: 0.0750 - acc: 0.964 - ETA: 7s - loss: 0.0704 - acc: 0.968 - ETA: 7s - loss: 0.0685 - acc: 0.971 - ETA: 7s - loss: 0.0749 - acc: 0.968 - ETA: 7s - loss: 0.0691 - acc: 0.971 - ETA: 6s - loss: 0.0696 - acc: 0.968 - ETA: 6s - loss: 0.0691 - acc: 0.968 - ETA: 6s - loss: 0.0671 - acc: 0.970 - ETA: 6s - loss: 0.0669 - acc: 0.970 - ETA: 6s - loss: 0.0631 - acc: 0.972 - ETA: 5s - loss: 0.0622 - acc: 0.972 - ETA: 5s - loss: 0.0619 - acc: 0.972 - ETA: 5s - loss: 0.0649 - acc: 0.967 - ETA: 5s - loss: 0.0634 - acc: 0.967 - ETA: 5s - loss: 0.0646 - acc: 0.967 - ETA: 4s - loss: 0.0630 - acc: 0.968 - ETA: 4s - loss: 0.0769 - acc: 0.963 - ETA: 4s - loss: 0.0761 - acc: 0.963 - ETA: 4s - loss: 0.0788 - acc: 0.963 - ETA: 4s - loss: 0.0782 - acc: 0.964 - ETA: 3s - loss: 0.0772 - acc: 0.964 - ETA: 3s - loss: 0.0751 - acc: 0.965 - ETA: 3s - loss: 0.0736 - acc: 0.966 - ETA: 3s - loss: 0.0719 - acc: 0.967 - ETA: 3s - loss: 0.0701 - acc: 0.968 - ETA: 3s - loss: 0.0707 - acc: 0.967 - ETA: 2s - loss: 0.0705 - acc: 0.966 - ETA: 2s - loss: 0.0735 - acc: 0.964 - ETA: 2s - loss: 0.0729 - acc: 0.965 - ETA: 2s - loss: 0.0763 - acc: 0.964 - ETA: 2s - loss: 0.0744 - acc: 0.965 - ETA: 1s - loss: 0.0753 - acc: 0.964 - ETA: 1s - loss: 0.0738 - acc: 0.965 - ETA: 1s - loss: 0.0738 - acc: 0.965 - ETA: 1s - loss: 0.0751 - acc: 0.965 - ETA: 1s - loss: 0.0741 - acc: 0.965 - ETA: 0s - loss: 0.0736 - acc: 0.965 - ETA: 0s - loss: 0.0736 - acc: 0.966 - ETA: 0s - loss: 0.0748 - acc: 0.964 - ETA: 0s - loss: 0.0741 - acc: 0.965 - ETA: 0s - loss: 0.0725 - acc: 0.966 - ETA: 0s - loss: 0.0785 - acc: 0.964 - 9s 6ms/step - loss: 0.0777 - acc: 0.9653 - val_loss: 0.1832 - val_acc: 0.9643\n",
      "Epoch 31/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0278 - acc: 0.968 - ETA: 8s - loss: 0.0218 - acc: 0.984 - ETA: 8s - loss: 0.0229 - acc: 0.989 - ETA: 8s - loss: 0.0320 - acc: 0.984 - ETA: 7s - loss: 0.0336 - acc: 0.981 - ETA: 7s - loss: 0.0302 - acc: 0.984 - ETA: 7s - loss: 0.0460 - acc: 0.977 - ETA: 7s - loss: 0.0407 - acc: 0.980 - ETA: 7s - loss: 0.0471 - acc: 0.975 - ETA: 6s - loss: 0.0447 - acc: 0.978 - ETA: 6s - loss: 0.0418 - acc: 0.980 - ETA: 6s - loss: 0.0414 - acc: 0.981 - ETA: 6s - loss: 0.0428 - acc: 0.980 - ETA: 6s - loss: 0.0448 - acc: 0.979 - ETA: 6s - loss: 0.0429 - acc: 0.981 - ETA: 5s - loss: 0.0468 - acc: 0.978 - ETA: 5s - loss: 0.0442 - acc: 0.979 - ETA: 5s - loss: 0.0430 - acc: 0.980 - ETA: 5s - loss: 0.0411 - acc: 0.981 - ETA: 5s - loss: 0.0411 - acc: 0.982 - ETA: 5s - loss: 0.0449 - acc: 0.982 - ETA: 4s - loss: 0.0443 - acc: 0.981 - ETA: 4s - loss: 0.0434 - acc: 0.982 - ETA: 4s - loss: 0.0447 - acc: 0.981 - ETA: 4s - loss: 0.0442 - acc: 0.982 - ETA: 4s - loss: 0.0433 - acc: 0.983 - ETA: 3s - loss: 0.0418 - acc: 0.983 - ETA: 3s - loss: 0.0417 - acc: 0.983 - ETA: 3s - loss: 0.0433 - acc: 0.982 - ETA: 3s - loss: 0.0420 - acc: 0.983 - ETA: 3s - loss: 0.0460 - acc: 0.981 - ETA: 3s - loss: 0.0471 - acc: 0.981 - ETA: 2s - loss: 0.0517 - acc: 0.980 - ETA: 2s - loss: 0.0533 - acc: 0.978 - ETA: 2s - loss: 0.0521 - acc: 0.979 - ETA: 2s - loss: 0.0509 - acc: 0.980 - ETA: 2s - loss: 0.0496 - acc: 0.980 - ETA: 2s - loss: 0.0506 - acc: 0.980 - ETA: 1s - loss: 0.0499 - acc: 0.980 - ETA: 1s - loss: 0.0488 - acc: 0.981 - ETA: 1s - loss: 0.0503 - acc: 0.980 - ETA: 1s - loss: 0.0507 - acc: 0.979 - ETA: 1s - loss: 0.0501 - acc: 0.980 - ETA: 0s - loss: 0.0510 - acc: 0.980 - ETA: 0s - loss: 0.0508 - acc: 0.979 - ETA: 0s - loss: 0.0522 - acc: 0.978 - ETA: 0s - loss: 0.0519 - acc: 0.979 - ETA: 0s - loss: 0.0511 - acc: 0.979 - ETA: 0s - loss: 0.0505 - acc: 0.980 - 9s 6ms/step - loss: 0.0511 - acc: 0.9798 - val_loss: 0.0859 - val_acc: 0.9643\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0399 - acc: 1.000 - ETA: 7s - loss: 0.0410 - acc: 1.000 - ETA: 7s - loss: 0.0452 - acc: 0.989 - ETA: 7s - loss: 0.0421 - acc: 0.992 - ETA: 7s - loss: 0.0553 - acc: 0.987 - ETA: 7s - loss: 0.0481 - acc: 0.989 - ETA: 7s - loss: 0.0466 - acc: 0.991 - ETA: 7s - loss: 0.0462 - acc: 0.992 - ETA: 6s - loss: 0.0429 - acc: 0.993 - ETA: 6s - loss: 0.0505 - acc: 0.990 - ETA: 6s - loss: 0.0473 - acc: 0.991 - ETA: 6s - loss: 0.0455 - acc: 0.992 - ETA: 6s - loss: 0.0442 - acc: 0.992 - ETA: 6s - loss: 0.0426 - acc: 0.993 - ETA: 5s - loss: 0.0399 - acc: 0.993 - ETA: 5s - loss: 0.0385 - acc: 0.994 - ETA: 5s - loss: 0.0370 - acc: 0.994 - ETA: 5s - loss: 0.0352 - acc: 0.994 - ETA: 5s - loss: 0.0388 - acc: 0.991 - ETA: 4s - loss: 0.0369 - acc: 0.992 - ETA: 4s - loss: 0.0364 - acc: 0.991 - ETA: 4s - loss: 0.0356 - acc: 0.991 - ETA: 4s - loss: 0.0348 - acc: 0.991 - ETA: 4s - loss: 0.0360 - acc: 0.990 - ETA: 4s - loss: 0.0389 - acc: 0.990 - ETA: 3s - loss: 0.0393 - acc: 0.989 - ETA: 3s - loss: 0.0380 - acc: 0.989 - ETA: 3s - loss: 0.0404 - acc: 0.988 - ETA: 3s - loss: 0.0391 - acc: 0.989 - ETA: 3s - loss: 0.0380 - acc: 0.989 - ETA: 3s - loss: 0.0370 - acc: 0.989 - ETA: 2s - loss: 0.0376 - acc: 0.989 - ETA: 2s - loss: 0.0390 - acc: 0.988 - ETA: 2s - loss: 0.0379 - acc: 0.989 - ETA: 2s - loss: 0.0376 - acc: 0.989 - ETA: 2s - loss: 0.0431 - acc: 0.986 - ETA: 2s - loss: 0.0421 - acc: 0.986 - ETA: 1s - loss: 0.0436 - acc: 0.986 - ETA: 1s - loss: 0.0437 - acc: 0.985 - ETA: 1s - loss: 0.0426 - acc: 0.985 - ETA: 1s - loss: 0.0431 - acc: 0.985 - ETA: 1s - loss: 0.0430 - acc: 0.985 - ETA: 1s - loss: 0.0434 - acc: 0.985 - ETA: 0s - loss: 0.0426 - acc: 0.985 - ETA: 0s - loss: 0.0440 - acc: 0.984 - ETA: 0s - loss: 0.0439 - acc: 0.984 - ETA: 0s - loss: 0.0432 - acc: 0.984 - ETA: 0s - loss: 0.0466 - acc: 0.983 - ETA: 0s - loss: 0.0462 - acc: 0.983 - 9s 5ms/step - loss: 0.0463 - acc: 0.9836 - val_loss: 0.2259 - val_acc: 0.9464\n",
      "Epoch 33/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0098 - acc: 1.000 - ETA: 8s - loss: 0.0165 - acc: 1.000 - ETA: 7s - loss: 0.0184 - acc: 1.000 - ETA: 7s - loss: 0.0191 - acc: 1.000 - ETA: 7s - loss: 0.0714 - acc: 0.987 - ETA: 7s - loss: 0.0945 - acc: 0.979 - ETA: 7s - loss: 0.0993 - acc: 0.977 - ETA: 7s - loss: 0.0876 - acc: 0.980 - ETA: 6s - loss: 0.0932 - acc: 0.979 - ETA: 6s - loss: 0.0890 - acc: 0.978 - ETA: 6s - loss: 0.0811 - acc: 0.980 - ETA: 6s - loss: 0.0771 - acc: 0.981 - ETA: 6s - loss: 0.0714 - acc: 0.983 - ETA: 6s - loss: 0.0681 - acc: 0.984 - ETA: 5s - loss: 0.0648 - acc: 0.985 - ETA: 5s - loss: 0.0630 - acc: 0.984 - ETA: 5s - loss: 0.0696 - acc: 0.981 - ETA: 5s - loss: 0.0691 - acc: 0.982 - ETA: 5s - loss: 0.0716 - acc: 0.978 - ETA: 5s - loss: 0.0693 - acc: 0.979 - ETA: 4s - loss: 0.0684 - acc: 0.979 - ETA: 4s - loss: 0.0675 - acc: 0.978 - ETA: 4s - loss: 0.0647 - acc: 0.979 - ETA: 4s - loss: 0.0644 - acc: 0.979 - ETA: 4s - loss: 0.0620 - acc: 0.980 - ETA: 4s - loss: 0.0643 - acc: 0.978 - ETA: 3s - loss: 0.0662 - acc: 0.976 - ETA: 3s - loss: 0.0642 - acc: 0.977 - ETA: 3s - loss: 0.0631 - acc: 0.977 - ETA: 3s - loss: 0.0613 - acc: 0.978 - ETA: 3s - loss: 0.0622 - acc: 0.976 - ETA: 3s - loss: 0.0775 - acc: 0.974 - ETA: 2s - loss: 0.0759 - acc: 0.975 - ETA: 2s - loss: 0.0818 - acc: 0.973 - ETA: 2s - loss: 0.0797 - acc: 0.974 - ETA: 2s - loss: 0.0820 - acc: 0.973 - ETA: 2s - loss: 0.0895 - acc: 0.967 - ETA: 1s - loss: 0.0901 - acc: 0.966 - ETA: 1s - loss: 0.0896 - acc: 0.966 - ETA: 1s - loss: 0.0881 - acc: 0.967 - ETA: 1s - loss: 0.0869 - acc: 0.968 - ETA: 1s - loss: 0.0878 - acc: 0.968 - ETA: 1s - loss: 0.0904 - acc: 0.966 - ETA: 0s - loss: 0.0890 - acc: 0.967 - ETA: 0s - loss: 0.0874 - acc: 0.968 - ETA: 0s - loss: 0.0861 - acc: 0.968 - ETA: 0s - loss: 0.0845 - acc: 0.968 - ETA: 0s - loss: 0.0841 - acc: 0.969 - ETA: 0s - loss: 0.0830 - acc: 0.969 - 9s 5ms/step - loss: 0.0835 - acc: 0.9691 - val_loss: 0.2264 - val_acc: 0.9464\n",
      "Epoch 34/50\n",
      "1584/1584 [==============================] - ETA: 9s - loss: 0.0300 - acc: 1.000 - ETA: 8s - loss: 0.0237 - acc: 1.000 - ETA: 8s - loss: 0.0235 - acc: 1.000 - ETA: 7s - loss: 0.0359 - acc: 0.984 - ETA: 7s - loss: 0.0799 - acc: 0.968 - ETA: 7s - loss: 0.0724 - acc: 0.974 - ETA: 7s - loss: 0.0715 - acc: 0.973 - ETA: 7s - loss: 0.0727 - acc: 0.972 - ETA: 7s - loss: 0.0675 - acc: 0.975 - ETA: 6s - loss: 0.0681 - acc: 0.971 - ETA: 6s - loss: 0.0685 - acc: 0.971 - ETA: 6s - loss: 0.0680 - acc: 0.971 - ETA: 6s - loss: 0.0656 - acc: 0.971 - ETA: 6s - loss: 0.0631 - acc: 0.973 - ETA: 6s - loss: 0.0621 - acc: 0.975 - ETA: 5s - loss: 0.0611 - acc: 0.974 - ETA: 5s - loss: 0.0584 - acc: 0.976 - ETA: 5s - loss: 0.0570 - acc: 0.975 - ETA: 5s - loss: 0.0617 - acc: 0.975 - ETA: 5s - loss: 0.0884 - acc: 0.973 - ETA: 4s - loss: 0.0871 - acc: 0.973 - ETA: 4s - loss: 0.0834 - acc: 0.974 - ETA: 4s - loss: 0.0818 - acc: 0.974 - ETA: 4s - loss: 0.0786 - acc: 0.975 - ETA: 4s - loss: 0.0778 - acc: 0.975 - ETA: 4s - loss: 0.0761 - acc: 0.976 - ETA: 3s - loss: 0.0736 - acc: 0.976 - ETA: 3s - loss: 0.0749 - acc: 0.976 - ETA: 3s - loss: 0.0748 - acc: 0.976 - ETA: 3s - loss: 0.0738 - acc: 0.976 - ETA: 3s - loss: 0.0721 - acc: 0.976 - ETA: 3s - loss: 0.0711 - acc: 0.977 - ETA: 2s - loss: 0.0706 - acc: 0.977 - ETA: 2s - loss: 0.0702 - acc: 0.977 - ETA: 2s - loss: 0.0707 - acc: 0.975 - ETA: 2s - loss: 0.0689 - acc: 0.976 - ETA: 2s - loss: 0.0682 - acc: 0.976 - ETA: 1s - loss: 0.0688 - acc: 0.976 - ETA: 1s - loss: 0.0695 - acc: 0.975 - ETA: 1s - loss: 0.0683 - acc: 0.975 - ETA: 1s - loss: 0.0674 - acc: 0.976 - ETA: 1s - loss: 0.0659 - acc: 0.976 - ETA: 1s - loss: 0.0673 - acc: 0.976 - ETA: 0s - loss: 0.0677 - acc: 0.975 - ETA: 0s - loss: 0.0664 - acc: 0.975 - ETA: 0s - loss: 0.0672 - acc: 0.975 - ETA: 0s - loss: 0.0661 - acc: 0.976 - ETA: 0s - loss: 0.0663 - acc: 0.975 - ETA: 0s - loss: 0.0653 - acc: 0.975 - 9s 6ms/step - loss: 0.0659 - acc: 0.9754 - val_loss: 0.1658 - val_acc: 0.9821\n",
      "Epoch 35/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0357 - acc: 0.968 - ETA: 7s - loss: 0.0474 - acc: 0.968 - ETA: 7s - loss: 0.0649 - acc: 0.958 - ETA: 7s - loss: 0.0525 - acc: 0.968 - ETA: 7s - loss: 0.0475 - acc: 0.975 - ETA: 7s - loss: 0.0424 - acc: 0.979 - ETA: 7s - loss: 0.0378 - acc: 0.982 - ETA: 7s - loss: 0.0425 - acc: 0.976 - ETA: 6s - loss: 0.0464 - acc: 0.975 - ETA: 6s - loss: 0.0695 - acc: 0.971 - ETA: 6s - loss: 0.0650 - acc: 0.974 - ETA: 6s - loss: 0.0628 - acc: 0.976 - ETA: 6s - loss: 0.0592 - acc: 0.978 - ETA: 6s - loss: 0.0639 - acc: 0.975 - ETA: 5s - loss: 0.0627 - acc: 0.975 - ETA: 5s - loss: 0.0591 - acc: 0.976 - ETA: 5s - loss: 0.0622 - acc: 0.976 - ETA: 5s - loss: 0.0603 - acc: 0.977 - ETA: 5s - loss: 0.0649 - acc: 0.975 - ETA: 4s - loss: 0.0652 - acc: 0.973 - ETA: 4s - loss: 0.0684 - acc: 0.973 - ETA: 4s - loss: 0.0665 - acc: 0.973 - ETA: 4s - loss: 0.0639 - acc: 0.974 - ETA: 4s - loss: 0.0696 - acc: 0.971 - ETA: 4s - loss: 0.0740 - acc: 0.970 - ETA: 3s - loss: 0.0842 - acc: 0.970 - ETA: 3s - loss: 0.0838 - acc: 0.969 - ETA: 3s - loss: 0.0829 - acc: 0.969 - ETA: 3s - loss: 0.0819 - acc: 0.969 - ETA: 3s - loss: 0.0821 - acc: 0.968 - ETA: 3s - loss: 0.0907 - acc: 0.966 - ETA: 2s - loss: 0.0916 - acc: 0.965 - ETA: 2s - loss: 0.0906 - acc: 0.965 - ETA: 2s - loss: 0.1007 - acc: 0.966 - ETA: 2s - loss: 0.0980 - acc: 0.967 - ETA: 2s - loss: 0.0988 - acc: 0.966 - ETA: 2s - loss: 0.0964 - acc: 0.967 - ETA: 1s - loss: 0.0955 - acc: 0.967 - ETA: 1s - loss: 0.0954 - acc: 0.967 - ETA: 1s - loss: 0.0957 - acc: 0.966 - ETA: 1s - loss: 0.1005 - acc: 0.964 - ETA: 1s - loss: 0.0987 - acc: 0.965 - ETA: 1s - loss: 0.0982 - acc: 0.965 - ETA: 0s - loss: 0.0965 - acc: 0.965 - ETA: 0s - loss: 0.1213 - acc: 0.964 - ETA: 0s - loss: 0.1254 - acc: 0.963 - ETA: 0s - loss: 0.1369 - acc: 0.962 - ETA: 0s - loss: 0.1558 - acc: 0.960 - ETA: 0s - loss: 0.1591 - acc: 0.959 - 9s 5ms/step - loss: 0.1575 - acc: 0.9596 - val_loss: 0.1893 - val_acc: 0.9643\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0455 - acc: 0.968 - ETA: 8s - loss: 0.0698 - acc: 0.984 - ETA: 7s - loss: 0.0556 - acc: 0.989 - ETA: 7s - loss: 0.0435 - acc: 0.992 - ETA: 7s - loss: 0.0386 - acc: 0.993 - ETA: 7s - loss: 0.0404 - acc: 0.994 - ETA: 7s - loss: 0.0392 - acc: 0.995 - ETA: 7s - loss: 0.0525 - acc: 0.984 - ETA: 7s - loss: 0.0475 - acc: 0.986 - ETA: 6s - loss: 0.0509 - acc: 0.984 - ETA: 6s - loss: 0.0631 - acc: 0.980 - ETA: 6s - loss: 0.0694 - acc: 0.976 - ETA: 6s - loss: 0.0655 - acc: 0.978 - ETA: 6s - loss: 0.0626 - acc: 0.979 - ETA: 5s - loss: 0.0614 - acc: 0.981 - ETA: 5s - loss: 0.0589 - acc: 0.982 - ETA: 5s - loss: 0.0572 - acc: 0.983 - ETA: 5s - loss: 0.0551 - acc: 0.984 - ETA: 5s - loss: 0.0579 - acc: 0.981 - ETA: 5s - loss: 0.0590 - acc: 0.979 - ETA: 4s - loss: 0.0567 - acc: 0.980 - ETA: 4s - loss: 0.0619 - acc: 0.978 - ETA: 4s - loss: 0.0631 - acc: 0.976 - ETA: 4s - loss: 0.0622 - acc: 0.976 - ETA: 4s - loss: 0.0611 - acc: 0.976 - ETA: 3s - loss: 0.0605 - acc: 0.977 - ETA: 3s - loss: 0.0591 - acc: 0.978 - ETA: 3s - loss: 0.0579 - acc: 0.978 - ETA: 3s - loss: 0.0573 - acc: 0.979 - ETA: 3s - loss: 0.0556 - acc: 0.980 - ETA: 3s - loss: 0.0545 - acc: 0.980 - ETA: 2s - loss: 0.0530 - acc: 0.981 - ETA: 2s - loss: 0.0551 - acc: 0.980 - ETA: 2s - loss: 0.0547 - acc: 0.980 - ETA: 2s - loss: 0.0544 - acc: 0.980 - ETA: 2s - loss: 0.0551 - acc: 0.980 - ETA: 2s - loss: 0.0546 - acc: 0.979 - ETA: 1s - loss: 0.0553 - acc: 0.979 - ETA: 1s - loss: 0.0564 - acc: 0.978 - ETA: 1s - loss: 0.0590 - acc: 0.977 - ETA: 1s - loss: 0.0577 - acc: 0.977 - ETA: 1s - loss: 0.0571 - acc: 0.978 - ETA: 1s - loss: 0.0562 - acc: 0.978 - ETA: 0s - loss: 0.0567 - acc: 0.978 - ETA: 0s - loss: 0.0561 - acc: 0.978 - ETA: 0s - loss: 0.0564 - acc: 0.978 - ETA: 0s - loss: 0.0584 - acc: 0.977 - ETA: 0s - loss: 0.0574 - acc: 0.977 - ETA: 0s - loss: 0.0569 - acc: 0.978 - 8s 5ms/step - loss: 0.0565 - acc: 0.9785 - val_loss: 0.2096 - val_acc: 0.9821\n",
      "Epoch 37/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0515 - acc: 0.968 - ETA: 8s - loss: 0.0446 - acc: 0.968 - ETA: 7s - loss: 0.0834 - acc: 0.958 - ETA: 7s - loss: 0.0700 - acc: 0.968 - ETA: 7s - loss: 0.0697 - acc: 0.968 - ETA: 7s - loss: 0.0649 - acc: 0.974 - ETA: 7s - loss: 0.0597 - acc: 0.977 - ETA: 7s - loss: 0.0549 - acc: 0.980 - ETA: 6s - loss: 0.0569 - acc: 0.975 - ETA: 6s - loss: 0.0527 - acc: 0.978 - ETA: 6s - loss: 0.0591 - acc: 0.977 - ETA: 6s - loss: 0.0588 - acc: 0.976 - ETA: 6s - loss: 0.0544 - acc: 0.978 - ETA: 6s - loss: 0.0580 - acc: 0.977 - ETA: 5s - loss: 0.0555 - acc: 0.979 - ETA: 5s - loss: 0.0521 - acc: 0.980 - ETA: 5s - loss: 0.0500 - acc: 0.981 - ETA: 5s - loss: 0.0487 - acc: 0.982 - ETA: 5s - loss: 0.0540 - acc: 0.981 - ETA: 4s - loss: 0.0522 - acc: 0.982 - ETA: 4s - loss: 0.0533 - acc: 0.982 - ETA: 4s - loss: 0.0535 - acc: 0.981 - ETA: 4s - loss: 0.0513 - acc: 0.982 - ETA: 4s - loss: 0.0552 - acc: 0.980 - ETA: 4s - loss: 0.0810 - acc: 0.977 - ETA: 3s - loss: 0.0865 - acc: 0.977 - ETA: 3s - loss: 0.0942 - acc: 0.975 - ETA: 3s - loss: 0.0929 - acc: 0.975 - ETA: 3s - loss: 0.1050 - acc: 0.974 - ETA: 3s - loss: 0.1019 - acc: 0.975 - ETA: 3s - loss: 0.1010 - acc: 0.974 - ETA: 2s - loss: 0.0991 - acc: 0.974 - ETA: 2s - loss: 0.0963 - acc: 0.975 - ETA: 2s - loss: 0.0960 - acc: 0.974 - ETA: 2s - loss: 0.0954 - acc: 0.974 - ETA: 2s - loss: 0.0941 - acc: 0.974 - ETA: 2s - loss: 0.0917 - acc: 0.974 - ETA: 1s - loss: 0.0897 - acc: 0.975 - ETA: 1s - loss: 0.0885 - acc: 0.975 - ETA: 1s - loss: 0.0893 - acc: 0.974 - ETA: 1s - loss: 0.0911 - acc: 0.973 - ETA: 1s - loss: 0.0899 - acc: 0.973 - ETA: 1s - loss: 0.0883 - acc: 0.973 - ETA: 0s - loss: 0.0877 - acc: 0.973 - ETA: 0s - loss: 0.0894 - acc: 0.972 - ETA: 0s - loss: 0.0969 - acc: 0.972 - ETA: 0s - loss: 0.0950 - acc: 0.972 - ETA: 0s - loss: 0.0934 - acc: 0.973 - ETA: 0s - loss: 0.0921 - acc: 0.973 - 8s 5ms/step - loss: 0.0917 - acc: 0.9741 - val_loss: 0.1107 - val_acc: 0.9821\n",
      "Epoch 38/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0291 - acc: 1.000 - ETA: 8s - loss: 0.0218 - acc: 1.000 - ETA: 7s - loss: 0.0258 - acc: 1.000 - ETA: 7s - loss: 0.0295 - acc: 1.000 - ETA: 7s - loss: 0.0545 - acc: 0.987 - ETA: 7s - loss: 0.0547 - acc: 0.984 - ETA: 7s - loss: 0.0802 - acc: 0.982 - ETA: 6s - loss: 0.0820 - acc: 0.980 - ETA: 6s - loss: 0.1195 - acc: 0.972 - ETA: 6s - loss: 0.1384 - acc: 0.971 - ETA: 6s - loss: 0.1494 - acc: 0.968 - ETA: 6s - loss: 0.1390 - acc: 0.971 - ETA: 6s - loss: 0.1299 - acc: 0.973 - ETA: 5s - loss: 0.1208 - acc: 0.975 - ETA: 5s - loss: 0.1131 - acc: 0.977 - ETA: 5s - loss: 0.1072 - acc: 0.978 - ETA: 5s - loss: 0.1022 - acc: 0.979 - ETA: 5s - loss: 0.0971 - acc: 0.980 - ETA: 5s - loss: 0.0954 - acc: 0.980 - ETA: 4s - loss: 0.0941 - acc: 0.979 - ETA: 4s - loss: 0.0903 - acc: 0.980 - ETA: 4s - loss: 0.0876 - acc: 0.981 - ETA: 4s - loss: 0.0902 - acc: 0.981 - ETA: 4s - loss: 0.0905 - acc: 0.979 - ETA: 4s - loss: 0.0980 - acc: 0.977 - ETA: 3s - loss: 0.0986 - acc: 0.974 - ETA: 3s - loss: 0.0952 - acc: 0.975 - ETA: 3s - loss: 0.0928 - acc: 0.975 - ETA: 3s - loss: 0.0911 - acc: 0.976 - ETA: 3s - loss: 0.0892 - acc: 0.977 - ETA: 3s - loss: 0.0870 - acc: 0.977 - ETA: 2s - loss: 0.0853 - acc: 0.978 - ETA: 2s - loss: 0.0839 - acc: 0.978 - ETA: 2s - loss: 0.0820 - acc: 0.978 - ETA: 2s - loss: 0.0813 - acc: 0.978 - ETA: 2s - loss: 0.0795 - acc: 0.979 - ETA: 2s - loss: 0.0775 - acc: 0.979 - ETA: 1s - loss: 0.0758 - acc: 0.980 - ETA: 1s - loss: 0.0755 - acc: 0.980 - ETA: 1s - loss: 0.0756 - acc: 0.979 - ETA: 1s - loss: 0.0752 - acc: 0.979 - ETA: 1s - loss: 0.0787 - acc: 0.978 - ETA: 1s - loss: 0.0775 - acc: 0.978 - ETA: 0s - loss: 0.0762 - acc: 0.979 - ETA: 0s - loss: 0.0746 - acc: 0.979 - ETA: 0s - loss: 0.0745 - acc: 0.979 - ETA: 0s - loss: 0.0809 - acc: 0.978 - ETA: 0s - loss: 0.0794 - acc: 0.978 - ETA: 0s - loss: 0.0801 - acc: 0.977 - 9s 6ms/step - loss: 0.0800 - acc: 0.9779 - val_loss: 0.1598 - val_acc: 0.9643\n",
      "Epoch 39/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0427 - acc: 0.968 - ETA: 8s - loss: 0.0337 - acc: 0.984 - ETA: 8s - loss: 0.0362 - acc: 0.989 - ETA: 8s - loss: 0.0544 - acc: 0.976 - ETA: 8s - loss: 0.0574 - acc: 0.975 - ETA: 7s - loss: 0.0581 - acc: 0.974 - ETA: 7s - loss: 0.0590 - acc: 0.973 - ETA: 7s - loss: 0.0524 - acc: 0.976 - ETA: 7s - loss: 0.0527 - acc: 0.975 - ETA: 7s - loss: 0.0542 - acc: 0.975 - ETA: 6s - loss: 0.0534 - acc: 0.974 - ETA: 6s - loss: 0.0525 - acc: 0.974 - ETA: 6s - loss: 0.0565 - acc: 0.968 - ETA: 6s - loss: 0.0664 - acc: 0.968 - ETA: 6s - loss: 0.0652 - acc: 0.968 - ETA: 5s - loss: 0.0640 - acc: 0.970 - ETA: 5s - loss: 0.0616 - acc: 0.972 - ETA: 5s - loss: 0.0619 - acc: 0.972 - ETA: 5s - loss: 0.0589 - acc: 0.973 - ETA: 5s - loss: 0.0565 - acc: 0.975 - ETA: 5s - loss: 0.0619 - acc: 0.973 - ETA: 4s - loss: 0.0608 - acc: 0.974 - ETA: 4s - loss: 0.0587 - acc: 0.975 - ETA: 4s - loss: 0.0624 - acc: 0.975 - ETA: 4s - loss: 0.0611 - acc: 0.976 - ETA: 4s - loss: 0.0644 - acc: 0.976 - ETA: 3s - loss: 0.0677 - acc: 0.975 - ETA: 3s - loss: 0.0661 - acc: 0.976 - ETA: 3s - loss: 0.0745 - acc: 0.975 - ETA: 3s - loss: 0.0748 - acc: 0.974 - ETA: 3s - loss: 0.0725 - acc: 0.974 - ETA: 3s - loss: 0.0704 - acc: 0.975 - ETA: 2s - loss: 0.0722 - acc: 0.975 - ETA: 2s - loss: 0.0701 - acc: 0.976 - ETA: 2s - loss: 0.0714 - acc: 0.975 - ETA: 2s - loss: 0.0728 - acc: 0.974 - ETA: 2s - loss: 0.0723 - acc: 0.974 - ETA: 2s - loss: 0.0707 - acc: 0.975 - ETA: 1s - loss: 0.0689 - acc: 0.976 - ETA: 1s - loss: 0.0735 - acc: 0.975 - ETA: 1s - loss: 0.0723 - acc: 0.975 - ETA: 1s - loss: 0.0736 - acc: 0.974 - ETA: 1s - loss: 0.0808 - acc: 0.973 - ETA: 0s - loss: 0.0793 - acc: 0.974 - ETA: 0s - loss: 0.0798 - acc: 0.973 - ETA: 0s - loss: 0.0784 - acc: 0.974 - ETA: 0s - loss: 0.0773 - acc: 0.974 - ETA: 0s - loss: 0.0773 - acc: 0.974 - ETA: 0s - loss: 0.0771 - acc: 0.974 - 9s 6ms/step - loss: 0.0782 - acc: 0.9741 - val_loss: 0.1075 - val_acc: 0.9821\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0062 - acc: 1.000 - ETA: 7s - loss: 0.0201 - acc: 1.000 - ETA: 7s - loss: 0.0165 - acc: 1.000 - ETA: 7s - loss: 0.0220 - acc: 0.992 - ETA: 7s - loss: 0.0352 - acc: 0.981 - ETA: 7s - loss: 0.0646 - acc: 0.974 - ETA: 7s - loss: 0.0656 - acc: 0.968 - ETA: 7s - loss: 0.0697 - acc: 0.964 - ETA: 6s - loss: 0.0717 - acc: 0.961 - ETA: 6s - loss: 0.0658 - acc: 0.965 - ETA: 6s - loss: 0.0638 - acc: 0.965 - ETA: 6s - loss: 0.0612 - acc: 0.968 - ETA: 6s - loss: 0.0596 - acc: 0.968 - ETA: 6s - loss: 0.0575 - acc: 0.971 - ETA: 5s - loss: 0.0648 - acc: 0.968 - ETA: 5s - loss: 0.0620 - acc: 0.970 - ETA: 5s - loss: 0.0587 - acc: 0.972 - ETA: 5s - loss: 0.0558 - acc: 0.974 - ETA: 5s - loss: 0.0540 - acc: 0.975 - ETA: 5s - loss: 0.0519 - acc: 0.976 - ETA: 4s - loss: 0.0500 - acc: 0.977 - ETA: 4s - loss: 0.0541 - acc: 0.977 - ETA: 4s - loss: 0.0527 - acc: 0.978 - ETA: 4s - loss: 0.0531 - acc: 0.976 - ETA: 4s - loss: 0.0653 - acc: 0.975 - ETA: 3s - loss: 0.0629 - acc: 0.976 - ETA: 3s - loss: 0.0729 - acc: 0.973 - ETA: 3s - loss: 0.0712 - acc: 0.974 - ETA: 3s - loss: 0.0688 - acc: 0.975 - ETA: 3s - loss: 0.0668 - acc: 0.976 - ETA: 3s - loss: 0.0654 - acc: 0.976 - ETA: 2s - loss: 0.0641 - acc: 0.977 - ETA: 2s - loss: 0.0630 - acc: 0.978 - ETA: 2s - loss: 0.0673 - acc: 0.977 - ETA: 2s - loss: 0.0679 - acc: 0.976 - ETA: 2s - loss: 0.0680 - acc: 0.976 - ETA: 2s - loss: 0.0744 - acc: 0.974 - ETA: 1s - loss: 0.0780 - acc: 0.972 - ETA: 1s - loss: 0.0784 - acc: 0.972 - ETA: 1s - loss: 0.0811 - acc: 0.970 - ETA: 1s - loss: 0.0838 - acc: 0.968 - ETA: 1s - loss: 0.0835 - acc: 0.968 - ETA: 1s - loss: 0.0824 - acc: 0.969 - ETA: 0s - loss: 0.0969 - acc: 0.968 - ETA: 0s - loss: 0.0965 - acc: 0.968 - ETA: 0s - loss: 0.0954 - acc: 0.968 - ETA: 0s - loss: 0.0937 - acc: 0.969 - ETA: 0s - loss: 0.0917 - acc: 0.970 - ETA: 0s - loss: 0.0904 - acc: 0.970 - 8s 5ms/step - loss: 0.0903 - acc: 0.9703 - val_loss: 0.3891 - val_acc: 0.9464\n",
      "Epoch 41/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.1476 - acc: 0.937 - ETA: 8s - loss: 0.1065 - acc: 0.953 - ETA: 7s - loss: 0.0831 - acc: 0.968 - ETA: 7s - loss: 0.0709 - acc: 0.968 - ETA: 7s - loss: 0.0573 - acc: 0.975 - ETA: 7s - loss: 0.0741 - acc: 0.963 - ETA: 7s - loss: 0.1025 - acc: 0.955 - ETA: 6s - loss: 0.0993 - acc: 0.957 - ETA: 6s - loss: 0.0925 - acc: 0.958 - ETA: 6s - loss: 0.1026 - acc: 0.959 - ETA: 6s - loss: 0.0961 - acc: 0.963 - ETA: 6s - loss: 0.0930 - acc: 0.966 - ETA: 6s - loss: 0.1062 - acc: 0.959 - ETA: 5s - loss: 0.1024 - acc: 0.959 - ETA: 5s - loss: 0.1003 - acc: 0.960 - ETA: 5s - loss: 0.0973 - acc: 0.960 - ETA: 5s - loss: 0.1056 - acc: 0.959 - ETA: 5s - loss: 0.1043 - acc: 0.960 - ETA: 5s - loss: 0.1100 - acc: 0.955 - ETA: 4s - loss: 0.1089 - acc: 0.956 - ETA: 4s - loss: 0.1112 - acc: 0.953 - ETA: 4s - loss: 0.1077 - acc: 0.956 - ETA: 4s - loss: 0.1082 - acc: 0.956 - ETA: 4s - loss: 0.1062 - acc: 0.957 - ETA: 4s - loss: 0.1050 - acc: 0.957 - ETA: 3s - loss: 0.1026 - acc: 0.959 - ETA: 3s - loss: 0.1006 - acc: 0.959 - ETA: 3s - loss: 0.0988 - acc: 0.960 - ETA: 3s - loss: 0.0983 - acc: 0.960 - ETA: 3s - loss: 0.1136 - acc: 0.959 - ETA: 3s - loss: 0.1103 - acc: 0.960 - ETA: 2s - loss: 0.1110 - acc: 0.960 - ETA: 2s - loss: 0.1095 - acc: 0.960 - ETA: 2s - loss: 0.1069 - acc: 0.961 - ETA: 2s - loss: 0.1042 - acc: 0.962 - ETA: 2s - loss: 0.1023 - acc: 0.963 - ETA: 2s - loss: 0.1076 - acc: 0.962 - ETA: 1s - loss: 0.1085 - acc: 0.960 - ETA: 1s - loss: 0.1060 - acc: 0.961 - ETA: 1s - loss: 0.1036 - acc: 0.962 - ETA: 1s - loss: 0.1028 - acc: 0.963 - ETA: 1s - loss: 0.1005 - acc: 0.964 - ETA: 1s - loss: 0.0996 - acc: 0.964 - ETA: 0s - loss: 0.1053 - acc: 0.963 - ETA: 0s - loss: 0.1071 - acc: 0.961 - ETA: 0s - loss: 0.1090 - acc: 0.960 - ETA: 0s - loss: 0.1069 - acc: 0.961 - ETA: 0s - loss: 0.1057 - acc: 0.961 - ETA: 0s - loss: 0.1040 - acc: 0.962 - 8s 5ms/step - loss: 0.1032 - acc: 0.9628 - val_loss: 0.1241 - val_acc: 0.9821\n",
      "Epoch 42/50\n",
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0308 - acc: 1.000 - ETA: 8s - loss: 0.0254 - acc: 1.000 - ETA: 8s - loss: 0.0307 - acc: 0.989 - ETA: 7s - loss: 0.0312 - acc: 0.984 - ETA: 7s - loss: 0.0311 - acc: 0.987 - ETA: 7s - loss: 0.0335 - acc: 0.984 - ETA: 7s - loss: 0.0339 - acc: 0.986 - ETA: 7s - loss: 0.0466 - acc: 0.980 - ETA: 7s - loss: 0.0533 - acc: 0.979 - ETA: 6s - loss: 0.0626 - acc: 0.971 - ETA: 6s - loss: 0.0602 - acc: 0.971 - ETA: 6s - loss: 0.0557 - acc: 0.974 - ETA: 6s - loss: 0.0516 - acc: 0.976 - ETA: 6s - loss: 0.0522 - acc: 0.975 - ETA: 5s - loss: 0.0497 - acc: 0.977 - ETA: 5s - loss: 0.0484 - acc: 0.978 - ETA: 5s - loss: 0.0550 - acc: 0.977 - ETA: 5s - loss: 0.0668 - acc: 0.977 - ETA: 5s - loss: 0.0679 - acc: 0.975 - ETA: 5s - loss: 0.0664 - acc: 0.975 - ETA: 4s - loss: 0.0647 - acc: 0.974 - ETA: 4s - loss: 0.0627 - acc: 0.975 - ETA: 4s - loss: 0.0625 - acc: 0.975 - ETA: 4s - loss: 0.0600 - acc: 0.976 - ETA: 4s - loss: 0.0634 - acc: 0.976 - ETA: 4s - loss: 0.0620 - acc: 0.977 - ETA: 3s - loss: 0.0615 - acc: 0.976 - ETA: 3s - loss: 0.0624 - acc: 0.975 - ETA: 3s - loss: 0.0701 - acc: 0.975 - ETA: 3s - loss: 0.0708 - acc: 0.975 - ETA: 3s - loss: 0.0690 - acc: 0.975 - ETA: 3s - loss: 0.0709 - acc: 0.974 - ETA: 2s - loss: 0.0692 - acc: 0.975 - ETA: 2s - loss: 0.0715 - acc: 0.974 - ETA: 2s - loss: 0.0700 - acc: 0.975 - ETA: 2s - loss: 0.0715 - acc: 0.974 - ETA: 2s - loss: 0.0714 - acc: 0.973 - ETA: 2s - loss: 0.0705 - acc: 0.973 - ETA: 1s - loss: 0.0702 - acc: 0.973 - ETA: 1s - loss: 0.0700 - acc: 0.973 - ETA: 1s - loss: 0.0688 - acc: 0.974 - ETA: 1s - loss: 0.0742 - acc: 0.973 - ETA: 1s - loss: 0.0738 - acc: 0.973 - ETA: 0s - loss: 0.0726 - acc: 0.973 - ETA: 0s - loss: 0.0717 - acc: 0.974 - ETA: 0s - loss: 0.0801 - acc: 0.972 - ETA: 0s - loss: 0.0792 - acc: 0.973 - ETA: 0s - loss: 0.0807 - acc: 0.973 - ETA: 0s - loss: 0.0824 - acc: 0.972 - 9s 5ms/step - loss: 0.0827 - acc: 0.9722 - val_loss: 0.2133 - val_acc: 0.9643\n",
      "Epoch 43/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0566 - acc: 0.968 - ETA: 7s - loss: 0.0871 - acc: 0.968 - ETA: 7s - loss: 0.0766 - acc: 0.979 - ETA: 7s - loss: 0.0633 - acc: 0.984 - ETA: 7s - loss: 0.0777 - acc: 0.975 - ETA: 7s - loss: 0.0716 - acc: 0.979 - ETA: 7s - loss: 0.0631 - acc: 0.982 - ETA: 7s - loss: 0.0610 - acc: 0.984 - ETA: 7s - loss: 0.0600 - acc: 0.982 - ETA: 6s - loss: 0.0622 - acc: 0.978 - ETA: 6s - loss: 0.0703 - acc: 0.974 - ETA: 6s - loss: 0.0696 - acc: 0.974 - ETA: 6s - loss: 0.0685 - acc: 0.973 - ETA: 6s - loss: 0.0698 - acc: 0.973 - ETA: 5s - loss: 0.0669 - acc: 0.975 - ETA: 5s - loss: 0.0633 - acc: 0.976 - ETA: 5s - loss: 0.0617 - acc: 0.976 - ETA: 5s - loss: 0.0602 - acc: 0.977 - ETA: 5s - loss: 0.0679 - acc: 0.977 - ETA: 5s - loss: 0.0697 - acc: 0.975 - ETA: 4s - loss: 0.0698 - acc: 0.974 - ETA: 4s - loss: 0.0683 - acc: 0.975 - ETA: 4s - loss: 0.0670 - acc: 0.976 - ETA: 4s - loss: 0.0646 - acc: 0.977 - ETA: 4s - loss: 0.0637 - acc: 0.978 - ETA: 4s - loss: 0.0615 - acc: 0.979 - ETA: 3s - loss: 0.0594 - acc: 0.980 - ETA: 3s - loss: 0.0597 - acc: 0.979 - ETA: 3s - loss: 0.0581 - acc: 0.980 - ETA: 3s - loss: 0.0562 - acc: 0.981 - ETA: 3s - loss: 0.0550 - acc: 0.981 - ETA: 3s - loss: 0.0551 - acc: 0.981 - ETA: 2s - loss: 0.0535 - acc: 0.982 - ETA: 2s - loss: 0.0531 - acc: 0.982 - ETA: 2s - loss: 0.0528 - acc: 0.982 - ETA: 2s - loss: 0.0522 - acc: 0.982 - ETA: 2s - loss: 0.0542 - acc: 0.980 - ETA: 1s - loss: 0.0528 - acc: 0.981 - ETA: 1s - loss: 0.0515 - acc: 0.981 - ETA: 1s - loss: 0.0509 - acc: 0.981 - ETA: 1s - loss: 0.0498 - acc: 0.981 - ETA: 1s - loss: 0.0504 - acc: 0.980 - ETA: 1s - loss: 0.0495 - acc: 0.981 - ETA: 0s - loss: 0.0485 - acc: 0.981 - ETA: 0s - loss: 0.0489 - acc: 0.981 - ETA: 0s - loss: 0.0490 - acc: 0.981 - ETA: 0s - loss: 0.0489 - acc: 0.980 - ETA: 0s - loss: 0.0480 - acc: 0.981 - ETA: 0s - loss: 0.0472 - acc: 0.981 - 9s 5ms/step - loss: 0.0484 - acc: 0.9811 - val_loss: 0.1628 - val_acc: 0.9643\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 7s - loss: 0.0039 - acc: 1.000 - ETA: 7s - loss: 0.0104 - acc: 1.000 - ETA: 8s - loss: 0.0539 - acc: 0.989 - ETA: 7s - loss: 0.0479 - acc: 0.992 - ETA: 7s - loss: 0.1015 - acc: 0.987 - ETA: 7s - loss: 0.0864 - acc: 0.989 - ETA: 7s - loss: 0.0812 - acc: 0.991 - ETA: 7s - loss: 0.0743 - acc: 0.988 - ETA: 7s - loss: 0.0674 - acc: 0.989 - ETA: 6s - loss: 0.0721 - acc: 0.987 - ETA: 6s - loss: 0.0864 - acc: 0.983 - ETA: 7s - loss: 0.0940 - acc: 0.979 - ETA: 7s - loss: 0.0900 - acc: 0.980 - ETA: 7s - loss: 0.0863 - acc: 0.979 - ETA: 6s - loss: 0.0831 - acc: 0.979 - ETA: 6s - loss: 0.0796 - acc: 0.980 - ETA: 6s - loss: 0.0827 - acc: 0.979 - ETA: 6s - loss: 0.0806 - acc: 0.979 - ETA: 6s - loss: 0.0781 - acc: 0.980 - ETA: 5s - loss: 0.0769 - acc: 0.979 - ETA: 5s - loss: 0.0740 - acc: 0.980 - ETA: 5s - loss: 0.0734 - acc: 0.980 - ETA: 5s - loss: 0.0723 - acc: 0.979 - ETA: 5s - loss: 0.0843 - acc: 0.976 - ETA: 4s - loss: 0.0813 - acc: 0.977 - ETA: 4s - loss: 0.0857 - acc: 0.977 - ETA: 4s - loss: 0.0859 - acc: 0.975 - ETA: 4s - loss: 0.0834 - acc: 0.976 - ETA: 4s - loss: 0.0848 - acc: 0.974 - ETA: 3s - loss: 0.0825 - acc: 0.975 - ETA: 3s - loss: 0.0830 - acc: 0.974 - ETA: 3s - loss: 0.0835 - acc: 0.974 - ETA: 3s - loss: 0.0823 - acc: 0.975 - ETA: 3s - loss: 0.0805 - acc: 0.976 - ETA: 2s - loss: 0.0798 - acc: 0.976 - ETA: 2s - loss: 0.0777 - acc: 0.977 - ETA: 2s - loss: 0.0778 - acc: 0.977 - ETA: 2s - loss: 0.0769 - acc: 0.977 - ETA: 2s - loss: 0.0774 - acc: 0.977 - ETA: 1s - loss: 0.0783 - acc: 0.977 - ETA: 1s - loss: 0.0765 - acc: 0.977 - ETA: 1s - loss: 0.0771 - acc: 0.977 - ETA: 1s - loss: 0.0784 - acc: 0.977 - ETA: 1s - loss: 0.0769 - acc: 0.978 - ETA: 0s - loss: 0.0754 - acc: 0.978 - ETA: 0s - loss: 0.0742 - acc: 0.978 - ETA: 0s - loss: 0.0733 - acc: 0.978 - ETA: 0s - loss: 0.0734 - acc: 0.977 - ETA: 0s - loss: 0.0726 - acc: 0.978 - 9s 6ms/step - loss: 0.0723 - acc: 0.9785 - val_loss: 0.1357 - val_acc: 0.9643\n",
      "Epoch 45/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0063 - acc: 1.000 - ETA: 8s - loss: 0.0332 - acc: 0.968 - ETA: 7s - loss: 0.0270 - acc: 0.979 - ETA: 7s - loss: 0.0255 - acc: 0.984 - ETA: 7s - loss: 0.0301 - acc: 0.981 - ETA: 7s - loss: 0.0349 - acc: 0.979 - ETA: 7s - loss: 0.0425 - acc: 0.977 - ETA: 7s - loss: 0.0441 - acc: 0.976 - ETA: 7s - loss: 0.0466 - acc: 0.975 - ETA: 6s - loss: 0.0528 - acc: 0.975 - ETA: 6s - loss: 0.0541 - acc: 0.974 - ETA: 6s - loss: 0.0518 - acc: 0.976 - ETA: 6s - loss: 0.0507 - acc: 0.976 - ETA: 6s - loss: 0.0480 - acc: 0.977 - ETA: 6s - loss: 0.0465 - acc: 0.979 - ETA: 5s - loss: 0.0448 - acc: 0.980 - ETA: 5s - loss: 0.0437 - acc: 0.979 - ETA: 5s - loss: 0.0430 - acc: 0.980 - ETA: 5s - loss: 0.0441 - acc: 0.980 - ETA: 5s - loss: 0.0442 - acc: 0.979 - ETA: 4s - loss: 0.0444 - acc: 0.979 - ETA: 4s - loss: 0.0441 - acc: 0.978 - ETA: 4s - loss: 0.0424 - acc: 0.979 - ETA: 4s - loss: 0.0407 - acc: 0.980 - ETA: 4s - loss: 0.0394 - acc: 0.981 - ETA: 4s - loss: 0.0382 - acc: 0.982 - ETA: 3s - loss: 0.0376 - acc: 0.982 - ETA: 3s - loss: 0.0366 - acc: 0.983 - ETA: 3s - loss: 0.0361 - acc: 0.983 - ETA: 3s - loss: 0.0354 - acc: 0.984 - ETA: 3s - loss: 0.0356 - acc: 0.983 - ETA: 3s - loss: 0.0449 - acc: 0.982 - ETA: 2s - loss: 0.0442 - acc: 0.983 - ETA: 2s - loss: 0.0447 - acc: 0.982 - ETA: 2s - loss: 0.0436 - acc: 0.983 - ETA: 2s - loss: 0.0486 - acc: 0.981 - ETA: 2s - loss: 0.0475 - acc: 0.982 - ETA: 2s - loss: 0.0501 - acc: 0.981 - ETA: 1s - loss: 0.0489 - acc: 0.982 - ETA: 1s - loss: 0.0514 - acc: 0.981 - ETA: 1s - loss: 0.0527 - acc: 0.980 - ETA: 1s - loss: 0.0516 - acc: 0.980 - ETA: 1s - loss: 0.0510 - acc: 0.981 - ETA: 0s - loss: 0.0520 - acc: 0.980 - ETA: 0s - loss: 0.0515 - acc: 0.980 - ETA: 0s - loss: 0.0522 - acc: 0.980 - ETA: 0s - loss: 0.0549 - acc: 0.979 - ETA: 0s - loss: 0.0554 - acc: 0.979 - ETA: 0s - loss: 0.0545 - acc: 0.979 - 9s 6ms/step - loss: 0.0542 - acc: 0.9798 - val_loss: 0.0465 - val_acc: 0.9821\n",
      "Epoch 46/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0222 - acc: 1.000 - ETA: 8s - loss: 0.0256 - acc: 1.000 - ETA: 8s - loss: 0.0781 - acc: 0.979 - ETA: 8s - loss: 0.0845 - acc: 0.976 - ETA: 7s - loss: 0.0877 - acc: 0.975 - ETA: 7s - loss: 0.0751 - acc: 0.979 - ETA: 7s - loss: 0.0720 - acc: 0.982 - ETA: 7s - loss: 0.0644 - acc: 0.984 - ETA: 6s - loss: 0.0607 - acc: 0.986 - ETA: 6s - loss: 0.0591 - acc: 0.987 - ETA: 6s - loss: 0.0549 - acc: 0.988 - ETA: 6s - loss: 0.0514 - acc: 0.989 - ETA: 6s - loss: 0.0637 - acc: 0.985 - ETA: 6s - loss: 0.0683 - acc: 0.982 - ETA: 5s - loss: 0.0641 - acc: 0.983 - ETA: 5s - loss: 0.0630 - acc: 0.982 - ETA: 5s - loss: 0.0635 - acc: 0.981 - ETA: 5s - loss: 0.0613 - acc: 0.982 - ETA: 5s - loss: 0.0616 - acc: 0.981 - ETA: 5s - loss: 0.0617 - acc: 0.981 - ETA: 4s - loss: 0.0674 - acc: 0.979 - ETA: 4s - loss: 0.0653 - acc: 0.980 - ETA: 4s - loss: 0.0632 - acc: 0.981 - ETA: 4s - loss: 0.0606 - acc: 0.981 - ETA: 4s - loss: 0.0588 - acc: 0.982 - ETA: 4s - loss: 0.0570 - acc: 0.983 - ETA: 3s - loss: 0.0551 - acc: 0.983 - ETA: 3s - loss: 0.0536 - acc: 0.984 - ETA: 3s - loss: 0.0520 - acc: 0.984 - ETA: 3s - loss: 0.0518 - acc: 0.984 - ETA: 3s - loss: 0.0512 - acc: 0.983 - ETA: 3s - loss: 0.0544 - acc: 0.983 - ETA: 2s - loss: 0.0529 - acc: 0.983 - ETA: 2s - loss: 0.0519 - acc: 0.984 - ETA: 2s - loss: 0.0507 - acc: 0.984 - ETA: 2s - loss: 0.0499 - acc: 0.985 - ETA: 2s - loss: 0.0486 - acc: 0.985 - ETA: 1s - loss: 0.0474 - acc: 0.986 - ETA: 1s - loss: 0.0463 - acc: 0.986 - ETA: 1s - loss: 0.0457 - acc: 0.986 - ETA: 1s - loss: 0.0446 - acc: 0.987 - ETA: 1s - loss: 0.0438 - acc: 0.987 - ETA: 1s - loss: 0.0439 - acc: 0.986 - ETA: 0s - loss: 0.0465 - acc: 0.986 - ETA: 0s - loss: 0.0502 - acc: 0.986 - ETA: 0s - loss: 0.0495 - acc: 0.986 - ETA: 0s - loss: 0.0497 - acc: 0.986 - ETA: 0s - loss: 0.0489 - acc: 0.986 - ETA: 0s - loss: 0.0480 - acc: 0.986 - 9s 6ms/step - loss: 0.0477 - acc: 0.9867 - val_loss: 0.1941 - val_acc: 0.9643\n",
      "Epoch 47/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0098 - acc: 1.000 - ETA: 8s - loss: 0.0107 - acc: 1.000 - ETA: 8s - loss: 0.0120 - acc: 1.000 - ETA: 8s - loss: 0.0128 - acc: 1.000 - ETA: 7s - loss: 0.0155 - acc: 1.000 - ETA: 7s - loss: 0.0256 - acc: 0.994 - ETA: 7s - loss: 0.0431 - acc: 0.991 - ETA: 7s - loss: 0.0396 - acc: 0.992 - ETA: 7s - loss: 0.0352 - acc: 0.993 - ETA: 6s - loss: 0.0332 - acc: 0.993 - ETA: 6s - loss: 0.0312 - acc: 0.994 - ETA: 6s - loss: 0.0289 - acc: 0.994 - ETA: 6s - loss: 0.0279 - acc: 0.995 - ETA: 6s - loss: 0.0303 - acc: 0.993 - ETA: 6s - loss: 0.0325 - acc: 0.991 - ETA: 5s - loss: 0.0409 - acc: 0.988 - ETA: 5s - loss: 0.0406 - acc: 0.987 - ETA: 5s - loss: 0.0394 - acc: 0.987 - ETA: 5s - loss: 0.0374 - acc: 0.988 - ETA: 5s - loss: 0.0367 - acc: 0.989 - ETA: 5s - loss: 0.0394 - acc: 0.986 - ETA: 4s - loss: 0.0386 - acc: 0.987 - ETA: 4s - loss: 0.0421 - acc: 0.983 - ETA: 4s - loss: 0.0417 - acc: 0.983 - ETA: 4s - loss: 0.0404 - acc: 0.983 - ETA: 4s - loss: 0.0391 - acc: 0.984 - ETA: 3s - loss: 0.0438 - acc: 0.981 - ETA: 3s - loss: 0.0425 - acc: 0.982 - ETA: 3s - loss: 0.0416 - acc: 0.982 - ETA: 3s - loss: 0.0416 - acc: 0.982 - ETA: 3s - loss: 0.0409 - acc: 0.982 - ETA: 3s - loss: 0.0400 - acc: 0.983 - ETA: 2s - loss: 0.0398 - acc: 0.983 - ETA: 2s - loss: 0.0402 - acc: 0.983 - ETA: 2s - loss: 0.0391 - acc: 0.983 - ETA: 2s - loss: 0.0384 - acc: 0.984 - ETA: 2s - loss: 0.0376 - acc: 0.984 - ETA: 2s - loss: 0.0369 - acc: 0.985 - ETA: 1s - loss: 0.0369 - acc: 0.985 - ETA: 1s - loss: 0.0369 - acc: 0.985 - ETA: 1s - loss: 0.0361 - acc: 0.985 - ETA: 1s - loss: 0.0353 - acc: 0.985 - ETA: 1s - loss: 0.0346 - acc: 0.986 - ETA: 0s - loss: 0.0338 - acc: 0.986 - ETA: 0s - loss: 0.0335 - acc: 0.986 - ETA: 0s - loss: 0.0336 - acc: 0.986 - ETA: 0s - loss: 0.0333 - acc: 0.986 - ETA: 0s - loss: 0.0329 - acc: 0.987 - ETA: 0s - loss: 0.0322 - acc: 0.987 - 9s 6ms/step - loss: 0.0319 - acc: 0.9874 - val_loss: 0.2317 - val_acc: 0.9643\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0248 - acc: 1.000 - ETA: 8s - loss: 0.0124 - acc: 1.000 - ETA: 8s - loss: 0.0159 - acc: 1.000 - ETA: 7s - loss: 0.0121 - acc: 1.000 - ETA: 7s - loss: 0.0142 - acc: 1.000 - ETA: 7s - loss: 0.0122 - acc: 1.000 - ETA: 7s - loss: 0.0215 - acc: 0.995 - ETA: 7s - loss: 0.0351 - acc: 0.984 - ETA: 7s - loss: 0.0312 - acc: 0.986 - ETA: 6s - loss: 0.0284 - acc: 0.987 - ETA: 6s - loss: 0.0272 - acc: 0.988 - ETA: 6s - loss: 0.0302 - acc: 0.987 - ETA: 6s - loss: 0.0282 - acc: 0.988 - ETA: 6s - loss: 0.0276 - acc: 0.988 - ETA: 5s - loss: 0.0258 - acc: 0.989 - ETA: 5s - loss: 0.0244 - acc: 0.990 - ETA: 5s - loss: 0.0232 - acc: 0.990 - ETA: 5s - loss: 0.0292 - acc: 0.989 - ETA: 5s - loss: 0.0304 - acc: 0.988 - ETA: 4s - loss: 0.0362 - acc: 0.987 - ETA: 4s - loss: 0.0359 - acc: 0.988 - ETA: 4s - loss: 0.0347 - acc: 0.988 - ETA: 4s - loss: 0.0361 - acc: 0.987 - ETA: 4s - loss: 0.0359 - acc: 0.987 - ETA: 4s - loss: 0.0349 - acc: 0.987 - ETA: 4s - loss: 0.0349 - acc: 0.986 - ETA: 4s - loss: 0.0351 - acc: 0.987 - ETA: 4s - loss: 0.0380 - acc: 0.985 - ETA: 4s - loss: 0.0387 - acc: 0.984 - ETA: 3s - loss: 0.0379 - acc: 0.985 - ETA: 3s - loss: 0.0370 - acc: 0.985 - ETA: 3s - loss: 0.0362 - acc: 0.986 - ETA: 3s - loss: 0.0353 - acc: 0.986 - ETA: 3s - loss: 0.0343 - acc: 0.987 - ETA: 2s - loss: 0.0334 - acc: 0.987 - ETA: 2s - loss: 0.0340 - acc: 0.987 - ETA: 2s - loss: 0.0333 - acc: 0.987 - ETA: 2s - loss: 0.0344 - acc: 0.986 - ETA: 2s - loss: 0.0368 - acc: 0.985 - ETA: 1s - loss: 0.0359 - acc: 0.985 - ETA: 1s - loss: 0.0354 - acc: 0.986 - ETA: 1s - loss: 0.0349 - acc: 0.986 - ETA: 1s - loss: 0.0348 - acc: 0.986 - ETA: 1s - loss: 0.0342 - acc: 0.987 - ETA: 0s - loss: 0.0337 - acc: 0.987 - ETA: 0s - loss: 0.0333 - acc: 0.987 - ETA: 0s - loss: 0.0328 - acc: 0.988 - ETA: 0s - loss: 0.0357 - acc: 0.986 - ETA: 0s - loss: 0.0354 - acc: 0.986 - 10s 6ms/step - loss: 0.0350 - acc: 0.9867 - val_loss: 0.2339 - val_acc: 0.9643\n",
      "Epoch 49/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.0216 - acc: 1.000 - ETA: 8s - loss: 0.0241 - acc: 1.000 - ETA: 8s - loss: 0.0279 - acc: 1.000 - ETA: 7s - loss: 0.0244 - acc: 1.000 - ETA: 7s - loss: 0.0332 - acc: 0.993 - ETA: 7s - loss: 0.0288 - acc: 0.994 - ETA: 7s - loss: 0.0280 - acc: 0.995 - ETA: 7s - loss: 0.0249 - acc: 0.996 - ETA: 6s - loss: 0.0348 - acc: 0.993 - ETA: 6s - loss: 0.0362 - acc: 0.993 - ETA: 6s - loss: 0.0352 - acc: 0.994 - ETA: 6s - loss: 0.0427 - acc: 0.992 - ETA: 6s - loss: 0.0445 - acc: 0.990 - ETA: 6s - loss: 0.0423 - acc: 0.991 - ETA: 6s - loss: 0.0447 - acc: 0.987 - ETA: 6s - loss: 0.0421 - acc: 0.988 - ETA: 5s - loss: 0.0400 - acc: 0.989 - ETA: 5s - loss: 0.0405 - acc: 0.989 - ETA: 5s - loss: 0.0389 - acc: 0.990 - ETA: 5s - loss: 0.0371 - acc: 0.990 - ETA: 5s - loss: 0.0360 - acc: 0.991 - ETA: 5s - loss: 0.0348 - acc: 0.991 - ETA: 4s - loss: 0.0335 - acc: 0.991 - ETA: 4s - loss: 0.0324 - acc: 0.992 - ETA: 4s - loss: 0.0381 - acc: 0.988 - ETA: 4s - loss: 0.0371 - acc: 0.989 - ETA: 4s - loss: 0.0358 - acc: 0.989 - ETA: 3s - loss: 0.0383 - acc: 0.987 - ETA: 3s - loss: 0.0375 - acc: 0.988 - ETA: 3s - loss: 0.0386 - acc: 0.986 - ETA: 3s - loss: 0.0391 - acc: 0.985 - ETA: 3s - loss: 0.0380 - acc: 0.986 - ETA: 3s - loss: 0.0370 - acc: 0.986 - ETA: 2s - loss: 0.0360 - acc: 0.987 - ETA: 2s - loss: 0.0354 - acc: 0.987 - ETA: 2s - loss: 0.0366 - acc: 0.987 - ETA: 2s - loss: 0.0360 - acc: 0.987 - ETA: 2s - loss: 0.0361 - acc: 0.986 - ETA: 1s - loss: 0.0359 - acc: 0.987 - ETA: 1s - loss: 0.0350 - acc: 0.987 - ETA: 1s - loss: 0.0349 - acc: 0.987 - ETA: 1s - loss: 0.0346 - acc: 0.987 - ETA: 1s - loss: 0.0356 - acc: 0.986 - ETA: 1s - loss: 0.0383 - acc: 0.985 - ETA: 0s - loss: 0.0378 - acc: 0.986 - ETA: 0s - loss: 0.0371 - acc: 0.986 - ETA: 0s - loss: 0.0364 - acc: 0.986 - ETA: 0s - loss: 0.0359 - acc: 0.987 - ETA: 0s - loss: 0.0361 - acc: 0.986 - 9s 6ms/step - loss: 0.0365 - acc: 0.9861 - val_loss: 0.2730 - val_acc: 0.9643\n",
      "Epoch 50/50\n",
      "1584/1584 [==============================] - ETA: 8s - loss: 0.2940 - acc: 0.968 - ETA: 7s - loss: 0.1524 - acc: 0.984 - ETA: 7s - loss: 0.1119 - acc: 0.979 - ETA: 7s - loss: 0.1085 - acc: 0.976 - ETA: 7s - loss: 0.0887 - acc: 0.981 - ETA: 7s - loss: 0.0867 - acc: 0.979 - ETA: 7s - loss: 0.0761 - acc: 0.982 - ETA: 7s - loss: 0.0675 - acc: 0.984 - ETA: 6s - loss: 0.0602 - acc: 0.986 - ETA: 6s - loss: 0.0730 - acc: 0.981 - ETA: 6s - loss: 0.0679 - acc: 0.983 - ETA: 6s - loss: 0.0644 - acc: 0.984 - ETA: 6s - loss: 0.0696 - acc: 0.980 - ETA: 6s - loss: 0.0673 - acc: 0.979 - ETA: 5s - loss: 0.0640 - acc: 0.981 - ETA: 5s - loss: 0.0661 - acc: 0.980 - ETA: 5s - loss: 0.0626 - acc: 0.981 - ETA: 5s - loss: 0.0610 - acc: 0.982 - ETA: 5s - loss: 0.0596 - acc: 0.981 - ETA: 5s - loss: 0.0579 - acc: 0.982 - ETA: 4s - loss: 0.0573 - acc: 0.982 - ETA: 4s - loss: 0.0557 - acc: 0.983 - ETA: 4s - loss: 0.0599 - acc: 0.979 - ETA: 4s - loss: 0.0581 - acc: 0.980 - ETA: 4s - loss: 0.0575 - acc: 0.980 - ETA: 3s - loss: 0.0557 - acc: 0.980 - ETA: 3s - loss: 0.0560 - acc: 0.980 - ETA: 3s - loss: 0.0543 - acc: 0.981 - ETA: 3s - loss: 0.0544 - acc: 0.980 - ETA: 3s - loss: 0.0528 - acc: 0.981 - ETA: 3s - loss: 0.0519 - acc: 0.981 - ETA: 2s - loss: 0.0513 - acc: 0.981 - ETA: 2s - loss: 0.0500 - acc: 0.982 - ETA: 2s - loss: 0.0488 - acc: 0.982 - ETA: 2s - loss: 0.0482 - acc: 0.983 - ETA: 2s - loss: 0.0505 - acc: 0.982 - ETA: 2s - loss: 0.0501 - acc: 0.983 - ETA: 1s - loss: 0.0492 - acc: 0.983 - ETA: 1s - loss: 0.0484 - acc: 0.984 - ETA: 1s - loss: 0.0473 - acc: 0.984 - ETA: 1s - loss: 0.0468 - acc: 0.984 - ETA: 1s - loss: 0.0460 - acc: 0.985 - ETA: 1s - loss: 0.0450 - acc: 0.985 - ETA: 0s - loss: 0.0579 - acc: 0.984 - ETA: 0s - loss: 0.0592 - acc: 0.984 - ETA: 0s - loss: 0.0619 - acc: 0.983 - ETA: 0s - loss: 0.0610 - acc: 0.984 - ETA: 0s - loss: 0.0598 - acc: 0.984 - ETA: 0s - loss: 0.0600 - acc: 0.984 - 9s 5ms/step - loss: 0.0594 - acc: 0.9842 - val_loss: 0.1230 - val_acc: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fad094eb38>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=50,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.01125067, -0.03761831,  0.00506061, ...,  0.01135404,\n",
       "           -0.01163099,  0.01054627]],\n",
       " \n",
       "         [[ 0.000873  , -0.01929228, -0.00669033, ...,  0.02965062,\n",
       "            0.00422322, -0.02420651]],\n",
       " \n",
       "         [[-0.04785929, -0.04232047, -0.01231945, ...,  0.01878584,\n",
       "            0.09917814, -0.0047835 ]],\n",
       " \n",
       "         [[-0.12049931, -0.03172345,  0.00635783, ..., -0.07323691,\n",
       "           -0.06069348,  0.01804657]],\n",
       " \n",
       "         [[-0.01670641, -0.03143491,  0.01803452, ..., -0.01929908,\n",
       "           -0.19950385,  0.08126143]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02750266,  0.06977442, -0.0290975 , ...,  0.03676389,\n",
       "            0.00761043, -0.0290525 ]],\n",
       " \n",
       "         [[ 0.00993804, -0.00144175, -0.14186163, ..., -0.09806665,\n",
       "            0.01136503, -0.06294262]],\n",
       " \n",
       "         [[ 0.0057756 , -0.01529799, -0.04213442, ..., -0.04734529,\n",
       "            0.00867265, -0.05124036]],\n",
       " \n",
       "         [[ 0.00039044,  0.08845065,  0.0944014 , ..., -0.14531694,\n",
       "           -0.03648807, -0.05597885]],\n",
       " \n",
       "         [[ 0.04590287, -0.08362719, -0.03845377, ...,  0.00508509,\n",
       "            0.04756454, -0.0078969 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03333125, -0.03434365,  0.03412451, ...,  0.0682218 ,\n",
       "            0.07722478, -0.02718456]],\n",
       " \n",
       "         [[ 0.01939576,  0.03313138, -0.00663348, ...,  0.01755081,\n",
       "            0.01766334, -0.01822876]],\n",
       " \n",
       "         [[-0.00446085,  0.0220068 , -0.04976514, ...,  0.02009689,\n",
       "            0.03671155, -0.02113833]],\n",
       " \n",
       "         [[-0.02742937, -0.04943479,  0.03097455, ...,  0.08388992,\n",
       "            0.01217949,  0.05109369]],\n",
       " \n",
       "         [[-0.02041742,  0.07364459,  0.06637469, ...,  0.02033745,\n",
       "            0.04631241,  0.06234662]]],\n",
       " \n",
       " \n",
       "        [[[-0.1400964 ,  0.07915279, -0.13265744, ..., -0.12072382,\n",
       "           -0.08134715, -0.0654413 ]],\n",
       " \n",
       "         [[-0.1087299 , -0.10970853, -0.11553682, ..., -0.13679476,\n",
       "            0.03517116, -0.19998507]],\n",
       " \n",
       "         [[-0.020394  ,  0.03711457, -0.10855198, ..., -0.07557368,\n",
       "            0.01717626, -0.07459547]],\n",
       " \n",
       "         [[-0.06327458, -0.04265371, -0.0623996 , ...,  0.03654877,\n",
       "           -0.05567004, -0.16587141]],\n",
       " \n",
       "         [[ 0.08349611, -0.08310801, -0.03417126, ...,  0.04969986,\n",
       "           -0.03295277, -0.22779651]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06326789, -0.04178488, -0.076914  , ..., -0.01288296,\n",
       "           -0.05148019, -0.17739065]],\n",
       " \n",
       "         [[-0.05859588, -0.01358173, -0.03690499, ..., -0.02334701,\n",
       "            0.04613065,  0.10566068]],\n",
       " \n",
       "         [[-0.13434808, -0.10275938, -0.03897975, ..., -0.04680995,\n",
       "           -0.04085713, -0.25899068]],\n",
       " \n",
       "         [[-0.01575499, -0.00331032,  0.01941715, ...,  0.02538046,\n",
       "           -0.02864002,  0.09530149]],\n",
       " \n",
       "         [[-0.17508316,  0.03888259, -0.06593119, ...,  0.08363419,\n",
       "            0.09997288,  0.05948941]]]], dtype=float32),\n",
       " array([-3.42686065e-02, -1.64770022e-01, -2.20763013e-02, -1.05615094e-01,\n",
       "        -1.54612273e-01,  1.22899219e-04,  1.97039340e-02, -1.02314837e-02,\n",
       "        -1.47096798e-01, -1.04319975e-01, -8.66243336e-03, -3.65388431e-02,\n",
       "        -9.88891125e-02, -4.97629568e-02, -5.61462529e-02, -3.36015895e-02,\n",
       "        -1.22952282e-01, -6.01609889e-03,  3.06546763e-02, -8.00232589e-03,\n",
       "        -2.27032587e-01, -2.00764000e-01,  1.75547153e-02, -8.26705843e-02,\n",
       "        -1.75180938e-02, -1.79271139e-02, -2.36315262e-02, -3.97530980e-02,\n",
       "        -7.52888620e-02, -1.01762740e-02, -1.28518179e-01, -1.49407443e-02,\n",
       "        -2.88441218e-02,  1.04452539e-02, -1.87649846e-01, -4.37179506e-02,\n",
       "        -3.10629699e-02, -1.12551853e-01, -5.98436333e-02,  2.44213641e-03,\n",
       "        -1.05000250e-02,  3.87316868e-02,  1.25374749e-01, -1.08453296e-02,\n",
       "        -7.51830861e-02, -6.49747963e-04,  5.15649933e-03, -7.34220967e-02,\n",
       "        -3.68790515e-02,  6.87900174e-04, -2.79192626e-02,  6.47648657e-03,\n",
       "        -1.04434462e-02, -8.41807015e-03, -1.32981315e-02, -6.56285463e-03,\n",
       "        -3.15684937e-02, -4.84815687e-02, -4.04288148e-04, -6.06565624e-02,\n",
       "        -7.13826418e-02, -3.96285206e-02, -2.80764680e-02, -4.96412776e-02],\n",
       "       dtype=float32),\n",
       " array([[[[-1.62136480e-02,  2.76612211e-02,  1.03903399e-03, ...,\n",
       "           -3.50535959e-02,  3.44570577e-02, -1.91696454e-02],\n",
       "          [-3.82532403e-02,  1.60066653e-02, -7.88931269e-04, ...,\n",
       "            1.58929657e-02,  2.60782875e-02, -2.97142519e-03],\n",
       "          [ 2.52352487e-02,  4.56911605e-03, -7.81773590e-03, ...,\n",
       "           -1.95136704e-02,  2.52785888e-02,  8.26112553e-03],\n",
       "          ...,\n",
       "          [-4.52827942e-03, -3.80506366e-02, -3.48054804e-02, ...,\n",
       "           -2.32553706e-02, -6.74839877e-03, -4.66592014e-02],\n",
       "          [ 1.01543786e-02, -3.30572575e-02, -7.04950606e-03, ...,\n",
       "           -5.68276942e-02,  6.11284887e-03,  2.23248964e-03],\n",
       "          [-3.70373949e-02, -4.75911200e-02,  1.06767379e-02, ...,\n",
       "           -2.91142464e-02, -2.37455014e-02, -2.95400191e-02]],\n",
       " \n",
       "         [[-3.93860452e-02, -2.08760146e-02, -1.40330233e-02, ...,\n",
       "           -3.79134226e-03, -1.64686721e-02,  8.49962700e-03],\n",
       "          [-2.32987404e-02, -2.90663559e-02,  2.41798349e-02, ...,\n",
       "           -3.22378911e-02, -3.10656074e-02, -2.36295946e-02],\n",
       "          [ 1.37814945e-02,  1.59066878e-02, -4.09501940e-02, ...,\n",
       "           -1.54556648e-03, -2.06475612e-03, -3.78151797e-02],\n",
       "          ...,\n",
       "          [ 3.58130666e-03, -8.36731214e-03, -1.82543194e-03, ...,\n",
       "           -3.52295935e-02, -3.85940680e-03,  1.80454664e-02],\n",
       "          [ 2.34537348e-02,  2.49012467e-03, -3.54647376e-02, ...,\n",
       "           -3.46712247e-02, -2.78388821e-02,  2.35503260e-02],\n",
       "          [-2.15529986e-02, -2.31864136e-02, -8.05487949e-03, ...,\n",
       "           -3.64254601e-02, -2.49368921e-02,  7.70797208e-03]],\n",
       " \n",
       "         [[ 4.50432906e-03, -1.95621811e-02,  2.76003573e-02, ...,\n",
       "            1.15348781e-02,  3.04451473e-02,  5.84337255e-03],\n",
       "          [ 1.59239639e-02, -2.93032899e-02, -1.87465232e-02, ...,\n",
       "           -1.37194749e-02, -2.77376119e-02, -5.03709652e-02],\n",
       "          [-2.42148712e-02,  1.27392728e-02, -6.31400011e-03, ...,\n",
       "           -4.46089618e-02, -1.85306054e-02, -3.89564782e-02],\n",
       "          ...,\n",
       "          [-5.17472811e-03,  5.69760753e-03, -4.18533497e-02, ...,\n",
       "           -1.43852355e-02, -6.55198051e-03, -3.47631648e-02],\n",
       "          [ 6.69421349e-03,  3.24943801e-03, -2.51426771e-02, ...,\n",
       "            4.59474372e-03, -3.36930752e-02, -1.75551753e-02],\n",
       "          [-3.63281183e-02,  4.15890710e-03, -2.02957280e-02, ...,\n",
       "            1.46407383e-02, -2.03698371e-02,  1.49524789e-02]],\n",
       " \n",
       "         [[-2.52486356e-02, -1.21237943e-02, -1.88682284e-02, ...,\n",
       "           -9.74472438e-04, -1.69583072e-03, -7.73613453e-02],\n",
       "          [ 2.48140888e-03,  5.05988440e-03,  6.01300737e-03, ...,\n",
       "            1.25633534e-02,  8.81064683e-03, -3.98119204e-02],\n",
       "          [ 4.04118076e-02, -2.62174662e-02, -3.39634088e-03, ...,\n",
       "           -4.90251649e-03, -2.31260359e-02, -1.79657806e-02],\n",
       "          ...,\n",
       "          [ 1.27050129e-03,  1.65534560e-02, -3.93576957e-02, ...,\n",
       "           -1.94156670e-03, -5.40637877e-04, -4.18042168e-02],\n",
       "          [-9.25946608e-03, -4.62984182e-02,  1.33122513e-02, ...,\n",
       "            1.04683149e-03, -2.76203342e-02, -2.83679254e-02],\n",
       "          [-2.57770531e-03, -4.16537672e-02, -2.70397831e-02, ...,\n",
       "            1.57148428e-02, -2.50167609e-03, -3.29325944e-02]],\n",
       " \n",
       "         [[ 1.06034763e-02, -3.09551582e-02, -9.10031702e-03, ...,\n",
       "            1.44030654e-03, -1.02903452e-02,  1.98457204e-02],\n",
       "          [ 2.73546446e-02,  2.44304314e-02, -3.86578515e-02, ...,\n",
       "            2.31656376e-02, -3.34191136e-02, -3.09014991e-02],\n",
       "          [ 4.90157912e-03, -2.95538120e-02, -3.00403312e-02, ...,\n",
       "           -2.26956559e-03, -2.67320015e-02, -3.34158726e-02],\n",
       "          ...,\n",
       "          [-1.38544077e-02,  2.08071824e-02,  9.22681391e-03, ...,\n",
       "            7.12137111e-03, -3.44071351e-02,  2.19765194e-02],\n",
       "          [ 7.41554657e-03,  5.01314527e-04, -1.53735038e-02, ...,\n",
       "           -2.25997791e-02, -2.51709074e-02, -1.76140405e-02],\n",
       "          [ 2.76562739e-02, -5.32501936e-03,  2.03644224e-02, ...,\n",
       "           -3.82757336e-02, -2.88720597e-02, -4.52393964e-02]]],\n",
       " \n",
       " \n",
       "        [[[-3.85141447e-02,  2.29081921e-02, -3.85189019e-02, ...,\n",
       "           -6.28409069e-03,  1.15764579e-02,  2.44767405e-02],\n",
       "          [-1.51448855e-02, -9.85268597e-03, -3.80162895e-02, ...,\n",
       "           -3.79080698e-02, -3.08896620e-02, -1.27265900e-02],\n",
       "          [-3.80625948e-02,  1.70317926e-02, -3.33062396e-03, ...,\n",
       "            1.04683610e-02, -2.43564397e-02, -1.43578080e-02],\n",
       "          ...,\n",
       "          [-4.12560850e-02,  7.51558749e-04, -1.56888179e-02, ...,\n",
       "            1.93784223e-03,  4.02598456e-03,  2.12833062e-02],\n",
       "          [-2.35508736e-02,  1.59800798e-02, -1.89211369e-02, ...,\n",
       "           -2.63085123e-02, -3.28894593e-02, -4.16786559e-02],\n",
       "          [ 2.34151445e-02,  1.43303825e-02,  1.48731498e-02, ...,\n",
       "           -6.11958699e-03, -4.82455269e-02,  6.44261949e-04]],\n",
       " \n",
       "         [[ 5.46895573e-03,  2.80962442e-03,  6.55058306e-03, ...,\n",
       "           -3.10185850e-02, -1.62745062e-02,  1.84732098e-02],\n",
       "          [ 2.90422216e-02,  1.05631240e-02, -2.18642261e-02, ...,\n",
       "           -1.95106007e-02, -3.46637294e-02, -1.76023655e-02],\n",
       "          [ 1.81506909e-02,  1.19234407e-02,  7.56970188e-03, ...,\n",
       "           -3.93119417e-02, -3.27800289e-02,  7.98702054e-03],\n",
       "          ...,\n",
       "          [-9.15020239e-03, -3.43832113e-02,  6.12626737e-03, ...,\n",
       "            3.56867872e-02,  2.07995512e-02, -1.33265983e-02],\n",
       "          [ 2.17452981e-02,  7.63563858e-03,  1.37347234e-02, ...,\n",
       "            2.34209030e-04, -3.97213884e-02,  1.46073150e-02],\n",
       "          [-3.84834595e-02, -4.19194438e-02,  3.89362895e-03, ...,\n",
       "            1.49581460e-02, -4.10712361e-02,  1.67361926e-02]],\n",
       " \n",
       "         [[-7.16450391e-03, -5.84787363e-03, -2.59042978e-02, ...,\n",
       "            1.00109437e-02,  1.90076958e-02, -1.11577057e-04],\n",
       "          [-3.75741273e-02, -4.00926620e-02,  2.22549103e-02, ...,\n",
       "            6.82531390e-03,  1.80363860e-02, -4.47543524e-02],\n",
       "          [ 3.00024897e-02, -3.54276923e-03,  7.11603975e-03, ...,\n",
       "            1.81542728e-02, -1.36708831e-02, -1.42183807e-03],\n",
       "          ...,\n",
       "          [-3.32415253e-02, -1.21797323e-02, -6.13069686e-04, ...,\n",
       "            2.89557390e-02, -1.88184790e-02,  2.68127024e-03],\n",
       "          [-1.47875352e-02, -3.32271978e-02, -3.30361202e-02, ...,\n",
       "            1.49333542e-02, -9.64779500e-03,  4.78145760e-03],\n",
       "          [ 1.51071949e-02, -1.79807134e-02,  1.08889559e-04, ...,\n",
       "           -3.43481041e-02, -3.07726916e-02, -5.45685217e-02]],\n",
       " \n",
       "         [[ 2.91220378e-02, -1.11685516e-02,  8.47473182e-03, ...,\n",
       "           -1.71025414e-02, -3.14706825e-02, -2.36029048e-02],\n",
       "          [-3.42264175e-02, -1.35974474e-02,  2.06040796e-02, ...,\n",
       "           -2.75251959e-02, -1.95172299e-02, -3.67676690e-02],\n",
       "          [ 3.58248390e-02, -1.89901665e-02,  2.46466938e-02, ...,\n",
       "            1.75645594e-02,  1.03079500e-02, -1.01237290e-03],\n",
       "          ...,\n",
       "          [-3.28916721e-02,  3.72611126e-03, -2.09169164e-02, ...,\n",
       "           -4.12443504e-02,  2.65704095e-03, -5.33126146e-02],\n",
       "          [ 2.96410546e-02, -8.48363340e-03, -6.31526113e-04, ...,\n",
       "            2.05890089e-02, -2.80769747e-02,  3.96365747e-02],\n",
       "          [ 1.18285678e-02, -2.94369236e-02, -1.21067716e-02, ...,\n",
       "           -3.20706852e-02, -5.57544408e-03, -2.67519373e-02]],\n",
       " \n",
       "         [[-1.92892961e-02, -1.03976605e-02, -3.45471725e-02, ...,\n",
       "            2.92114783e-02, -1.75124127e-02, -3.85967717e-02],\n",
       "          [ 6.56023435e-03,  2.29832307e-02, -1.49519211e-02, ...,\n",
       "           -6.04052655e-03, -4.34874110e-02,  8.00157990e-03],\n",
       "          [ 7.51338259e-04, -4.04504165e-02, -2.94195232e-03, ...,\n",
       "           -6.13209838e-03, -2.05913130e-02, -5.88474236e-02],\n",
       "          ...,\n",
       "          [-7.78637733e-03, -4.24972735e-03,  1.29215969e-02, ...,\n",
       "            1.79687683e-02,  3.56245302e-02, -2.39057885e-03],\n",
       "          [ 5.74884063e-04, -2.76147611e-02, -7.29293446e-04, ...,\n",
       "           -3.53355333e-02,  2.03127973e-02,  3.30293849e-02],\n",
       "          [-2.84932442e-02,  3.92521644e-04, -1.55695528e-02, ...,\n",
       "           -3.90480906e-02,  3.31429914e-02, -2.07642633e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.01922834e-02,  8.66750721e-03,  2.37791557e-02, ...,\n",
       "            2.65440401e-02, -3.06811254e-03,  2.54096854e-02],\n",
       "          [ 1.51790446e-03,  7.12284073e-03, -1.35901812e-02, ...,\n",
       "           -7.63453403e-03,  4.67344513e-03,  1.19067235e-02],\n",
       "          [ 3.17890309e-02,  1.52757019e-02, -3.72853875e-02, ...,\n",
       "           -3.02379169e-02, -2.91409041e-03,  3.06492746e-02],\n",
       "          ...,\n",
       "          [-3.50349285e-02, -2.27459762e-02, -2.74402853e-02, ...,\n",
       "           -2.29473319e-02,  5.29745501e-03,  2.81731542e-02],\n",
       "          [ 3.43356282e-02, -1.24044549e-02, -1.40313469e-02, ...,\n",
       "           -3.20242383e-02,  2.16233637e-02, -1.77261401e-02],\n",
       "          [ 1.55234160e-02,  1.02314064e-02,  2.81377370e-03, ...,\n",
       "           -3.33287269e-02, -4.76126969e-02, -1.66276917e-02]],\n",
       " \n",
       "         [[ 6.13554008e-03,  2.21645087e-02, -2.75729205e-02, ...,\n",
       "           -3.03528793e-02,  1.58080216e-02, -1.46750631e-02],\n",
       "          [-1.80323366e-02, -2.28558406e-02, -4.20345087e-03, ...,\n",
       "           -5.10103023e-03, -2.33597625e-02,  1.26311621e-02],\n",
       "          [-2.14557536e-02, -4.23359089e-02,  1.86930317e-02, ...,\n",
       "            3.68797290e-03, -4.53890264e-02,  1.65469944e-02],\n",
       "          ...,\n",
       "          [-1.06614176e-02, -4.40447181e-02,  9.30929382e-04, ...,\n",
       "            7.10410124e-04,  1.22292945e-02,  7.83996750e-03],\n",
       "          [-9.08774696e-03, -2.45076735e-02,  2.05394942e-02, ...,\n",
       "            1.74813140e-02, -1.34332394e-02,  1.06739486e-02],\n",
       "          [ 1.15713673e-02, -1.08856446e-04, -3.27933766e-02, ...,\n",
       "           -1.16884299e-02,  2.27579121e-02,  1.31852673e-02]],\n",
       " \n",
       "         [[ 3.02444324e-02, -1.36808055e-02, -2.62186788e-02, ...,\n",
       "           -1.34149892e-03,  2.53772736e-03, -9.72502679e-03],\n",
       "          [-9.28097114e-04, -2.62844190e-02,  1.86880957e-02, ...,\n",
       "           -4.47504176e-03, -1.70477740e-02, -1.08984476e-02],\n",
       "          [ 6.92703016e-03, -4.12536860e-02, -1.30325966e-02, ...,\n",
       "           -2.18814369e-02,  6.93031913e-03,  5.33542857e-02],\n",
       "          ...,\n",
       "          [ 2.25152355e-02,  1.26039702e-02,  2.39398442e-02, ...,\n",
       "           -2.72981822e-02,  1.90511700e-02, -7.40411952e-02],\n",
       "          [-1.57796182e-02,  6.04847912e-03,  8.27926770e-03, ...,\n",
       "           -2.39451919e-02, -3.54885273e-02, -2.50999797e-02],\n",
       "          [-3.98977771e-02, -3.14097665e-02,  1.40947625e-02, ...,\n",
       "            9.86938644e-03, -1.98660884e-02, -8.10194481e-03]],\n",
       " \n",
       "         [[-3.22272852e-02, -3.78183275e-02, -1.04305297e-02, ...,\n",
       "            1.25180269e-02,  2.67656241e-03, -5.47675323e-03],\n",
       "          [-2.17140801e-02, -3.98856960e-02, -3.79184708e-02, ...,\n",
       "           -3.12445816e-02, -1.30428281e-02, -5.65570546e-03],\n",
       "          [-7.98720587e-03, -3.47989649e-02, -3.03948415e-03, ...,\n",
       "            1.26050645e-02,  2.11270638e-02, -1.48143070e-02],\n",
       "          ...,\n",
       "          [-1.23170605e-02, -2.05292162e-02, -8.08008388e-03, ...,\n",
       "           -2.27782922e-03, -1.23624951e-02, -3.58036458e-02],\n",
       "          [ 2.05046404e-03, -2.04694215e-02,  4.84498357e-03, ...,\n",
       "           -7.62943085e-03,  1.30954543e-02, -5.71371838e-02],\n",
       "          [ 2.48339791e-02, -4.91943173e-02, -2.01745499e-02, ...,\n",
       "           -3.18305343e-02,  1.76483542e-02, -1.58861820e-02]],\n",
       " \n",
       "         [[ 5.73342026e-04,  5.84876677e-03,  2.80444063e-02, ...,\n",
       "            1.67424195e-02,  2.26551034e-02, -4.80327122e-02],\n",
       "          [-3.58454548e-02,  1.17675131e-02, -1.27221541e-02, ...,\n",
       "            1.83182266e-02, -4.96262219e-03,  3.41388360e-02],\n",
       "          [-3.64830680e-02, -1.51707428e-02, -2.18320154e-02, ...,\n",
       "            1.42254112e-02, -1.50152203e-03,  3.65707353e-02],\n",
       "          ...,\n",
       "          [-6.63397310e-04, -2.31614765e-02,  2.33083460e-02, ...,\n",
       "           -1.42427087e-02,  1.11536495e-02,  3.31954695e-02],\n",
       "          [-1.46978395e-02, -2.49970946e-02,  2.27924511e-02, ...,\n",
       "            5.07681398e-03, -2.23061554e-02, -3.44250798e-02],\n",
       "          [-2.73846257e-02,  2.99594626e-02,  1.03868600e-02, ...,\n",
       "           -3.17721441e-02, -3.39225717e-02,  1.09184608e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 9.97893978e-04,  5.71162114e-03, -1.76692884e-02, ...,\n",
       "           -2.14163326e-02,  1.52201233e-02, -6.09294558e-03],\n",
       "          [-2.20839046e-02,  2.12223642e-02, -8.53111129e-03, ...,\n",
       "            2.33693253e-02, -7.50849210e-03,  1.35073159e-02],\n",
       "          [-5.43458760e-03, -2.50042398e-02, -3.26922759e-02, ...,\n",
       "            9.73305199e-03, -1.42407008e-02,  1.78365912e-02],\n",
       "          ...,\n",
       "          [-3.40191498e-02, -4.10956740e-02, -4.84868698e-02, ...,\n",
       "            4.56043752e-03,  1.59394145e-02,  2.06756219e-03],\n",
       "          [-1.83041934e-02, -2.10525300e-02, -4.20387648e-02, ...,\n",
       "            2.87598129e-02,  9.49198939e-03, -3.19551602e-02],\n",
       "          [-4.54413425e-03, -2.07111500e-02, -4.03795345e-03, ...,\n",
       "            1.64272767e-02, -5.45546832e-03, -3.12359855e-02]],\n",
       " \n",
       "         [[-3.24657336e-02, -3.39028649e-02, -1.40624270e-02, ...,\n",
       "           -1.96950771e-02,  5.64716756e-03,  1.53081315e-02],\n",
       "          [-5.32860868e-03, -1.97559055e-02,  2.99944468e-02, ...,\n",
       "           -1.62370671e-02, -2.92761009e-02, -1.26882493e-02],\n",
       "          [ 2.54588537e-02, -3.49735618e-02,  5.55549702e-03, ...,\n",
       "           -4.01679203e-02, -3.29067116e-03, -1.28090894e-02],\n",
       "          ...,\n",
       "          [-1.65096000e-02,  2.27840655e-02, -3.78512964e-02, ...,\n",
       "           -1.71020310e-02,  3.03356163e-03, -1.79784652e-02],\n",
       "          [-2.24660840e-02, -2.04013102e-02, -2.04109494e-02, ...,\n",
       "           -4.58893850e-02, -1.64119527e-02,  2.32246630e-02],\n",
       "          [-2.40233308e-03,  1.14831654e-02, -2.63192076e-02, ...,\n",
       "           -1.35851139e-02, -8.75502545e-03,  8.34433455e-03]],\n",
       " \n",
       "         [[-2.73285098e-02, -3.32623869e-02, -9.55912191e-03, ...,\n",
       "            1.92517396e-02,  1.26846684e-02, -2.60293335e-02],\n",
       "          [-2.96131019e-02,  1.09367240e-02, -3.47378589e-02, ...,\n",
       "           -3.88459638e-02,  9.92119778e-03, -4.09693569e-02],\n",
       "          [-1.19253912e-03, -4.42517884e-02,  2.68133953e-02, ...,\n",
       "            9.86308046e-03, -2.92309001e-02, -4.51122820e-02],\n",
       "          ...,\n",
       "          [-7.47149996e-03, -3.08654830e-03, -3.37534510e-02, ...,\n",
       "           -3.29815969e-02,  8.85421876e-03, -2.00684555e-02],\n",
       "          [-4.30638008e-02, -4.56660427e-02,  1.50725886e-03, ...,\n",
       "            3.16753499e-02, -3.52614722e-03, -5.55479154e-02],\n",
       "          [-3.88648137e-02, -1.29975965e-02,  4.25545077e-05, ...,\n",
       "            3.53172305e-03, -1.86837185e-02, -3.18555022e-03]],\n",
       " \n",
       "         [[-9.55918990e-03,  7.94277620e-03, -2.66689286e-02, ...,\n",
       "           -1.44476658e-02, -6.24621706e-03, -1.71792377e-02],\n",
       "          [-4.72781993e-03, -2.71198861e-02,  5.70636615e-03, ...,\n",
       "           -1.26606775e-02, -2.05220487e-02, -1.80306844e-02],\n",
       "          [-6.32155826e-03,  1.77748650e-02, -3.35825570e-02, ...,\n",
       "           -2.77740415e-02, -3.82228307e-02, -3.66424099e-02],\n",
       "          ...,\n",
       "          [-1.40236393e-02,  2.09925082e-02, -1.39525263e-02, ...,\n",
       "            2.31944602e-02, -9.68723465e-03, -4.39609820e-03],\n",
       "          [ 2.41401568e-02, -1.77770900e-03, -3.34462225e-02, ...,\n",
       "           -3.91727313e-02, -1.04811201e-02, -5.05748466e-02],\n",
       "          [-1.86230578e-02, -6.75654691e-03, -7.45613361e-03, ...,\n",
       "            4.39100759e-03, -2.05310956e-02, -6.05247356e-02]],\n",
       " \n",
       "         [[ 8.06942768e-03, -2.92320102e-02, -4.12421906e-03, ...,\n",
       "            1.76112987e-02,  2.02969089e-02,  3.15086842e-02],\n",
       "          [ 2.10964568e-02, -2.96512656e-02, -8.18937179e-03, ...,\n",
       "           -5.72556630e-03,  1.17514608e-02, -3.86946276e-02],\n",
       "          [-2.79036108e-02, -3.54806781e-02,  1.74969714e-02, ...,\n",
       "           -8.40444025e-03,  2.95555666e-02,  5.27303852e-02],\n",
       "          ...,\n",
       "          [-2.73079313e-02, -6.28638500e-03,  1.99591201e-02, ...,\n",
       "            1.38915507e-02, -1.18998056e-02, -2.21719090e-02],\n",
       "          [-2.00932268e-02, -1.87559817e-02,  7.28881359e-03, ...,\n",
       "            9.08773765e-03, -1.38547104e-02, -1.52155505e-02],\n",
       "          [ 2.61955205e-02,  1.81928407e-02,  2.87135746e-02, ...,\n",
       "            3.44285034e-02, -1.41346157e-02,  7.42093548e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 3.38074863e-02,  2.16212459e-02, -1.26053253e-02, ...,\n",
       "           -1.11496365e-02, -8.17824155e-03,  1.14555480e-02],\n",
       "          [ 1.65778324e-02,  2.42491513e-02,  8.04133620e-03, ...,\n",
       "           -1.04307206e-02,  1.99725442e-02, -3.48330513e-02],\n",
       "          [-7.46530388e-03, -1.90328751e-02,  1.89895071e-02, ...,\n",
       "           -4.59182374e-02, -2.84424778e-02,  2.46698558e-02],\n",
       "          ...,\n",
       "          [-3.11740264e-02,  2.93038189e-02,  1.34703266e-02, ...,\n",
       "           -1.49064995e-02, -2.54349541e-02,  7.73894542e-04],\n",
       "          [-9.66612436e-03,  1.16764251e-02, -2.69832630e-02, ...,\n",
       "            5.31706121e-03,  1.05048325e-02, -3.28498669e-02],\n",
       "          [ 9.93150380e-03, -4.77383882e-02,  5.28393034e-03, ...,\n",
       "           -1.69479027e-02,  1.41646983e-02,  2.69780797e-03]],\n",
       " \n",
       "         [[ 2.70586759e-02,  5.89631709e-05, -2.76813079e-02, ...,\n",
       "           -4.48898114e-02,  2.62553003e-02, -1.73673443e-02],\n",
       "          [ 2.85811499e-02,  8.25145468e-03,  1.01183383e-02, ...,\n",
       "           -3.24500911e-02,  1.74935404e-02, -1.47102810e-02],\n",
       "          [ 2.37357300e-02, -1.81177224e-04, -2.35350635e-02, ...,\n",
       "           -2.48426795e-02,  1.08511699e-03, -1.20002767e-02],\n",
       "          ...,\n",
       "          [-1.01340814e-02, -7.26811821e-03, -1.16400709e-02, ...,\n",
       "            5.51773841e-03, -3.78968902e-02, -7.60013377e-03],\n",
       "          [ 1.27711194e-02,  1.95406582e-02,  2.21632216e-02, ...,\n",
       "            2.46357429e-03, -1.30869821e-02, -2.22320650e-02],\n",
       "          [ 3.09857130e-02,  3.49108200e-03, -2.65590884e-02, ...,\n",
       "            4.36375476e-03,  2.66359057e-02, -2.55475268e-02]],\n",
       " \n",
       "         [[-1.35042612e-02, -1.56371072e-02, -1.50118740e-02, ...,\n",
       "            5.09875687e-03,  3.20331715e-02,  3.53188515e-02],\n",
       "          [ 2.92109437e-02,  2.54273415e-03, -3.81426769e-03, ...,\n",
       "           -4.16225791e-02,  1.15380492e-02,  2.72882227e-02],\n",
       "          [ 1.58921946e-02,  2.01827530e-02,  1.61859859e-02, ...,\n",
       "           -2.73425691e-02,  1.13001922e-02, -6.54921085e-02],\n",
       "          ...,\n",
       "          [ 5.61755663e-03,  5.77656412e-03, -6.90191286e-03, ...,\n",
       "           -7.77220214e-03,  2.96825916e-02, -5.78418793e-03],\n",
       "          [-2.96357069e-02,  9.50041693e-03, -1.07365092e-02, ...,\n",
       "           -2.69768480e-02, -1.57702416e-02,  3.22814062e-02],\n",
       "          [-1.20895086e-02, -2.97408663e-02, -1.01321936e-02, ...,\n",
       "            7.90804811e-03,  1.47227652e-03, -3.82924229e-02]],\n",
       " \n",
       "         [[-1.74408816e-02,  1.63000692e-02,  2.84907855e-02, ...,\n",
       "           -2.55951490e-02,  2.91573964e-02,  5.76500827e-03],\n",
       "          [-1.03517976e-02, -4.16733063e-04, -3.38575244e-02, ...,\n",
       "            5.63177699e-03,  2.61211628e-03, -2.86151040e-02],\n",
       "          [ 1.34605961e-02,  2.26248391e-02, -2.41542067e-02, ...,\n",
       "           -3.37035805e-02, -2.26598382e-02, -2.69440562e-02],\n",
       "          ...,\n",
       "          [-8.88357684e-03, -3.96127589e-02, -6.62724953e-04, ...,\n",
       "            3.41066788e-03,  2.63716597e-02, -2.31371317e-02],\n",
       "          [-1.98595915e-02, -1.85107850e-02, -2.60885945e-03, ...,\n",
       "           -3.18086781e-02, -1.41948275e-02, -3.76110747e-02],\n",
       "          [-1.56023400e-02, -3.78178656e-02, -6.10752078e-03, ...,\n",
       "            1.88206397e-02, -3.33904251e-02, -1.83571205e-02]],\n",
       " \n",
       "         [[-4.01978865e-02,  2.33177263e-02,  2.94596795e-02, ...,\n",
       "           -3.63077782e-02, -2.91533675e-02, -3.64010297e-02],\n",
       "          [-3.71345989e-02, -2.31507551e-02, -3.82102933e-03, ...,\n",
       "           -3.42456251e-02, -1.60090216e-02,  1.23171145e-02],\n",
       "          [ 1.64667666e-02, -1.98888350e-02, -3.28029580e-02, ...,\n",
       "            1.86793634e-03,  2.96278903e-03,  1.58903394e-02],\n",
       "          ...,\n",
       "          [-5.84741938e-04, -3.43858711e-02,  2.15143450e-02, ...,\n",
       "            1.23205699e-03, -1.63937602e-02, -1.90015696e-02],\n",
       "          [ 1.21147037e-02, -3.97283994e-02, -3.29249050e-03, ...,\n",
       "           -4.15804721e-02,  1.01386243e-02, -1.55591117e-02],\n",
       "          [-1.98679548e-02,  1.19530791e-02,  2.64391322e-02, ...,\n",
       "            6.30507478e-03, -2.70224456e-02,  9.62311868e-03]]]],\n",
       "       dtype=float32),\n",
       " array([-0.01628762, -0.01139544, -0.00968316, -0.0111745 , -0.01778685,\n",
       "        -0.01114385, -0.00683997, -0.00556129, -0.01480785,  0.03849648,\n",
       "        -0.0046523 ,  0.02611945, -0.01177922,  0.06631257, -0.00214053,\n",
       "        -0.01553465,  0.12402521, -0.01070835,  0.13960207,  0.0174553 ,\n",
       "        -0.02240624, -0.02076955, -0.0147795 , -0.03316634,  0.07673139,\n",
       "         0.03889538,  0.0679544 , -0.03056514,  0.00140873,  0.10197166,\n",
       "        -0.01271068, -0.01581588, -0.01248808,  0.07410617, -0.01792086,\n",
       "        -0.01604489, -0.01022593, -0.01402753, -0.01423414, -0.02208258,\n",
       "        -0.00898106, -0.03491667, -0.01251738, -0.02326551, -0.0298228 ,\n",
       "        -0.01620747,  0.10544035,  0.11040542, -0.01982302, -0.01069263,\n",
       "         0.09196489,  0.02204156, -0.01462246, -0.01918635, -0.01301293,\n",
       "         0.09574054,  0.06594882,  0.09628135, -0.00783336, -0.01233655,\n",
       "         0.04179237,  0.01125724, -0.01244179,  0.09116368, -0.02239723,\n",
       "        -0.0040744 , -0.01147202, -0.03718669, -0.01863218,  0.12469059,\n",
       "         0.07766862, -0.05560998, -0.00810341, -0.02124978, -0.06992733,\n",
       "        -0.01443456,  0.112068  , -0.00859102,  0.00709991, -0.00598643,\n",
       "        -0.00844843, -0.01491749, -0.00681425, -0.00304056,  0.09456564,\n",
       "        -0.02108244, -0.01545298,  0.02369415, -0.00552644, -0.01630048,\n",
       "        -0.01901386, -0.01536645, -0.0070382 , -0.01736954, -0.02225454,\n",
       "         0.07998943, -0.02778023, -0.02083609, -0.01315964, -0.019989  ,\n",
       "        -0.06257483, -0.03162295, -0.03063627,  0.105502  ,  0.09560195,\n",
       "        -0.00656138, -0.0169334 , -0.00674928, -0.01511622, -0.0097502 ,\n",
       "        -0.02327169, -0.0213537 ,  0.07934961, -0.00973712, -0.01163673,\n",
       "         0.00439768, -0.04036956, -0.0111575 ,  0.01886742,  0.11414593,\n",
       "        -0.00564798, -0.01716539, -0.00571477, -0.00957219, -0.01638956,\n",
       "        -0.01456792, -0.02946067,  0.01375787], dtype=float32),\n",
       " array([[ 0.03768178, -0.03444809, -0.03768625, ...,  0.01449626,\n",
       "         -0.04282274, -0.01130447],\n",
       "        [-0.03842176, -0.0155063 ,  0.04051287, ...,  0.02974017,\n",
       "         -0.04738279, -0.00555439],\n",
       "        [ 0.01049459, -0.02178766,  0.01889836, ...,  0.02976642,\n",
       "          0.03077839,  0.01581566],\n",
       "        ...,\n",
       "        [ 0.03514713, -0.02299678,  0.04117142, ...,  0.01999392,\n",
       "         -0.0265776 , -0.02870047],\n",
       "        [ 0.02505034, -0.03207287,  0.04442737, ..., -0.0037929 ,\n",
       "         -0.00224912, -0.03514383],\n",
       "        [ 0.00449878,  0.01112965,  0.01739461, ..., -0.00662523,\n",
       "         -0.0455972 ,  0.03259184]], dtype=float32),\n",
       " array([-0.01225909, -0.05120811, -0.08589127, -0.0107744 , -0.00703078,\n",
       "        -0.06306455, -0.05215207, -0.06944025, -0.00227579, -0.00018656,\n",
       "         0.00552696,  0.04674207, -0.04112935, -0.06406683,  0.03432988,\n",
       "        -0.0288905 , -0.04959072, -0.00762853, -0.10189802, -0.06139124,\n",
       "        -0.01108814,  0.00733321, -0.02482403, -0.09801339, -0.06612963,\n",
       "        -0.03029988, -0.09129707, -0.06575438,  0.02281618,  0.05669393,\n",
       "        -0.08600531,  0.01917558, -0.0120247 ,  0.03787459, -0.01036745,\n",
       "         0.05922665, -0.08615567, -0.09019486, -0.09303874, -0.02780308,\n",
       "        -0.07009514, -0.05318927,  0.06944764, -0.05433126, -0.043149  ,\n",
       "         0.01728061, -0.08788893,  0.03299974, -0.01147041, -0.01111357,\n",
       "        -0.04133943, -0.08161671,  0.02004628, -0.07001964, -0.02025158,\n",
       "        -0.05002752, -0.052744  ,  0.03631409,  0.05468245, -0.08000601,\n",
       "        -0.03799224, -0.03890125, -0.02668442, -0.05703508, -0.04603047,\n",
       "        -0.00064237, -0.08354537, -0.02265882, -0.00504442, -0.08200236,\n",
       "        -0.07951221, -0.02461149, -0.01858236, -0.0540757 ,  0.03645867,\n",
       "         0.00660717, -0.01934395, -0.09090764, -0.00082933, -0.05491168,\n",
       "         0.07601535, -0.04749405,  0.03033015, -0.02660912,  0.05506845,\n",
       "        -0.04858904, -0.04171228, -0.06277812,  0.06479167, -0.10333376,\n",
       "        -0.06538782, -0.03929957, -0.05536133, -0.0470668 ,  0.0150683 ,\n",
       "        -0.05315549, -0.04106476,  0.01799747,  0.01757671, -0.04403219,\n",
       "        -0.08882696, -0.05797445,  0.04003227, -0.02336846, -0.06022773,\n",
       "        -0.04268807, -0.0461339 , -0.06967961,  0.08383248,  0.00660567,\n",
       "        -0.05058239, -0.07312905, -0.01122437,  0.05650677, -0.07394639,\n",
       "        -0.05642466, -0.07423737,  0.07408299, -0.00591446,  0.02166751,\n",
       "        -0.05595258, -0.08343949, -0.03057256, -0.07478078,  0.04778598,\n",
       "        -0.03758806, -0.06695043,  0.01674506, -0.05475823, -0.03310098,\n",
       "        -0.00951963, -0.02060613, -0.04402176,  0.07067914, -0.03596906,\n",
       "        -0.04511332, -0.08779263,  0.04110143, -0.07023561,  0.02890861,\n",
       "        -0.00760482, -0.04405057, -0.05494804, -0.01525014, -0.06859995,\n",
       "         0.04004649, -0.06655318, -0.09036655, -0.03598253, -0.05818403,\n",
       "        -0.03506485,  0.0152061 ,  0.00738629,  0.00203296,  0.07009838,\n",
       "         0.03887733, -0.04564763, -0.0481314 , -0.01762361, -0.06038736,\n",
       "        -0.09527908, -0.05063322, -0.09219576, -0.05262404, -0.02390531,\n",
       "        -0.03844415, -0.04205606, -0.03251324, -0.06166911, -0.01794767,\n",
       "        -0.06700156, -0.04570206,  0.0273602 , -0.0442522 ,  0.05338448,\n",
       "        -0.0630407 , -0.00441385,  0.01063269, -0.05409177, -0.02909334,\n",
       "         0.04813816, -0.01518553, -0.06700157, -0.02406079, -0.01737766,\n",
       "        -0.00548311, -0.08108055, -0.07723216,  0.05534264, -0.06250493,\n",
       "        -0.03735508,  0.05378645, -0.0548374 , -0.0481432 , -0.01040373,\n",
       "        -0.01576782, -0.03003757, -0.0421581 , -0.06386649, -0.01819054,\n",
       "        -0.07420751, -0.05937758,  0.02991734,  0.04879829,  0.01619126,\n",
       "        -0.0188066 , -0.03479455,  0.0171679 , -0.02620058,  0.07063252,\n",
       "        -0.07193256, -0.05325911, -0.02068033,  0.00085033, -0.02919334,\n",
       "        -0.05494117, -0.03985766,  0.07370234, -0.06861168,  0.02912451,\n",
       "        -0.0397868 ,  0.02724834,  0.02021124, -0.06704599, -0.03484366,\n",
       "        -0.0442131 , -0.05382505, -0.10638964, -0.04350115, -0.06361721,\n",
       "        -0.01913469,  0.01087543,  0.04714705, -0.04568165,  0.00166855,\n",
       "        -0.06167919, -0.04707152,  0.03784447,  0.00584161, -0.07818314,\n",
       "        -0.09041991, -0.08405679, -0.05356919, -0.08424564, -0.02013701,\n",
       "        -0.0077565 , -0.08517752, -0.05028167, -0.02362057, -0.04617357,\n",
       "        -0.09724741, -0.01403915,  0.02671875, -0.06394944, -0.05088623,\n",
       "         0.04276204], dtype=float32),\n",
       " array([[-0.0791054 , -0.00452043, -0.00772658, ...,  0.02757706,\n",
       "         -0.06971771,  0.04929078],\n",
       "        [ 0.07742192, -0.00049256, -0.01345637, ...,  0.01365817,\n",
       "         -0.06274512, -0.0650558 ],\n",
       "        [ 0.00577486, -0.02045243, -0.10906869, ..., -0.03451563,\n",
       "         -0.09031235,  0.05340072],\n",
       "        ...,\n",
       "        [-0.11719923, -0.054316  , -0.0632278 , ..., -0.07466821,\n",
       "          0.07269689,  0.00906046],\n",
       "        [-0.04856632,  0.07390479,  0.03730854, ..., -0.07984575,\n",
       "          0.0278273 ,  0.01563686],\n",
       "        [ 0.04970809,  0.02026957, -0.00392431, ..., -0.0303232 ,\n",
       "         -0.01517919,  0.09456728]], dtype=float32),\n",
       " array([ 0.01275114,  0.01189204, -0.07409336, -0.03926338, -0.05521142,\n",
       "        -0.00121903, -0.04427284,  0.00956688, -0.04637542, -0.00739425,\n",
       "         0.02603958, -0.03464597, -0.06683528,  0.01651769,  0.00462643,\n",
       "        -0.0096716 ,  0.02679072,  0.059297  ,  0.00900466,  0.0347284 ,\n",
       "        -0.02581692,  0.05263181, -0.04243675,  0.04640355, -0.04905999,\n",
       "        -0.06610346, -0.0441783 , -0.06995085,  0.00608187, -0.04807804,\n",
       "         0.01871311,  0.03782352, -0.0432695 ,  0.05652372, -0.03820296,\n",
       "        -0.01358752, -0.00232422,  0.09517693, -0.03500672, -0.00930565,\n",
       "        -0.04018473,  0.02737161, -0.0633986 ,  0.03572883, -0.03922453,\n",
       "        -0.01003844, -0.00369294, -0.00913518, -0.03664909,  0.01247303,\n",
       "        -0.04721871,  0.01705304, -0.06853105, -0.0027615 ,  0.00903647,\n",
       "         0.03789544,  0.03037204,  0.06111244,  0.02739117,  0.02433109,\n",
       "         0.03193866, -0.01393366, -0.01043816, -0.01668638, -0.05028631,\n",
       "        -0.0376539 ,  0.04404564, -0.00708388, -0.01928331, -0.02375039,\n",
       "        -0.04658085,  0.02572902, -0.02879194, -0.02863327, -0.00229299,\n",
       "        -0.03844526,  0.04306183,  0.01069894, -0.08178335, -0.07500376,\n",
       "        -0.06630619, -0.07695703, -0.04187284, -0.0270113 ,  0.05296005,\n",
       "         0.06399604,  0.0129133 ,  0.03291488, -0.03854092, -0.02330048,\n",
       "        -0.05373519, -0.0363826 , -0.04321887,  0.03407035,  0.00443115,\n",
       "         0.01082803,  0.06951304, -0.0399172 ,  0.03763393, -0.06532034,\n",
       "        -0.07566953, -0.03976213, -0.03502517, -0.01436169,  0.01386578,\n",
       "        -0.06090478, -0.01174329, -0.04015162,  0.01080237, -0.02674232,\n",
       "         0.0012346 ,  0.05859359, -0.06494972,  0.0386215 ,  0.0100729 ,\n",
       "        -0.03084852,  0.00356879,  0.01616058,  0.06687658,  0.03208656,\n",
       "        -0.01726081, -0.04344418, -0.03205886, -0.01444063, -0.03072032,\n",
       "        -0.05463837,  0.04450371, -0.01069186, -0.05706772,  0.04758807,\n",
       "        -0.03283945,  0.14496332, -0.00858471,  0.03342511, -0.04046906,\n",
       "         0.0014808 , -0.0679694 , -0.05289657, -0.10512226, -0.08924052,\n",
       "        -0.00059085,  0.09224797, -0.04542053,  0.05615675, -0.07476783,\n",
       "        -0.0548712 , -0.02001621,  0.03484784, -0.03217497,  0.03573852,\n",
       "        -0.02032401,  0.07303654, -0.06950595, -0.0716012 , -0.06413212,\n",
       "         0.02346646,  0.06926209, -0.06575216,  0.03587489, -0.11596723,\n",
       "         0.13852997, -0.06938125,  0.00406561, -0.00512156,  0.03579983,\n",
       "        -0.03169889, -0.10328403,  0.00266244,  0.01510948, -0.01996971,\n",
       "        -0.00616156, -0.10042717, -0.06257915,  0.04007941,  0.03861875,\n",
       "        -0.04277572,  0.04548615, -0.05028335, -0.09779729, -0.01190348,\n",
       "        -0.03647624,  0.00029389,  0.09662963, -0.04802438, -0.02194092,\n",
       "        -0.03082303,  0.01607199, -0.03632456,  0.05276756, -0.00841436,\n",
       "         0.06919958,  0.04052607, -0.04664525, -0.03366287,  0.02871957,\n",
       "        -0.03530979, -0.00293117, -0.04032946, -0.05530379, -0.00495892,\n",
       "         0.08947974,  0.03268259,  0.00768417, -0.02680937, -0.04080132,\n",
       "         0.05766964,  0.01935315, -0.07133312, -0.07982963, -0.03663424,\n",
       "        -0.03725707, -0.0698177 , -0.04982149, -0.06888997, -0.0699991 ,\n",
       "        -0.00864858,  0.05024768, -0.06627063,  0.02226367, -0.02083007,\n",
       "         0.02732263, -0.04920447, -0.02155524, -0.02541981,  0.01515335,\n",
       "        -0.01045389, -0.03371847, -0.01495019, -0.01636144,  0.01954456,\n",
       "         0.01977183,  0.01972035,  0.01622305, -0.03652826, -0.03472108,\n",
       "         0.06256966, -0.08228669, -0.0129424 , -0.03377457,  0.00366626,\n",
       "         0.03184392, -0.08076508, -0.06237876, -0.03245269,  0.03533099,\n",
       "         0.08729801, -0.02791632,  0.08917762,  0.04540993, -0.05796092,\n",
       "         0.00241428,  0.00220085,  0.05679169, -0.05121198,  0.1320748 ,\n",
       "         0.15400466, -0.05182226,  0.02565727,  0.09788612, -0.05477276,\n",
       "        -0.03464179, -0.08851274, -0.02573486, -0.02794347,  0.03533193,\n",
       "         0.05578623, -0.02527324, -0.09057233,  0.05394454, -0.00793294,\n",
       "        -0.01845069,  0.03931801,  0.01738306, -0.05583218, -0.04271901,\n",
       "        -0.03956757, -0.05652206, -0.0370141 , -0.02957108, -0.05320005,\n",
       "         0.00051701,  0.008967  , -0.03660963, -0.07011157,  0.06425221,\n",
       "        -0.05090772,  0.00780816, -0.05903409, -0.09715498,  0.00970273,\n",
       "        -0.03134924,  0.00158051,  0.00811223, -0.02685355, -0.06081811,\n",
       "        -0.0097594 ,  0.11214362, -0.10050504,  0.0526085 , -0.00401529,\n",
       "         0.02855246, -0.09547961,  0.09189188, -0.06926041, -0.08523865,\n",
       "         0.0166209 ,  0.00050129, -0.0222026 ,  0.07917374,  0.00360704,\n",
       "         0.00127528, -0.01827956,  0.04943674,  0.03168787, -0.04373217,\n",
       "        -0.03704581, -0.01620462,  0.01827654, -0.01078773, -0.04684169,\n",
       "         0.09672841, -0.00584226,  0.02571983,  0.0764783 , -0.01053792,\n",
       "        -0.04565491, -0.05890526,  0.05679203, -0.02644009,  0.03996987,\n",
       "         0.10001606, -0.02905611,  0.0959986 , -0.0221686 , -0.05483352,\n",
       "         0.03117959,  0.09787782, -0.05111417,  0.03152191, -0.05049864,\n",
       "        -0.0352958 , -0.03089948, -0.01304531, -0.04089726, -0.05691839,\n",
       "        -0.04673155,  0.10342886, -0.01875938, -0.06267752, -0.00524337,\n",
       "        -0.07984838,  0.09690998, -0.05781511, -0.01582239, -0.02441221,\n",
       "        -0.03670445,  0.09977801, -0.01266592, -0.05124125, -0.09710744,\n",
       "         0.02910221, -0.06095267, -0.02222418, -0.04478175,  0.02541844,\n",
       "        -0.07716394,  0.04074448, -0.04113198, -0.02067273, -0.04559579,\n",
       "        -0.03849906, -0.0600822 , -0.02022999, -0.01659157,  0.00778164,\n",
       "        -0.07303577, -0.00418415, -0.06828928, -0.04344028,  0.01757419,\n",
       "        -0.05327933, -0.04314439, -0.01526969, -0.0501804 ,  0.1040633 ,\n",
       "         0.03240166, -0.03375683,  0.09619438, -0.04949892, -0.06862684,\n",
       "         0.02011538,  0.00097906,  0.03695139,  0.07176665,  0.02198356,\n",
       "         0.04154335,  0.00020044, -0.01477723, -0.02177897, -0.03148021,\n",
       "         0.04210665,  0.11145141,  0.06438626, -0.02062176, -0.01202057,\n",
       "         0.02442864, -0.04720746,  0.06420857, -0.0279679 ,  0.03234018,\n",
       "        -0.01453303, -0.03966895,  0.02146773,  0.04047017, -0.06822716,\n",
       "        -0.04239522,  0.05989085, -0.02260842,  0.01414342,  0.08704727,\n",
       "        -0.03937904,  0.02467674,  0.01594344, -0.04873593, -0.07307066,\n",
       "        -0.0403126 , -0.03098719, -0.04771838, -0.0236601 , -0.00821215,\n",
       "        -0.04096421, -0.00103466, -0.05374721, -0.11126905, -0.04582494,\n",
       "        -0.00564115,  0.05536304,  0.01894869, -0.04901674,  0.0241477 ,\n",
       "        -0.00473688, -0.07397243,  0.01271271,  0.01642202,  0.08788708,\n",
       "        -0.02586577,  0.03009918, -0.05358732, -0.00427751, -0.05418075,\n",
       "        -0.0492133 , -0.00389208,  0.0041819 ,  0.13564163, -0.03998421,\n",
       "        -0.04293495,  0.08338597,  0.03804175,  0.00864557, -0.0442364 ,\n",
       "        -0.03752302,  0.07305592,  0.05270528, -0.03926216, -0.00499347,\n",
       "        -0.00190132, -0.0178903 , -0.02785641, -0.04611255, -0.03483397,\n",
       "         0.12555979,  0.002192  ,  0.00523552,  0.04591267, -0.00171982,\n",
       "         0.02876934,  0.08132458,  0.07357576, -0.06201257,  0.03153662,\n",
       "        -0.08577771, -0.04374451, -0.04747475, -0.00241487,  0.03187907,\n",
       "         0.05437048,  0.02280285, -0.00426263,  0.04752367,  0.01289582,\n",
       "        -0.02108981, -0.01063526, -0.05936889, -0.00332013,  0.01064384,\n",
       "         0.14359277, -0.03289254, -0.06524449, -0.09258091,  0.01454146,\n",
       "         0.01823333, -0.03935571, -0.06036446,  0.00839057, -0.07703059,\n",
       "        -0.03320911, -0.05676313, -0.05639809, -0.06564493,  0.01180064,\n",
       "        -0.03527775,  0.038456  ], dtype=float32),\n",
       " array([[ 0.03051261,  0.0181585 ],\n",
       "        [-0.06767423, -0.07086504],\n",
       "        [-0.08740932, -0.09491486],\n",
       "        ...,\n",
       "        [-0.05439458,  0.03066338],\n",
       "        [ 0.04670342,  0.05103219],\n",
       "        [-0.00902511, -0.02515239]], dtype=float32),\n",
       " array([-0.01821835,  0.01821836], dtype=float32)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 1ms/step\n",
      "56/56 [==============================] - ETA:  - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(x_train,y_train)\n",
    "score_test = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.9924242424242424\n",
      "Accuracy on testing set :  0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set : \", score_train[1])\n",
    "print(\"Accuracy on testing set : \", score_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"speech_model_correct.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
